
package com.github.jmeta.tools.fileaccessperformance.api.services;

import java.io.BufferedInputStream;
import java.io.BufferedOutputStream;
import java.io.File;
import java.io.FileFilter;
import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.RandomAccessFile;
import java.nio.MappedByteBuffer;
import java.nio.channels.FileChannel;
import java.nio.file.Files;
import java.nio.file.StandardCopyOption;
import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.logging.FileHandler;
import java.util.logging.Logger;
import java.util.logging.SimpleFormatter;
import java.util.logging.StreamHandler;

import com.github.jmeta.tools.benchmark.api.services.MeasurementSession;
import com.github.jmeta.tools.benchmark.api.services.SystemMillisTimeProvider;
import com.github.jmeta.tools.benchmark.api.types.MeasuredCommand;
import com.github.jmeta.tools.benchmark.api.types.MeasuredCommandExecution;
import com.github.jmeta.tools.benchmark.api.types.MeasurementCommandListener;
import com.github.jmeta.tools.fileaccessperformance.api.services.access.AbstractFileAccessor;
import com.github.jmeta.tools.fileaccessperformance.api.services.access.BufferedStreamAccessor;
import com.github.jmeta.tools.fileaccessperformance.api.services.access.FileChannelAccessor;
import com.github.jmeta.tools.fileaccessperformance.api.services.access.MappedByteBufferAccessor;
import com.github.jmeta.tools.fileaccessperformance.api.services.access.StreamAccessor;
import com.github.jmeta.utility.dbc.api.services.Reject;

/**
 * {@link FilePerformanceRunner} does a performance test
 *
 * The utility accesses an arbitrary number of files in different ways:
 * <ul>
 * <li>- Using a {@link RandomAccessFile}</li>
 * <li>- Using {@link FileInputStream} and {@link FileOutputStream}</li>
 * <li>- Using {@link BufferedInputStream} and {@link BufferedOutputStream}
 * around {@link FileInputStream} and {@link FileOutputStream}</li>
 * <li>- Using {@link FileInputStream} and {@link FileOutputStream} together
 * with their {@link FileChannel}</li>
 * <li>- Using {@link BufferedInputStream} and {@link BufferedOutputStream}
 * around {@link FileInputStream} and {@link FileOutputStream} together with
 * their {@link FileChannel}</li>
 * <li>- Using {@link FileInputStream} and {@link FileOutputStream} together
 * with their {@link FileChannel}'s {@link MappedByteBuffer}</li>
 * </ul>
 *
 * The performance test first reads some bytes from a specific offset up to the
 * end of file. Afterwards, some new bytes as well as the read bytes are written
 * to the file again.
 *
 * The file access is done like that:
 * <ul>
 * <li>(a) Read [bytes to read] + [bytes at end] bytes from the file starting
 * from offset (file size - [bytes at end] - [bytes to read])
 * <li>(b) Write [bytes to write] randomly generated bytes to the file starting
 * from offset (file size - [bytes at end] - [bytes to read]), i.e. at the same
 * offset of the bytes previously read
 * <li>(c) Write the [bytes to read] after the written [bytes to write]
 * <li>(d) Write the [bytes at end]</li>
 * </ul>
 *
 * The measurement results are written to an arbitrary OutputStream and a file
 * as semicolon-separated list.
 */
public class FilePerformanceRunner implements MeasurementCommandListener {

	/**
	 * {@link PerformanceTestFileFilter} prevents the following {@link File}s from
	 * being taken into account within the performance test:
	 * <ul>
	 * <li>Directories</li>
	 * <li>Hidden files</li>
	 * <li>Files that do not have accurate size</li>
	 * </ul>
	 */
	static class PerformanceTestFileFilter implements FileFilter {

		private long m_minimumSize;

		/**
		 * Creates a new {@link PerformanceTestFileFilter}.
		 *
		 * @param minimumSize The minimum size for accepting a {@link File}.
		 */
		public PerformanceTestFileFilter(long minimumSize) {
			m_minimumSize = minimumSize;
		}

		/**
		 * @see java.io.FileFilter#accept(java.io.File)
		 */
		@Override
		public boolean accept(File pathname) {

			return !pathname.isDirectory() && !pathname.isHidden() && (pathname.length() > m_minimumSize);
		}
	}

	private static final String RUN_DIR_NAME_FORMAT = "yy-MM-dd_hh-mm-ss";

	private static int CLONED_FILE_COUNTER = 1;

	/**
	 * Logs errors and infos to a given log file.
	 */
	private static Logger LOG = Logger.getLogger("global");

	static {
		try {
			final FileHandler handler = new FileHandler(
				"." + File.separator + "logs" + File.separator + "measurements_%g.log", true);

			handler.setFormatter(new SimpleFormatter());
			FilePerformanceRunner.LOG.addHandler(new StreamHandler(System.out, new SimpleFormatter()));
			FilePerformanceRunner.LOG.addHandler(handler);
			FilePerformanceRunner.LOG.setUseParentHandlers(false);
		} catch (Exception e) {
			throw new RuntimeException("Could not initialize logger", e);
		}
	}

	private Runtime m_runtime = Runtime.getRuntime();

	private ResultsWriter m_resultWriter;

	private MeasurementSession m_session;

	private final File m_testFile;

	private final long m_bytesToRead;

	private final long m_bytesToWrite;

	private final long m_bytesAtEnd;

	private AbstractFileAccessor[] m_accessors;

	/**
	 * Creates a new {@link FilePerformanceRunner}.
	 *
	 * @param testFile        The file to test.
	 * @param bytesToRead     The number of bytes to read.
	 * @param bytesToWrite    The number of bytes to write.
	 * @param bytesAtEnd      The number of bytes at the end.
	 * @param deleteTempFiles Whether to delete temporarily created files or not.
	 * @param machineString   The string identifying machine HW properties.
	 */
	public FilePerformanceRunner(File testFile, int bytesToRead, int bytesToWrite, int bytesAtEnd,
		boolean deleteTempFiles, String machineString) {
		Reject.ifNull(testFile, "testFile");
		Reject.ifTrue(!testFile.exists(), "The given file " + testFile.getAbsolutePath() + " exists");

		m_testFile = testFile;
		m_bytesToRead = bytesToRead;
		m_bytesToWrite = bytesToWrite;
		m_bytesAtEnd = bytesAtEnd;

		try {
			FilePerformanceRunner.LOG.info("\n");
			FilePerformanceRunner.LOG.info("\n");
			FilePerformanceRunner.LOG.info("============================");
			FilePerformanceRunner.LOG.info("File performance measurement");
			FilePerformanceRunner.LOG.info("============================");
			FilePerformanceRunner.LOG.info("\n");

			checkFile(m_testFile);

			FilePerformanceRunner.LOG.info("Original file path: " + m_testFile);
			FilePerformanceRunner.LOG.info("Original file size: " + m_testFile.length() + " bytes");

			File runDir = createRunDirectory();

			FilePerformanceRunner.LOG.info("Directory for cloned run files: " + runDir);

			byte[] writeBytes = generateBytesToWrite();

			m_accessors = new AbstractFileAccessor[] {
				new FileChannelAccessor(cloneFile(testFile, runDir), writeBytes, bytesToRead, bytesAtEnd,
					deleteTempFiles),
				new StreamAccessor(cloneFile(testFile, runDir), writeBytes, bytesToRead, bytesAtEnd, deleteTempFiles),
				new BufferedStreamAccessor(cloneFile(testFile, runDir), writeBytes, bytesToRead, bytesAtEnd,
					deleteTempFiles),
				new MappedByteBufferAccessor(cloneFile(testFile, runDir), writeBytes, bytesToRead, bytesAtEnd,
					deleteTempFiles), };

			m_session = new MeasurementSession(new SystemMillisTimeProvider(), machineString);
			m_resultWriter = new ResultsWriter(new File("./data/performanceTest/results"));

			m_session.setMeasurementCommandListener(this);
		}

		catch (Exception e) {
			final String message = "Exception occurred during file performance test initialization: " + e.getMessage();
			FilePerformanceRunner.LOG.severe(message);
			throw new RuntimeException(message, e);
		}
	}

	/**
	 * @see MeasurementCommandListener#aboutToExecuteCommand(MeasuredCommand,
	 *      MeasurementSession)
	 */
	@Override
	public void aboutToExecuteCommand(MeasuredCommand command, MeasurementSession session) {

		Reject.ifNull(session, "session");
		Reject.ifNull(command, "command");

		FilePerformanceRunner.LOG.info("About to execute command: " + command.getUniqueName());
		logMemoryFootprint();
	}

	/**
	 * Checks the test file for being feasible for the test run.
	 *
	 * @param testFile The test file
	 */
	private void checkFile(File testFile) {

		long minimumSize = m_bytesToRead + m_bytesAtEnd;

		final PerformanceTestFileFilter filter = new PerformanceTestFileFilter(minimumSize);

		if (!filter.accept(testFile)) {
			final String message = "File <" + m_testFile + "> cannot be measured due to at least one "
				+ "of the following reasons: It is a folder, it is a hidden file or its "
				+ "size is less than the minimum size <" + minimumSize + ">.";

			throw new RuntimeException(message);
		}
	}

	/**
	 * Clones the test file by copying its contents to the run directory. This
	 * ensures that each command and that later test runs will operate on the
	 * exactly same file.
	 *
	 * @param testFile The test file
	 * @param runDir   The directory the copied file will be stored.
	 * @return The cloned {@link File}.
	 * @throws IOException In case of any problems during file access
	 */
	private File cloneFile(File testFile, File runDir) throws IOException {

		File clonedFile = new File(runDir, m_testFile.getName() + "_" + FilePerformanceRunner.CLONED_FILE_COUNTER++);

		Files.copy(testFile.toPath(), clonedFile.toPath(), StandardCopyOption.REPLACE_EXISTING);

		return clonedFile;
	}

	/**
	 * @see MeasurementCommandListener#commandExecuted(MeasuredCommand,
	 *      MeasurementSession, MeasuredCommandExecution)
	 */
	@Override
	public void commandExecuted(MeasuredCommand command, MeasurementSession session,
		MeasuredCommandExecution measuredCommandExceution) {

		Reject.ifNull(session, "session");
		Reject.ifNull(command, "command");

		FilePerformanceRunner.LOG.info("Executed command: " + command.getUniqueName());
		FilePerformanceRunner.LOG.info(
			"Execution time: " + (measuredCommandExceution.getStopTime() - measuredCommandExceution.getStartTime())
				+ " " + session.getTimeProvider().getUnit());

		try {
			m_resultWriter.writeResults(command, m_testFile, m_bytesToRead, m_bytesToWrite, m_bytesAtEnd, session,
				measuredCommandExceution, session.getMachineInfo());
			logMemoryFootprint();
		}

		catch (Exception e) {
			FilePerformanceRunner.LOG
				.severe("Unable to write data set to csv file <" + m_resultWriter.getFilePath() + ">");
			e.printStackTrace();
		}
	}

	/**
	 * Creates a new sub directory used for storing temporary files and results of a
	 * file performance test run.
	 *
	 * @return The newly created directory.
	 */
	private File createRunDirectory() {

		Date currentDate = new Date();

		SimpleDateFormat sdf = new SimpleDateFormat(FilePerformanceRunner.RUN_DIR_NAME_FORMAT);

		File runDir = new File("./data/performanceTest/runs" + File.separator + "RUN_" + sdf.format(currentDate) + "_"
			+ m_testFile.getName());

		if (!runDir.mkdir()) {
			throw new RuntimeException(
				"Could not create directory for performance run: <" + runDir.getAbsolutePath() + ">");
		}

		return runDir;
	}

	/**
	 * Generates bytes for writing.
	 *
	 * @return randomly generated bytes for writing.
	 */
	private byte[] generateBytesToWrite() {
		byte[] bytesToWrite = new byte[(int) m_bytesToWrite];

		for (int i = 0; i < m_bytesToWrite; i++) {
			bytesToWrite[i] = (byte) (1 + (Math.random() * Byte.MAX_VALUE));
		}

		return bytesToWrite;
	}

	/**
	 * Returns the total free memory currently available.
	 *
	 * @return the total free memory currently available.
	 */
	private long getTotalFreememory() {

		long maxMemory = m_runtime.maxMemory();
		long allocatedMemory = m_runtime.totalMemory();
		long freeMemory = m_runtime.freeMemory();

		return (freeMemory + (maxMemory - allocatedMemory));
	}

	/**
	 * Logs the memory footprint.
	 */
	private void logMemoryFootprint() {

		FilePerformanceRunner.LOG.info("[MEM] free memory: " + m_runtime.freeMemory() + " [byte]");
		FilePerformanceRunner.LOG.info("[MEM] allocated memory: " + m_runtime.totalMemory() + " [byte]");
		FilePerformanceRunner.LOG.info("[MEM] max memory: " + m_runtime.maxMemory() + " [byte]");
		FilePerformanceRunner.LOG.info("[MEM] total free memory: " + getTotalFreememory() + " [byte]");
	}

	/**
	 * Starts the performance test
	 */
	public void runPerformanceTest() {

		FilePerformanceRunner.LOG.info("Measurement started....");

		try {
			m_session.runMeasurement(m_accessors, 1);
		}

		catch (Exception e) {
			final String message = "Exception during running performance test";
			FilePerformanceRunner.LOG.severe(message + ": " + e);
			throw new RuntimeException(message, e);
		}

		FilePerformanceRunner.LOG.info("....Measurement stopped");

		try {
			m_resultWriter.close();

			for (int i = 0; i < m_accessors.length; i++) {
				m_accessors[i].close();
			}

			final File runDir = m_accessors[0].getFile().getParentFile();

			if (runDir.listFiles().length == 0) {
				if (!runDir.delete()) {
					FilePerformanceRunner.LOG.warning("Could not delete run directory <" + runDir + ">");
				}
			}
		}

		catch (Exception e) {
			final String message = "Exception during shutting down performance test";
			FilePerformanceRunner.LOG.severe(message + ": " + e);
			throw new RuntimeException(message, e);
		}
	}
}
