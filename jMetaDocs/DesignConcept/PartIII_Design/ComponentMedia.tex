%-----------------------------------------------------------------------------------------------
%		\COMPmedia{} Design
%-----------------------------------------------------------------------------------------------

\section{\COMPmedia{} Design}
\label{sec:COMPmediaDesign}

In this section, the design of the component \COMPmedia{} is described. Basic task of the component is to provide access to memory areas which contain multimedia data. Primarily these are files.

The term \TERMmedium{} needs to be sharpened here: In \SectionLink{sec:Medium} we had defined:
``A \TERMmedium{} defines the storage medium of \TERMdataBlocks{}. It can be a file or a \TERMmediaStream{}, or the main memory itself.''

In detail, the term summarizes the aspects ``physical storage'' and ``access mechanism'' (e.g. file-based random-access, or byte stream). Thus there might perfectly be two different media which access the same physical storage, but using different access mechanism. The term \TERMmedium{} is an abstraction and potentially allows even more special possibilities, like media streams, databases etc.

%-----------------------------------------------------------------------------------------------
%		Designentscheidungen \COMPmedia{}
%-----------------------------------------------------------------------------------------------

\subsection{Basic  Design Decisions \COMPmedia{}}
\label{sec:InterfaceDesignCOMPdataPartManagementDES2}

Here, the fundamental design decisions of the component \COMPmedia{} beschrieben.

%-----------------------------------------------------------------------------------------------

\subsubsection{Supported \TERMmedia{}}
\label{sec:SuppMedia}

This section lists decisions about supported \TERMmedia{}. To start with, it is clear that \LibName{} must support files as basic medium.

%%%% DD --> %%%%
\DD{dd:400}
{% Titel
Support for random-access file access
}
{% Kurzbeschreibung
\LibName{} supports the use of files as input and output medium via \COMPmedia{} with access mechanism ``Random Access''.
}
{% Begründung
Files are \emph{the} fundamental and most common digital media containers, even in 2016. Of course MP3 files, AVI files etc. with multimedia content are wide-spread. A library such as \LibName{} must support files as core element. To more efficiently process files, random-access is inevitable. Especially reading at arbitrary offsets \-- e.g. tags at end of file \-- as well as skipping of unimportant content is efficient to implement with random-access.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

But also reading streams shall be supported to increase the flexibility of the library:

%%%% DD --> %%%%
\DD{dd:401}
{% Titel
Support for sequential, reading byte streams
}
{% Kurzbeschreibung
\LibName{} supports the use of reading byte streams, i.e. \texttt{InputStream}s for input in mode ``sequential access''.
}
{% Begründung
\texttt{InputStream} represents the most general alternative of a \TERMmedium{} from Java perspective, which ensures a potentially higher flexibility for using \LibName{}. E.g. multimedia files can be read from ZIP or JAR archives using streams, and support for media streams might be easier to implement in later releases \-- However: To state clearly: media streams do have nothing to do with this design decision. They might be implemented completely different in upcoming releases.
}
{% Nachteile
An \texttt{InputStream} supports by definition only sequential access and no random-access (e.g. via \texttt{FileInputStream}). Thus there might be higher complexity for implementation, as well as signficant performance drawbacks because of lacking random-access.
}
%%%% <-- DD %%%%

Last but not least, the library offers access to RAM contained data, due to flexibility:

%%%% DD --> %%%%
\DD{dd:402}
{% Titel
Support for random-access to byte arrays
}
{% Kurzbeschreibung
\LibName{} allows for random-access to byte arrays as input medium and output medium.
}
{% Begründung
Already loaded memory content can be parsed with \LibName{} without need for artistic climbs, increasing flexibility of the library.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

What about \texttt{OutputStream}s? That is discussed in the following:

%%%% DD --> %%%%
\DD{dd:403}
{% Titel
No support for writing byte streams
}
{% Kurzbeschreibung
\LibName{} does not support writing byte streams, i.e. \texttt{OutputStream}s.
}
{% Begründung
\texttt{OutputStream}s are write-only, but still not random-access. Thus we would need \-- provided we want to access random-access media in a random-access style \-- a second implementation next to writing random-access. A combined usage of \texttt{InputStream}s and \texttt{OutputStream}s for Read-/Write access on the same medium is not designed into the Java API and leads to diverse problems. As \LibName{} already implements writing to output files and byte arrays, for reasons of effort, \texttt{OutputStream}s are not supported as output media. The user might implement \texttt{OutputStream}s easily by him- or herself, e.g. by first writing into byte arrays, then into an \texttt{OutputStream}.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{Consistency of  \TERMmedium{} Accesses}
\label{sec:KonsPerfMedia}

Parallel access to the same medium from different processes or threads, reading by one and writing by the other, might lead to unpredictable difficulties - even without using any caching. If you e.g. have some parsing metadata like the length of a block in bytes at hand, but a parallel process shortens the block, your read access trying to fetch the whole block will run into unexpected end of file or read inconsistent data.

To avoid such problems, there are special locking mechanisms for exclusive access to the bottleneck ressource, at least for files. We define:

%%%% DD --> %%%%
\DD{dd:404}
{% Titel
Locking of files during \LibName{} access
}
{% Kurzbeschreibung
Files are \emph{always} locked during access by \LibName{} explicitly. File content is protected by exclusive locks from corruption by other processes and threads. See \cite{PWikIO}, where we show that a file in Java must be explicitly opened for writing to be able to lock it. ``During access'' means: After opening it and until closing it. The lock thus might be long-term. \LibName{} opens a file for writing (and locking) even if the user explicitly requested read access only.
}
{% Begründung
Other processes and threads of the same JVM cannot access the files and corrupt any data, which avoids consistency problems.
}
{% Nachteile
It is not possible to access the same file in parallel threads when using \LibName{}. It seems rather unlikely that such parallel access to the same file (e.g. reading at different places) can speedup an application. But for future media this might indeed be a drawback.
}
%%%% <-- DD %%%%

The locking of byte streams or memory regions does not make sense, as discussed in the following desing decisions:

%%%% DD --> %%%%
\DD{dd:405}
{% Titel
No locking of byte streams 
}
{% Kurzbeschreibung
Byte streams are not locked
}
{% Begründung
The interface \texttt{InputStream} does not offer any locking mechanisms. \LibName{} will not try to guess the kind of stream and lock it (e.g. by checking if it is a \texttt{FileInputStream}).
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

For different processes, the os usually protects access of memory regions. The question is whether \LibName{} should protect access to byte arrays:

%%%% DD --> %%%%
\DD{dd:406}
{% Titel
No locking of byte arrays
}
{% Kurzbeschreibung
Byte arrays are not locked
}
{% Begründung
This makes not much sense as the user anyways gets a reference to the byte array by the API, and thus can access and manipulate the raw bytes arbitrarily in a multi- or single-threaded way. Protecting it by thread locking mechanisms increases complexity and does not seem to generate any benefits whatsoever.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{Unified API for Media Access}
\label{sec:PerfMediaZUGR}

In the wiki article \cite{PWikIO}, we have shown clearly the differences between byte streams and random-access files. With so many difference the question arises: Can this be unified at all and does the effort make sense here? The least common demoninator for random-file-access and \texttt{InputStream}s is the linear reading of all bytes in the medium. This is clearly too less. It denies all advantages of random-access. The intersection of features for a unification is therefore not making sense.

Moreover, we want a unifying combination of both approaches:

%%%% DD --> %%%%
\DD{dd:407}
{% Titel
Unified access to all supported media types in one API
}
{% Kurzbeschreibung
\COMPmedia{} offers a common abstraction for accessing files via random-access, \texttt{InputStream}s as well as byte arrays. This API provides the advantages of both access mechanisms via a common interface. The implementation throws exceptions of kind ``Operation not supported'' in some cases, if a feature is not supported by the medium. In other cases, a meaningful alternative behaviour is implemented. The using code must perform branche decisions at some places depending on the medium type.

While byte arrays are no problem for the abstraction, even random-access files and \texttt{InputStream}s have more in common as you might think at first glance:
\begin{itemize}
	\item The operations Open, (sequential) Read, Close.
	\item \texttt{InputStream}s can also (at least technically) be assigned a beginning, offsets and an end.
	\item Files can be read-only, too, which \texttt{InputStream}s are always by definition.
\end{itemize}

Writing access to a read-only medium is acquitted with a runtime exception, especially for an \texttt{InputStream}.

The main difference between files and \texttt{InputStream}s is of course: Random access is possible for files, while \texttt{InputStream}s can only be read sequentially. This difference can be potentially decreased using mechanisms such as buffering.
}
{% Begründung
The API of the component \COMPmedia{} gets easier for outside users, its usage feels more comfortable. Using components of \COMPmedia{} can offer their users in turn an easier interface. At the same time, the advantages of both approaches (random-access and better performance for files, generality and flexibility for streams) are still available. 
}
{% Nachteile
A few operations of the API cannot be implemted for both media types, which makes case decisions in the client code necessary in some cases.
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{Two-Stage Write Protocol}
\label{sec:GrundSchreiben}

When Writing, it is all about bundeling accesses and buffering. We want optimum performance und thus want to implement these mechanisms. Therefore we commit to following design decisionfor implementing writing in \LibName{} in general:

%%%% DD --> %%%%
\DD{dd:410}
{% Titel
\COMPmedia{} uses a two-stage write protocol controlled by the user
}
{% Kurzbeschreibung
The first stageis the mere registration of changes, that need to written to the external medium. In this first stage, there is no access to the external medium yet. The second stage is the operation \emph{flush}, the final writing and commiting of all changes to the external medium. The underlying implementation bundles the write actions according to its needs into one or several packets and execute the write only in the second stage.
}
{% Begründung
An efficient write implementation is possible. Internally, write actions can be bundled as needed to perform better. And this can be done without forcing the user to do it himself. The user can perform write (registration) actions whenever his code architecture needs it. Saying this, the user code is not burdened with too much restrictions or rules. Furthermore, the potential possibility of an ``undo'' of already registered actions comes into view.
}
{% Nachteile
Errors that occur when actually flushing changes to the external medium are recognizes potentially quite late. Thus the registration of changes is quite fast while the flush itself can be a long taking process. Bugs might be introduced by user code forgetting to implement the second step, the flush.
}
%%%% <-- DD %%%%

Even if we implement this, it must be clearly stated that this is not in any way a transaction protocol as implemented by some O/R mappers (e.g. hibernate) or application servers. The mentioned protocol is much simpler and not in the least capable to provide ACID! Thus the following exclusion:

%%%% DD --> %%%%
\DD{dd:410b}
{% Titel
Writing in \COMPmedia{} does not guarantee ACID, in case of errors during \emph{flush}, there is no rollback
}
{% Kurzbeschreibung
ACID (atomicity, consistency, isolation and durability) is not ensured neither by the implementation ofn \COMPmedia{} nor in gerenal by the Java File I/O. If e.g. an error occurs during Writing in the \emph{flush} stage, some data has been written already, while upcoming data will not get written anymore. There is no undo of already written data. The operation \emph{undo} must not be mixed up with a rollback and it is no action that is done automatically. While isolation and durability can be more or less provided, the user is responsible for consistency and atomicity himself.
}
{% Begründung
A transaction manager that guarantees ACID, and this for files, is really hard to implement (correctly). This requirement is somehow out of scope, no other competing library is doing something similar. \LibName{} will not be a database!
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%


% -------------------------------------------------------------------------------------------------------
\subsubsection{Requirements for the Two-Stage Write Protocol }%
\label{sec:AnforderungenandaszweistufigeSchreibprotokoll}%

Which writing operations must be offered? One method write() \-- at the end it is the only really writing primitive of the Java File I/O \-- is not sufficient. How do you remove with this method? write() equals \textit{overwriting}, which is not convenient at all. \COMPmedia{} must offer a better API, taken some of the burdens of I/O from the user. Here, we only specify the necessary operations, without going into details with their  implementation - this will be done later.

To develop a good design, however, you must first list down the user's requirements to \COMPmedia{}. This especially includes the requirements for a two-stage write protocol. Main users of the component is definitely the component \COMPdataPartManagement{}. It uses \COMPmedia{} to extract and write metadata from and into tags. Without going into the design details of \COMPdataPartManagement{}, here we nevertheless list detailed requirements that \COMPdataPartManagement{} has for \COMPmedia{} regarding two-stage writing, see table \hyperref[tab:AnfDBlocks]{\ref{tab:AnfDBlocks}}.

\begin{landscape}
\begin{longtable}{|p{0.07\linewidth}|p{0.44\linewidth}|p{0.44\linewidth}|}
	\hline
	\rowcolor[gray]{.9}\textbf{ID} & \textbf{Requirement} & \textbf{Motivation} \\
	\endhead
	\hline
	\texttt{AMed01} & It must be possible to insert bytes & Formats such as ID3v2 can be dynamically extended and have a payload of flexible length. Before an already present data block, it must be possible to insert another one. There is especially a need for an insertion operation in the case when metadata with dynamic length need to be written at the beginning of a file. \\
	\hline
	\texttt{AMed02} & It must be possible to remove bytes & With the same motivation as for insertion. It must be especially possible to remove entire metadata tags. \\
	\hline
	\texttt{AMed03} & It must be possible to replace bytes and not only overwrite, but also grow or shrink an existing byte area with replacement bytes & In metadata formats, there are both static fields with fixed length as well as dynamic fields such as null-terminated strings. If bytes are already present, it must be possible to overwrite them to save costly remove and insert operations. The growing and shrinking is especially useful and represents a higher level of abstration. If this would not be possible, replacing a previous small string value by a new longer or shorte one would need to be implemented with two operations (overwrite and insert or remove, respectively). \\
	\hline
	\texttt{AMed04} & Inserted data (Anforderung \texttt{AMed01}) must be changeable before a \texttt{flush} e.g. by extending, overwriting or removing of child fields inside the inserted data block & Based on the two-stage write protocol, an arbitrary number of writing changes can be made before a \texttt{flush}, and these might correct each other. E.g. a new ID3v2 tag footer is inserted, that stores the length of the tag. Assume that after this, a new frame is inserted into the tag, before the flush. This requires the \texttt{size} field in the firstly inserted footer to be changed afterwards again, before the flush. \\
	\hline
	\texttt{AMed05} & Replaced data (Anforderung \texttt{AMed03}) must be changeable before a \texttt{flush} e.g. by extending, overwriting or removing of child fields inside the replaced data block & A prominent example is insertion of and step-by-step extension of a frame into an ID3v2 tag: For the first creation as well as each extension, the \texttt{size} field of the tag must be changed, which induces a replace operation each time. E.g. it is allowed that users first only create and insert the new frame, and then insert new child fields afterwards, step by step. \\
	\hline
	\texttt{AMed06} & The padding feature of several data formats should be used by \LibName{} & Formats such as ID3v2 allow padding, i.e. using an overwrite buffer are to avoid newly writing the whole file. \LibName{} must use this feature when writing data, such that e.g. an insert only affects the file content until the padding area, effectively decreasing the padding, while a remove increases the padding, but the overall tag size remains the same. It is rather an indirect requirement which needs not necessarily be implemented by \COMPmedia{} only. \\
	\hline
	\texttt{AMed07} & The operations replace, remove and insert must be undoable before a \texttt{flush} & This allows to avoid unnecessary accesses to the medium and to undo mistakes by end users. \\
	\hline
\caption{Requirements for the two-stage write protocol by \COMPdataPartManagement{}}
\label{tab:AnfDBlocks}
\end{longtable}
\end{landscape}

Based on these requirements, we can first define the following basic design decisions for writing:

%%%% DD --> %%%%
\DD{dd:410d}
{% Titel
\COMPmedia{} offers the writing operations \emph{insert}, \emph{replace} and \emph{remove}
}
{% Kurzbeschreibung
The user can:
\begin{itemize}
\item \emph{insert} $N$ bytes at a given offset
\item \emph{replace} $N$ bytes at a given offset by $M$ new bytes
\item \emph{remove} $N$ bytes at a given offset
\end{itemize}
}
{% Begründung
These are operations, that are in principle already necessary for a metadata library: \texttt{replace} is needed for formats with static length (such as ID3v1) and those allowing a padding mechanism or similar (such as ID3v2). For dynamically extensible formats such as ID3v2, additional possibilities to \texttt{insert} and \texttt{remove} data blocks are necessary. A dynamic replacement (replace $N$ bytes by $M=N$ or $M\neq N$ bytes) is necessary to easily change fields with dynamic lengths, without the need to inconveniently call several different operations (e.g. first \texttt{replace}, then \texttt{remove} when decreasing the length of a string by setting a new value).

The burden to implemen these convenient operations using the Java File I/O, which essentially only offers write() and truncate(), is taken over by \COMPmedia{}, such that the user need not care.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

As we have a two-stage write protocol, the \emph{undo} of not yet flushed changes is possible, and according to the requirements also necessary.

%%%% DD --> %%%%
\DD{dd:420}
{% Titel
Writing operations on a medium can be undone with \emph{undo} before a \emph{flush}
}
{% Kurzbeschreibung
Writing operations lead to pending changes according to \DesLink{dd:410}. These can be undone according to the requirements defined above.
}
{% Begründung
The application logic can require \emph{undo} in some cases, e.g. for corrections of mistakes done by an end user. Instead of requiring to call the inverse operation (if any at all), the user is much more convenient with undoing the operation itself directly. This also ensures that the using code does not need to trace changes to be able to find which is the inverse operation.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%


%-----------------------------------------------------------------------------------------------

\subsubsection{Caching}
\label{sec:PerfMedia}

The component \COMPmedia{} takes over I/O tasks with potentially slow input and output media. Thus, it is here where the basic performance problems of the whole library need to be solved. We will approach these topics with some motivation and deductions.

In \cite{PWikIO}, basic stuff regarding performance with file access is discussed. The ground rule for performant I/O is minimizing accesses to the external, potentially slow medium. For writing, we already introduced \DesLink{dd:410}. A similar important question is: How can you make reading perform better?

At first it is quite clear that for reading, you should help yourself with buffering to improve performance:

%%%% DD --> %%%%
\DD{dd:409}
{% Titel
Reading access can be done using a buffering mechanism, controlled by the component's user
}
{% Kurzbeschreibung
For each reading access, the calling code can specify the number of bytes to read, which corresponds to a buffering. The code controls the size of the buffer by itself. It potentially can also read only one byte. It lies in the responsibility of the calling code to read an amount of bytes that makes sense and minimizes read accesses.
}
{% Begründung
A hardcoded fixed length buffering would rather lead to performance disadvantages, as there might be read too much bytes, more than necessary in average. Furthermore, depending on the fixed size, it would be necessary to read two or even several times when a bigger chunk of data is needed. According to \cite{PWikIO}, there is no ``one size fits all'' for buffer sizes in file I/O. The logical consequence is to let the user decide.
}
{% Nachteile
No disadvantages known.
}
%%%% <-- DD %%%%

A further important aspect is caching: With \emph{Caching}, we refer to the possibly long-term storage of \TERMmedium{} contents in RAM to support faster access to the data. Buffering differs from caching in a sense that buffering is only a short-lived temporary storage without the necessity of synchronisation.

To start with, we can see - besides the already mentioned buffering - different kinds of ``Caching'' in an application that is based on \LibName{}:
\begin{itemize}
	\item During file access there are caches on hardware level, in the OS and file system.
	\item Java supports temporary buffering via the \texttt{BufferedInputStream}, and caching explicitly via \texttt{MappedByteBuffer}s.
	\item Applications that mostly are interested in human-readable metadata read it, convert it via \LibName{} into a clear-text representation and show this representation in their GUI. In this case the GUI model represents a kind of caching that also allows changes to this metadata in the GUI, it is not necessary to re-read again from the medium.
\end{itemize}

If we look at all these alternatives, the question arises why at all an additional built-in caching in \LibName{} would be needed? For answering this question, we should look at some use case scenarios for the library: One scenario is the already mentioned reading of metadata from a file to display it in a GUI. For such a case, caching would usually not be very useful. You read once, and maybe twice, if the user wishes to update the screen. It would be an acceptable performance without caching. Another use case is the arbitrary jumping between parts of a container format file using a low-level API to process specific contents. This is true ``random access''. The question is: Do you want to read the same place twice? Sometimes possibly yes. Instead, would you want a direct medium access again? Possibly yes or no.

The last question brings up another general problem with caching: The problem of synchronicity with the external medium. If the medium has been changed in between, the cache content is probably aged and invalid. Code that accesses the cache can usually not recognize this.

We first sum up the identified advantages and disadvantages:

\begin{longtable}{|p{0.5\textwidth}|p{0.5\textwidth}|}
	\hline
	\rowcolor[gray]{.9}\textbf{Advantages} & \textbf{Disadvantages} \\
	\endhead
	\hline
	$+$ Performance improvement when reading the same data multiple times, as cache access is much faster than the access to the external medium & $-$ When only accessing once there is of course no performance improvement \\
	\hline
  $+$ In a cache you are - in principle - more flexible to reorganize data than on an external medium, making it easier to correct, undo or bundle changes. & $-$ External 3rd party changes on the \TERMmedium{} cannot be recognized and lead to invalid cache content that might lead to erroneous behaviour or data corruption in follow-up write actions. \\
	\hline
	 & $-$ There is additional code necessary for caching, e.g. questions such as ``when is the allocated memory freed?'' must be answered. For consistency topics, even more complex code is necessary.\\
	\hline
	 & $-$ More heap space required\\
	\hline
\caption{Advantages and disadvantages of caching in \LibName{}}
\label{tab:CachingProCon}
\end{longtable}

The disadvantages outweight the advantages. Why should you then use caching in \LibName{} at all? Because some of the previous design decisions combine well with a caching approach:
\begin{itemize}
\item \DesLink{dd:407} can be achieved using a cache, as we see just a little later
\item \DesLink{dd:409} can be implemented with a cache, i.e. anything that has been buffered should directly go into the cache for subsequent read actions
\item \DesLink{dd:410} may or may not be easier to implement using a cache. In this case the cache would be used to store the registered changes before a flush. However, if it would only be this, a cache would be greatly too complex. Easier solutions are possible for holding the not-yet-flushed data.
\end{itemize}

Thus we decide:

%%%% DD --> %%%%
\DD{dd:411}
{% Titel
\COMPmedia{} keeps medium data read in a cache
}
{% Kurzbeschreibung
\COMPmedia{} uses a RAM-based, potentially long-lived fast storage (cache) to store already read content of the \TERMmedium{}. Subsequent read accesses request the cache content (if present) only.
}
{% Begründung
\begin{itemize}
\item We provide faster repeated read access to already read data to the end-user
\item This can be used for direct implementation of \DesLink{dd:409} in a sense of buffering when reading. i.e. the cache works as the buffer for \DesLink{dd:409}
\item Implementation of \DesLink{dd:407} can be done using a cache
\end{itemize}
}
{% Nachteile
Were given in table \hyperref[tab:CachingProCon]{\ref{tab:CachingProCon}}. The alternative is a direct medium access. To summarize the disadvantages against a direct medium access:
\begin{itemize}
\item Higher code complexity
\item More heap required, the cache is durable
\item The medium might change by external processes, such that the cache content is not in synch anymore.
\end{itemize}
Note that this last mentioned disadvantage is mostly mitigated by \DesLink{dd:404}.
}
%%%% <-- DD %%%%

How to use caching to better achieve \DesLink{dd:407}?

%%%% DD --> %%%%
\DD{dd:411b}
{% Titel
Caching is used to better mitigate the differences between \texttt{InputStream}s and files according to \DesLink{dd:407}.
}
{% Kurzbeschreibung
The data that has been read from an \texttt{InputStream} is always put into a cache. Reading actions are therefore allowed to ``go back'' to already read data, by not issuing another direct access (which is anyway not possible using an \texttt{InputStream}), but by taking the data from the cache. ``Read ahead'' for areas that have not yet been reached on the \texttt{InputStream} lead to the behaviour that all data up to the given higher offset is read and cached.
}
{% Begründung
This implements \DesLink{dd:407} nearly entirely, ``transparent'' to the user.
}
{% Nachteile
Even more heap space is necessary for \texttt{InputStream}s, as in extreme cases the whole medium might end up in the cache, which might lead to \texttt{OutOfMemoryError}s.
}
%%%% <-- DD %%%%

Of course, the disadvantages mentioned in \DesLink{dd:411b} are heavy-weigth. If you wouldn't do anything about it to mitigate these disadvantages, then \DesLink{dd:411b} would be nonsense, as the advantages of this approach would be dramatically overshadowed by its disadvantages.

As a first step, the following three design decisions are necessary:
%%%% DD --> %%%%
\DD{dd:411c}
{% Titel
The user can disable caching entirely
}
{% Kurzbeschreibung
The user can disable caching entirely. Here, too, access to previously cached offsets is not possible for \texttt{InputStream}s and will be acquitted with an exception.
}
{% Begründung
The user is responsible to decide about the memory footprint: E.g. if the medium is comparatively small, caching can be tolerated. If it is a big medium, the user has the possibility to disable caching, however demanding a step-wise processing of the data.
}
{% Nachteile
The implementation of \COMPmedia{} gets more complex due to corresponding case decisions.
}
%%%% <-- DD %%%%


%%%% DD --> %%%%
\DD{dd:411e}
{% Titel
The user can set the maximum size of the cache per medium, the cache keeps only the newest added data
}
{% Kurzbeschreibung
The user is allowed to limit the maximum size of the cache per medium by configuring it before creating the cache. The cache implementation ensures that at any time, the cache does not contain more bytes than which correspond to the maximum size. This is done using a FIFO (first in, first out) mechanism. I.e. the bytes added first are first discarded whenever trying to add new bytes to a cache.
}
{% Begründung
This way, the user can influence the maximum heap size required for caching of a single medium. At the same time, he needs not control the cache size himself, but it is internally managed by \COMPmedia{}
}.
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%%%% DD --> %%%%
\DD{dd:411f}
{% Titel
Performance drawbacks of \texttt{InputStream}s are explicitly documented
}
{% Kurzbeschreibung
Reducing differences between \texttt{InputStream}s and files by caching in accordance to \DesLink{dd:411b} means: You must deal with the fact that you cannot store virtually unlimited \texttt{InputStream}s in a cache. For file access, the user can also choose between \texttt{FileInputStream} and more direct access via \texttt{RandomAccessFile}s. The performance drawbacks induced by using \texttt{FileInputStream} compared to  random-access \-- which are introduced by a unified API according to \DesLink{dd:411b} \-- are explicity described in the \LibName{} documentation. The mitigation mechanisms (setting maximum cache size, disabling caching) are explicitly described with their corresponding consequences.
}
{% Begründung
There are no wrong expectations by providing the unified API. The contract is described clearly enoughto the user. He must choose the medium best suited for his purpose.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%%%% DD --> %%%%
\DD{dd:411g}
{% Titel
The user cannot free up cache data in a fine-grained way
}
{% Kurzbeschreibung
\COMPmedia{} will not provide any mechanisms for the user to free up cached data himself in a fine-grained way (e.g. range-based).
}
{% Begründung
This functionality needs to be implemented and tested (additional effort). It is quite unlikely that it is actually needed when having implemented \DesLink{dd:411e}. Furthermore, when should the user free the data? A monitoring by the using code is necessary which also makes the using code more complex.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

After these results, the disadvantages previously listed in table \hyperref[tab:CachingProCon]{\ref{tab:CachingProCon}} and in \DesLink{dd:411} need a closing look:
\begin{itemize}
\item Code Complexity: The higher code complexity cannot be disregarded. You have to accept it when implementing a permanent caching. It implies you need very good unit and integration tests to ensure it works as expected.
\item More Heap Memory: It is usual to achieve a better runtime performance by increasing the memory footprint. So it is here. To nevertheless avoid \texttt{OutOfMemoryError}s, we have defined \DesLink{dd:411c} and \DesLink{dd:411e} and thus give enough room for the user to avoid these situations.
\item Data Corruption due to Out-Of-Synch Medium: The cache might receive updates that are not yet persisted on the external medium, as explicitly allowed by  \DesLink{dd:410}. A problem might arise due to changes by other processes or threads. These cannot be handeled in a general way by \LibName{}. Thus we have introduced the locking of media in \DesLink{dd:404}. Even this cannot give a full protection for some OSs. The user is in any case informed about irresolvabe inconsistencies by a runtime exception.
\end{itemize}

Finally, we want to list a design decision rejected during a proof of concept, which was to provide a mechanism of skipping bytes for \texttt{InputStream}s instead of reading them into the cache, here is why:

%%%% DD --> %%%%
\DD{dd:411d}
{% Titel
The \COMPmedia{} API does not provide the option to skip bytes of an \texttt{InputStream} instead of reading them into the cache
}
{% Kurzbeschreibung
It sounds like a good idea to offer the configurable possibility to skip bytes from an \texttt{InputStream} instead of unnecessarily reading them (and put them into a cache). This mainly applies for the case when you are currently at offset $x$, but now you want to read bytes from the stream starting at offset $x+100$. You might never want to access the bytes between $x$ and $x+100$. So it would be worthwile to allow the possibility to simply skip them instead of reading them into memory and into the cache.

However, \texttt{InputStream.skip} is not as straightforward as one could wish. It does not guarantee to skip the number of bytes given, but it might skip fewer bytes or even return a negative number. It might also throw an \texttt{IOException}, which might or might not include the case of reaching the end of medium. Although not specified, there might be the same behavior as for read, that \texttt{InputStream.skip} might block. Furthermore the javadocs specify that it is only supported for streams that support seeking. All in all, this gives the impression that the method is highly platform and implementation-dependent. How to bring this implementation into a reliable form that guarantees to always skip the given number of bytes or block (possibly with timeout)?
}
{% Begründung
It is too complex to implement the method reliably, thus we omit it and only offer the possibility to read ahead until a given offset. All bytes read are possibly read into the cache. However, the cache is ``self-cleaning'' according to \DesLink{dd:411e}, if a maximum size is configured. This mechanism should be sufficient for achieving a moderate heap usage.
}
{% Nachteile
Probably more heap usage and bytes might be unnecessary read and kept in memory.
}
%%%% <-- DD %%%%

Implementing the discussed caching mechanisms is a big challenge. It will be detailed more in the implementation part of this component. Here, we can only exclude one way of implementing it:

%%%% DD --> %%%%
\DD{dd:412}
{% Titel
\texttt{MappedByteBuffer} will not be used to implement caching
}
{% Kurzbeschreibung
You could come with the idea to use the Java NIO class \texttt{MappedByteBuffer} for implementing the caching of \DesLink{dd:411}. However, we do not use it and implement another solution ``by hand''.
}
{% Begründung
It is not guaranteed, that each OS supporting Java also supports a \texttt{MappedByteBuffer}. It is also not guaranteed that the data ``cached'' is really present in RAM and thus accessible faster. Furthermore, it is indicated that for each concecutive region of a medium a new \texttt{MappedByteBuffer} instance including new OS call would need to be created. Thus this approach is unpredictable and might lack the desired benefits.
}
{% Nachteile
The ``by hand'' caching is harder to implement.
}
%%%% <-- DD %%%%

At the end we shortly list a special case of caching for byte array media:
%%%% DD --> %%%%
\DD{dd:412a}
{% Titel
For byte array media, caching is always disabled
}
{% Kurzbeschreibung
For byte array media, caching is always disabled
}
{% Begründung
byte arrays already are in RAM, caching would just be unncessary overhead
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%


% -------------------------------------------------------------------------------------------------------
\subsubsection{Reading Access to the Medium}%
\label{sec:LesenderZugriffaufdasMedium}%

The two-stage write protocol introduced in \SectionLink{sec:GrundSchreiben} brings up some questions regarding reading the data. The most important among these: What does the user need to consider after calling a writing operation (stage 1) and before \emph{flush}ing these changes (stage 2)? Especially: What do reading calls return after already having made changes, that are however not yet \emph{flush}ed? The possibilities we have:
\begin{enumerate}
\item Either the last persisted state on the medium after opening it or the last successful \emph{flush}, respectively,
\item Or already a state the includes any ``pending'' changes introduced by writing calls before the \emph{flush}?
\end{enumerate}
 
You could base your answer on the following: For sure alternative (2), as it is this way that e.g. transactions mostly work for code accessing databases. What you have already written during the transaction, you re-read later, too, even if the transaction is not yet persisted. However, the view of \LibName{} is different:

%%%% DD --> %%%%
\DD{dd:410c}
{% Titel
The user can only read what is currently persisted on the medium
}
{% Kurzbeschreibung
Even if there are pending changes not yet \emph{flush}ed (e.g. inserts, removes), with \COMPmedia{} the user can only see the latest flushed state.
}
{% Begründung
The changes the user has registered are coming form the user, and he thus could potentially keep bookmarks of them. Therefore their sole management by \COMPmedia{} is - at this point in time - not strictly necessary. Furthermore it must still be possible to read the data of a datablock that is threatened by a pending remove. 

Another good reason for this behaviour is that  the reading operations are much less complex, as they do not need to consider any pending changes. The code that reads data can be sure to always only work on a persistent (or at least a cached) state. Thus it cannot occur that logic is basing on data that is not yet persisted.
}
{% Nachteile
The expectation that ``what I have written before - even if pending - I can re-read afterwards'' is not fulfilled. The user must manage this for changed data by himself, at least temporarily until the next flush. 
}
%%%% <-- DD %%%%

In \SectionLink{sec:PerfMedia}, caching has been discussed in detail. For buffering, we first need an operation to do buffering without actually returning the buffered data:
%%%% DD --> %%%%
\DD{dd:412b}
{% Titel
Explicit operation for buffering of media data
}
{% Kurzbeschreibung
There is an operation \emph{cache} which buffers $n$ data bytes starting at a given offset, without returning this data. Additionally, there is an operation to query the number of bytes buffered concecutively starting at a given offset. Of course, this might lead to an ``end of medium'' situation indicated by the method to the caller.
}
{% Begründung
Necessary for implementing \DesLink{dd:409}. Of course one could ask: Why isn't it sufficient to just provide a single \texttt{getData} operation that returns data, either from the cache or from the medium. If the data was not yet in cache, it also adds it to the cache. The reason is: The code might not want the bytes yet! It just wants to give a statement like ``At this point in time, I know how much bytes I might need to read later, so please already buffer them. But do not give the bytes to me, because at this point in the code I cannot really use them and it would complicate my code strucutre.'' For instance, if only providing one method returning the data, the code must pass the read data as parameter to other methods to read it. Instead of doing this, the code can just buffer the needed number of bytes, then call other code to get just the data it needs without needing to fiddle keeping track of the last read byte.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Additionally, you must be able to get your hands at the buffered data:
%%%% DD --> %%%%
\DD{dd:412c}
{% Titel
Explicit operation to get medium bytes
}
{% Kurzbeschreibung
There is an operation \emph{getData} which returns $n$ data bytes starting at a given offset.
}
{% Begründung
Without it there would not be any possibility to read data from a medium, as \emph{cache} only buffers it internally without returning it.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Now the question arises, how the operation \emph{getData} interacts with the cache, which is answered here:
%%%% DD --> %%%%
\DD{dd:412d}
{% Titel
\emph{getData} combines data from the cache with data form the medium and updates the cache thereby, if necessary
}
{% Kurzbeschreibung
\emph{getData} reads data from the cache, if the given range is entirely contained in it. Is it not entirely contained in the cache, \emph{getData} reads the bytes present in the cache, and reads the non-present ones from the medium, adding it to the cache afterwards. Thus data is combined from the two sources.
}
{% Begründung
To ensure efficient reading, \emph{getData} can be used as such to fetch data from the cache, if anyhow possible. Only if there is at leaast one byte not in the cache, the medium must be accessed directly. Updating the cache by read data is useful, to ensure later calls to query the same data can fully leverage the cache and do not need another access to the external medium.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Should we provide a way to force medium access when getting data?
%%%% DD --> %%%%
\DD{dd:412da}
{% Titel
\emph{getData} provides no specific mode or configuration to ignore the cache and always read from the medium
}
{% Kurzbeschreibung
\emph{getData} does not provide a forced read mechanism, but it always only reads data from the external medium that it cannot find in the cache.
}
{% Begründung
It is not clear when using code should use the forced or the unforced mode. If the using code somehow can magically see that the underlying medium was changed by other processes, it could do a forced direct read. But in this case, everything is lost already, because you can never know what the other process did. A better way to ensure integrity and consistency would be for the using code to close the medium and reopen another access instance.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

We want to define now how the read media data is represented:
%%%% DD --> %%%%
\DD{dd:412e}
{% Titel
Read media data is represented as read-only \texttt{ByteBuffer}
}
{% Kurzbeschreibung
Read data is not returned in the form of \texttt{byte} arrays, but as \texttt{ByteBuffer} instances that are read-only.
}
{% Begründung
Firstly, users can directly gain profit from conversion functions offered by \texttt{ByteBuffer}, on the other hand the implementation is more flexible when it comes to the content of the \texttt{ByteBuffer}, as only the bytes between \texttt{position()} and \texttt{limit()} can be read. Using this e.g. an internally managed, much bigger \texttt{ByteBuffer} object can be returned as a read-only view instead of copying it.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

For efficiency reasons, we define the following:
%%%% DD --> %%%%
\DD{dd:412f}
{% Titel
Handle reading from a single already cached region or a size smaller than the maximum read-write block size as special case
}
{% Kurzbeschreibung
If a read offset and size for \emph{getData} is exactly hitting a single cache region, and this single region fully contains the range to read, the \texttt{ByteBuffer} corresponding to this region with adapted position and limit is returned instead of allocating a new \texttt{ByteBuffer} and copying bytes, which will happen in any other case. Similarly, if a range is not cached and needs to be read, and if the range's size is below the maximum read-write block size, again no copying happens, but the read \texttt{ByteBuffer} is directly returned.
}
{% Begründung
The case of an already cached region fully covering the range to read can be considered as at least the use case covering 80\% of the typical uses. The reason is: Usually, the users should use cached media. And usually, they should call \emph{cache} before \emph{getData}, covering e.g. a whole header. Thus, reading individual fields later with \texttt{getData} will always hit the cache. Thus, for this 80\% case, we could optimize the library performance a lot by simply not copying.
}
{% Nachteile
Slightly more complexity and testing effort involved
}
%%%% <-- DD %%%%

Let's discuss the topic of timeouts. In Java, each reading and writing I/O call might block. How to deal with this? The following design decision clearly states it.

%%%% DD --> %%%%
\DD{dd:426}
{% Titel
\LibName{} does not support any timeouts, neither reading nor writing
}
{% Kurzbeschreibung
\COMPmedia{} does not offer the possibility to configure timeouts for any reading or writing actions, and likewise, it does not implement any measures to prevent these actions from blocking arbitrarily long
}
{% Begründung
Both for file or stream access, read and write operations, including determining where we are or truncation might or might not block. This is - unfortunately - OS and implementation dependent and cannot be predicted. It is possible and was tried to implement a parallel thread to execute the action against the medium and the main thread to monitor the time taken by the other thread and retrieve the result after a given timeout. While this is easily possible using Java's \texttt{Future}s, it is not so easy to really terminate the blocking action and its thread. In reality, on some OSs the action is really interruptible, on others it is not. This might also depend on the implementation. Thus, \LibName{} won't implement anything that would try to convince the user it can actually do it, leading also to increased complexity. Instead, the user must use his own mechanisms, i.e. an own custom \texttt{InputStream} implementation, using multithreading and monitoring of calls from the outside, or using implementation-specific timeouts such as for \texttt{SocketInputStream}.

Furthermore, it is also problematic what state the medium is in after the timeout was detected. What shall the library or the user do with this implementation? Retry, fail, close and retry? There is not always an easy answer to it.
}
{% Nachteile
Users might need to write more custom code themselves, if they strictly require this for mediums they use.
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------
%		API Layer Design
%-----------------------------------------------------------------------------------------------

\subsection{API Design}
\label{sec:InterfaceDesignCOMPmedia}

On the basis of the design decisions made in the previous section, we can now develop an API design for the component \COMPmedia{}. The API is the public interface of the component, i.e. all classes that can be used by other components to access the \COMPmedia{} functionality.

%-----------------------------------------------------------------------------------------------

\subsubsection{Reprasentation of a  \TERMmedium{}}
\label{sec:RepraesentationEinesTERMmedium}

The medium has appeared a lot of times already as a term, thus a representation as a class makes sense.

%%%% DD --> %%%%
\DD{dd:413}
{% Titel
Media are represented as interface and implementation class with following properties
}
{% Kurzbeschreibung
A medium is represented as Java interface \IMedium{} and allows users of \LibName{} to specify a concrete physical medium (i.e. the implementations of the interface \IMedium{}). As implementations we support a \FileMedium{} according to \DesLink{dd:400}, according to \DesLink{dd:401} aan \InputStreamMedium{} and according to \DesLink{dd:402} a \InMemoryMedium{}.

A medium has the following properties:
\begin{itemize}
	\item Is random-access: Yes/No \-- \textbf{Motivation:} This property has strong impact on the read and write process, yet it is an intrinsic property of the \TERMmedium{} itself and not of the access mechanism. Thus it is directly available for at a \TERMmedium{}.
	\item Read-only: Yes/No \-- \textbf{Motivation:} This property disables writing in practice if set to ``Yes''. Some \TERMmedia{} can never be written (e.g. \texttt{InputStream}s), for others it is possible. This flag shall be used to also give the \LibName{} user a possibility to signal he wants to only access read-only.
	\item Current lenght in bytes (only relevant for random-access) \-- \textbf{Motivation:} Java offers queries for each kind of \IMedium{} except \texttt{InputStream}. Thus this should be implemented directly in the \IMedium{} implementation. For \texttt{InputStream} and non-random-access media in general, terms like length to not make much sense. Thus here there is no value, but a constant indicating an unknown length. In spirit pf design decision \DesLink{dd:410}, it is a currently persisted lenght and not a length including any not-yet persisted changes.
	\item A clear text name of the \TERMmedium{} \-- \textbf{Motivation:} This is helpful for identification purposes of the \IMedium{} e.g. in log output. It can be derived from e.g. a file name, depending on the medium type.
	\item The ``wrapped'' object representing the raw medium or its access mechanism, e.g. the file, the \texttt{InputStream} or the byte array.
\end{itemize}
}
{% Begründung
It can be controlled in detail which medium types are supported. The user can specify the medium to use in a comfortable way. Further API parts get more easier, as their interfaces must not distinguish between different media types, but rather only use the abstaction that \IMedium{} offers. Motivation for each of the properties see the listing above.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Due to consistency reasons there are some restrictions regarding the manipulation of media properties:

%%%% DD --> %%%%
\DD{dd:414}
{% Titel
If a \IMedium{} implementation is writable, it must also be random-access
}
{% Kurzbeschreibung
Every in principle writable \IMedium{} implementation must be random-access, too. 
}
{% Begründung
The \LibName{} APIs for writing content can thus concentrate on random-access output media. No separate API design and implementation for output media that are not random-access is necessary. The API gets easier for end-users. Lack of non-random-access output media such as \texttt{OutputStream}s can be mitigated via the examples in \DesLink{dd:403}.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Here is a very importante note for byte array media:
%%%% DD --> %%%%
\DD{dd:414b}
{% Titel
For byte array media, a writing method for resetting the whole byte array is necessary
}
{% Kurzbeschreibung
The user can reset the bytes of the medium via a public method \texttt{setBytes} of class \InMemoryMedium{}.
}
{% Begründung
It is mostly not harmful to offer the method as public, it is even an advantage for the users, as he can set the bytes himself. Only between registering write operations and a flush, this call leads to unexpected behaviour.

This methode is very important for the implementation: Via writing actions, the byte array must be extended or shrinked in some situations. This basically means reacreating and copying the array. The method must thus be public, as the corresponding implementation funcitonality will be for sure placed in another package.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{Positions in and Lengths of a \TERMmedium{}}
\label{sec:PositiZugriffEinesTERMmedium}

In each case where dare is read from or written to a \TERMmedium{}, the question ``where?'' arises. Usually libraries use integer or long variables to represent offsets. It must be said however: Offsets do not only make sense for random-access media. You could also interpret them as offset since start of reading from an \texttt{InputStream}, which is actually the way it is done in \LibName{}. We decide:

%%%% DD --> %%%%
\DD{dd:415}
{% Titel
Byte offsets are used for any kind of \TERMmedia{}
}
{% Kurzbeschreibung
Byte offsets that refer to a position on a \TERMmedium{} are used for all media types: random-access and non-random-access. For byte streams they refer to the position of the current byte since start of reading the first byte after opening the stream, which has offset 0. The offset-based reading is simulated as specified in \DesLink{dd:407} and \DesLink{dd:411b}, because when directly reading from an \texttt{InputStream} via Java API, offsets are not needed, it is always read from the current position of the stream. 
}
{% Begründung
We must therefore distinguish between random-access and non-random-access only at a few places in the implementation. Users can use the API uniformly and irrespective of the actual medium type (with restrictions: see \DesLink{dd:411e}).
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

It makes not so much sense to represent offsets only via a primitve data type. Instead, the representation as a user-defined data type offers some advantages:

%%%% DD --> %%%%
\DD{dd:416}
{% Titel
\LibName{} uses the interface \IMediumReference{} to represent offsets on a \TERMmedium{}.
}
{% Kurzbeschreibung
The interface binds both the \TERMmedium{} and the offset on this \TERMmedium{} together, and thus is a kind of ``global'' address of a byte. Next to reading medium and of offset, it offers some helper methods:
\begin{itemize}
\item \texttt{behindOrEqual:} Returns true if another \IMediumReference{} is located on the same medium behind of at the same position as this instance.
\item \texttt{before:} Returns true if another \IMediumReference{} is located on the same medium before the position of this instance.
\item \texttt{advance:} Creates a new \IMediumReference{} that is located by the given byte number before (negative argument) or after (positive argument) this instance.
\end{itemize}
}
{% Begründung
We clearly state how the library deals with offsets. We can thus implement some helper functions into the datatype (e.g. validation, offset comparison, advance etc.) which ensure reuse and ease working with offsets in general.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Now we come to a central decision when it comes to dealing with lengths and offsets:

%%%% DD --> %%%%
\DD{dd:417}
{% Titel
\LibName{} uses long for length and offset specifications, byte is always its unit
}
{% Kurzbeschreibung
In \LibName{}, lenghts and offsets are always specified using the Java datatyp long. The lenght is in any case the number of bytes, offsets are zero-based, linearly increasing byte offsets.
}
{% Begründung
This guarantees uniformity. However, we also want to meet the requirement \SectionLink{sec:ANF009LesenSchreibenGrosse}. Integer with a maximum of 4.3 GB is already too limited, which leaves only long as a viable option. The datatype long allows for positive numbers up to $2^{63}-1=9223372036854775807$, i.e. approximately $9\cdot 10^{18}$ bytes, which is 9 exabytes or 9 billion gigabytes. From current point of view, such lenghts and offsets for input media, even for streams, should be sufficient for some decades to come. Furthermore, big data chunks are almost in any case subdivided in small units that can be easier handled, and these small units will not have big lengths. Even the Java file I/O uses long as offset and length datatype in most cases.
}
{% Nachteile
More memory for saving offsets and lengths is necessary. If we look at the development of storage media, storage needs and processing speed it might be that in 100 years the maximum data volume of long will be reached. If \LibName{} is still used in these future scenarios, a change request would be worth it!
}
%%%% <-- DD %%%%

A rather seldom special case is dealt with in the following design decision:

%%%% DD --> %%%%
\DD{dd:418}
{% Titel
No special handling of long overflows
}
{% Kurzbeschreibung
For unusal long uninterrupted reading from \texttt{InputStream} you could think that even when using long, it could come to an overflow in some time. This is however very unlikely, thus this case is not treated. The implementation always assumes taht the current offset is positive and can be incremented without reaching the max long number.
}
{% Begründung
Even here it holds true: The datatype long allows positive numbers up to $2^{63}-1=9223372036854775807$. Let us assume that an implementation could make it to process 10 GB per second, then it would still need 9 billion seconds, i.e. nearly 30 years, to reach the offset limit and create an overflow.
}
{% Nachteile
No disadvantages knownn
}
%%%% <-- DD %%%%

Now the problem arises that the medium changes due to writing access. How do the offsets change in this case? Is it necessary to update already created \IMediumReference{} instances according to the changes on the mediums, or not? If yes, when this needs to happen? In principle, we could see following alternatives:
\begin{enumerate}
\item Never update already created \IMediumReference{} instances
\item Update already created \IMediumReference{} instances directly for each pending change registered (see \DesLink{dd:410})
\item Update already created \IMediumReference{} instances only when an explicit \emph{flush} according to \DesLink{dd:410} occurs
\end{enumerate}

Assume that \IMediumReference{} instances are not updated when writing. That means the user code remembers a position of an element in form of a \IMediumReference{} instance, and uses it to read or write data. If e.g. an inseration operation takes place on the medium before the offset of the \IMediumReference{} instance, then the instance refers to another data byte than before, and thus not anymore to the object it was referring to initially. We should not only think of raw bytes but - as necessary for data formats - \emph{objects}, i.e. parts of the binary data that form a specific unit with which has a specific meaning, representing something. Then failure to update the offset is fatal. Code using \COMPmedia{} locates an object at the wrong place if the medium changed before that offset meanwhile.

To formulate the following design decision a bit easier, the vague term of ``Object'' used above is now defined a bit sharper: An object is a consecutive byte unit starting at aspecific offset $x$ and it has a length of $n$ bytes. \texttt{remove}, \texttt{insert} and \texttt{replace} in the offset interval $[x,x+n]$ change these objects, which cannot be in any case specifically treated by \COMPmedia{}.

%%%% DD --> %%%%
\DD{dd:418b}
{% Titel
\COMPmedia{} needs to automatically update \IMediumReference{} instances after medium changes
}
{% Kurzbeschreibung
All \IMediumReference{} instances ever created for a medium must be updated automatically whenever this medium changes. The kind of update needed is more complex than you would think on first glance. 

Let $y$ be the insert or remove offset and $k$ the number of bytes to insert or remove. Let $\overline{x}$ be the offset of the \IMediumReference{} instance after updating. Then the following detailed rules apply:
\begin{itemize}
\item \emph{\texttt{insert} before the object start offset:} Is $y\leq x$, then $\overline{x}:=x+k$. I.e. this includes the case that new bytes are inserted exactly at offset $x$.
\item \emph{\texttt{insert} behind the object start offset:} Is $y>x$, then $\overline{x}:=x$, i.e. it does not change the start offset of the object, and this even in the case that $y<x+n$, i.e. the action happens \emph{within} the object. If and how this changes the object semantically is lying in the hands of the user and cannot be recognized or interpreted by \LibName{}.
\item \emph{\texttt{remove} before the object start offset without overlap:} Is $y+k \leq x$, then $\overline{x}:=x-k$. Thus $k$ bytes are removed before the object, however the removed region does not overlap with the object.
\item \emph{\texttt{remove} before the object start offset with overlap:} Is $y \leq x$, but $y+k > x$, then the removed region overlaps the object. It is thus a \emph{truncation} of the object starting at front, and it might even reduce the object to length 0. Thus the start offset of the object shifts $x-y$ to be equal to $y$, thus it follows that $\overline{x}:=y$. If and how this changes the object semantically is lying in the hands of the user and cannot be recognized or interpreted by \LibName{}.
\item \emph{\texttt{remove} behind the object start offset:} Is $y>x$, then $\overline{x}:=x$, i.e. the object start offset remains unchanged, of course also in the case that $y<x+n$. In the latter case, however, the object is truncated at its end. If and how this changes the object semantically is lying in the hands of the user and cannot be recognized or interpreted by \LibName{}.
\item \emph{\texttt{replace}:} Replacing $n$ bytes by $m>n$ bytes has the same effect to existing objects as an \texttt{insert}, with the very same case distinctions. Likewise, \texttt{replace} behaves like \texttt{remove} if $m<n$. The case $m=n$, i.e. an \emph{overwrite} operation does not lead to any offset changes of existing objects.
\end{itemize}
}
{% Begründung
The connection between an \IMediumReference{} instance and an object is a viable picture and quite illustrates the real use case behind manipulating raw binary data. Due to this design decision, this connection persists - from point of view of the caller - even in case of writing changes to the medium. We cannot burden the user with keeping track of these changes as he would need to manage \IMediumReference{} himself in a complex way, listing which operations he has done. This complex book-keeping is what you would expec from a component such as \COMPmedia{}.

If all bytes of the object are removed, then the \IMediumReference{} instance still refers to the ``previous'' location of the object. The user must not ensure that the \IMediumReference{} instance still refers to the same object.
}
{% Nachteile
A central management of \IMediumReference{} instances must be implemented (see \DesLink{dd:419}).
}
%%%% <-- DD %%%%

As already indicated by \DesLink{dd:418b} the automatic updating of already created \IMediumReference{} instances requires that only \COMPmedia{} may create \IMediumReference{} instances. These must be managed in a kind of pool to be able to automatically update them in case of writing operations.

%%%% DD --> %%%%
\DD{dd:419}
{% Titel
\IMediumReference{} instances are centrally managed by \COMPmedia{} and cannot be directly created by users of the component
}
{% Kurzbeschreibung
The lifecycle of \IMediumReference{} instances is controlled by \COMPmedia{}. They are created and returned to the user via a factory method.
}
{% Begründung
It is strictly required to implement \DesLink{dd:418b}. Instances that have been created by the user cannot be update automatically, thus we have to ensure the manual creation by the user does not happen.
}
{% Nachteile
More complex instantiation of \IMediumReference{} instances.
}
%%%% <-- DD %%%%

The question \emph{when} to update \IMediumReference{} instances has still not been answered yet. The following design decision clearly defines this:

%%%% DD --> %%%%
\DD{dd:419b}
{% Titel
\IMediumReference{} instances are only updated after a \emph{flush}
}
{% Kurzbeschreibung
According to \DesLink{dd:418} \IMediumReference{} instances are automatically updated in case of medium changes. This automatic update only happens at \emph{flush} time.
}
{% Begründung
Assumed that \IMediumReference{} instances would already be updated whenever a pending change is registered using \emph{insert}, \emph{replace} or \emph{remove}. In this case the following would be necessary:
\begin{itemize}
\item When reading data, this data is not necessarily in a cache. This indicates that reading from external medium is necessary. If all \IMediumReference{} instances would reflect a state including any pending changes, they would no longer correspond to the state of the external medium. If you would now want to read or write to the external medium, the real offset on the external medium would need to be ``reconstructed'' based on the changes made so far, everytime you want to know where current data resides on the medium. This implies a complex coding overhead that would not ease debugging errors or understanding the current state of instances.
\item The operation \texttt{undo} according to \DesLink{dd:420} requires that offsets would need to be ``re-adapted'' if a pending changes is undone again. Again this is additional complexity.
\end{itemize}
If \IMediumReference{} instances in contrast are first updated after a \emph{flush}, then no reconstruction of original offsets based on already made changes is necessary.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

This directly implies the following design decision:

%%%% DD --> %%%%
\DD{dd:421}
{% Titel
In \COMPmedia{}, offset specifications always are offsets on the external medium as it was looking like after the last \emph{flush} or after opening it initially
}
{% Kurzbeschreibung
For operations of \COMPmedia{} that take an offset as argument, this offset refers to a location on the external \TERMmedium{} after the last \emph{flush} or the initial opening - in case no \emph{flush} has occurred yet. These offsets must especially be located within the interval $[0, \text{length}]$, where ``length'' is the current length of the medium in bytes.
}
{% Begründung
Naturally follows from \DesLink{dd:419b}. For users, the offset situation remains stable and logical, he does not need to maintain a history of \emph{insert}, \emph{replace} and \emph{remove} operations. Likewise, the offsets stay stable for the implementation, too: Checking offsets and organisation of internal data structures can be based on this invariant.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{Semantic of Writing Operations}
\label{sec:SemantikSchreib}

In \DesLink{dd:410d}, we have defined the primitive writing operations \emph{insert}, \emph{replace} and \emph{remove} that are essential for \COMPmedia{}. In the same section, we have listed basic requirements for writing that lead to these operations. The API of \COMPmedia{} includes their guaranteed behavior. It is very important to define interrelations between these operations, especially how they behave for overlapping offset areas of the medium. These things are defined by the following design decisions. The behaviors are part of the API contract and must be documented as such for the API users.

We start with the operation \emph{insert}:

%%%% DD --> %%%%
\DD{dd:422}
{% Titel
\emph{insert} concatenates insertions in call order, the operation is not influenced by any other writing operations
}
{% Kurzbeschreibung
The temporal order of calls have the following semantics:
\begin{enumerate}
\item Step 1: \emph{insert}, Step 2: \emph{insert} at the same offset: \emph{insert} concats, each call with the same offset determines a new, consecutive insertion, i.e. insertions at the same medium location are done with increasing offsets. Let's take two calls to \emph{insert} at the same offset $x$. Let ``Call 1'' be the earlier call with insertion length $n_1$, ``Call 2'' the later call at $x$ with insertion length $n_2$. The end result on the medium after \emph{flush} is:
\begin{itemize}
\item At offset $x$, the insertion data of ``Call 1'' is located
\item At offset $x+n_2$, the insertion data of ``Call 2'' is located
\end{itemize}
\item Step 1: \emph{insert}, Step 2: \emph{remove} at same offset: Do not influence each other.
\item Step 1: \emph{insert}, Step 2: \emph{replace} at same offset: Do not influence each other.
\item Step 1: \emph{insert} at offset $x$, Step 2: \emph{replace} $m$ bytes by $n$, starting at offset $y$, where $x>y+m$, i.e. the insertion does not happen within the replacement region, but behind: These operations do not influence each other. This includes the case that $m>n$, i.e. an override operation with a removal, and $x\in[y,y+m)$, i.e. the insertion does not happen within the replacement region, but behind.
\item Step 1: \emph{insert} at offset $x$, Step 2: \emph{replace} $m$ bytes by an arbitrary number of new bytes, starting at offset $y$, where $x\in (y,y+m)$: Put in other words, the bytes to replace contain the prior insertion. Here, the second call is invalid and rejected with an exception.
\item Step 1: \emph{insert} at offset $x$, Step 2: \emph{insert} at offset $y\neq x$: Do not influence each other.
\end{enumerate}
}
{% Begründung
For (1): You could alternatively interpret ``insert'' as such that the second call inserts data \emph{before} the previous earlier one. However, the design decision says that ``insert'' inserts before the currently persisted medium byte at the insertion offset. Concatenating allows user code to linearly insert stuff with increasing offsets, which is in most cases the convenient and expected behavior. For (2), (3) and (4): As offsets refer to offsets on the external medium according to \DesLink{dd:410b}, \emph{remove} and \emph{replace} only affect bytes that are currently persisted on the external medium, they thus cannot remove any pending content of a prior \emph{insert} not yet \emph{flush}ed. For (5): Otherwise complex logic is necessary to mix insertion bytes into replacement bytes. The user can achieve the same by simply including the insertion bytes in the replacement bytes starting at offset $y$.
}
{% Nachteile
For (1): You could alternatively interpret ``insert'' as such that the second call inserts data \emph{before} the previous earlier one. However, the design decision says that ``insert'' inserts before the currently persisted medium byte at the insertion offset. With concatenating, user code can linearly insert stuff with increasing offsets, which is mostly the expected behavior.
}
%%%% <-- DD %%%%

The operation \emph{remove} behaves as follows:

%%%% DD --> %%%%
\DD{dd:424}
{% Titel
\emph{remove} allows no overlaps, only later calls with bigger region make earlier calls obsolete
}
{% Kurzbeschreibung
The following temporal order of calls have the described semantics:
\begin{enumerate}
\item Step 1: \emph{remove} $n$ bytes at offset $x$, Step 2: \emph{remove} or \emph{replace} $m$ bytes at offset $y\leq x$ with $y+m\geq x+n$: When calling \emph{remove} twice or first \emph{remove}, then \emph{replace}, where the second call fully contains the offset region of the first, the earlier call is declared as invalid and is not processed during a \emph{flush}. Of course this is also true for all earlier calls, not only the last one.
\item Step 1: \emph{remove} $n$ bytes at offset $x$, Step 2: \emph{remove} or \emph{replace} $m$ bytes at offset $y\in (x,x+n)$ with $y+m<x+n$: The first call fully contains the region of the second call. The second call is invalid and rejected with an exception.
\item Step 1: \emph{remove} $n$ bytes at offset $x$, Step 2: \emph{remove} or \emph{replace} $m$ bytes at offset $y\in (x,x+n)$ with $y+m\geq x+n$: The second call is an overlapping call, that probably removes additional bytes behind the first remove call, but still includes the end of the first call. The second call is invalid and rejected with an exception.
\item Step 1: \emph{remove} $n$ bytes at offset $x$, Step 2: \emph{remove} or \emph{replace} $m$ bytes at offset $y \leq x$ with $y+m<x+n$: In this case there is an overlap from the start. The second call is invalid and rejected with an exception.
\item Step 1: \emph{remove} $n$ bytes at offset $x$, Step 2: \emph{insert} at offset $y\in [x,x+n)$: As the insert call according to \DesLink{dd:410b} refers to offsets on the external medium, here first $n$ bytes present on the medium are removed, then the new bytes are inserted after the last byte persisted, i.e. at offset $x$.
\item Step 1: \emph{remove} $n$ bytes at offset $x$, Step 2: \emph{remove} or \emph{replace} at offset $y$ without any overlaps to $[x,x+n)$: Do not influence each other.
\end{enumerate}
}
{% Begründung
There are no accidental multiple removals or replaces. For (1): It may happen that the user first removes a chield field, and additionally still before the flush \texttt{flush}, he removes the parent block. For (2) to (4): Would we allow the second calls, we would need to change the remove areas of the first calls. This leads to a more complex logic, that is not necessary according to the requirements stated in \SectionLink{sec:AnforderungenandaszweistufigeSchreibprotokoll}. A very important reason to not allow this is implementation of \texttt{undo}: Would we allow later changes of already made calls, then \texttt{undo} would be quite complex, because it would need to also undo such changes to removed regions, what basically means keeping a history of all changes made for the same region.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

The operation \emph{replace} behaves like this:

%%%% DD --> %%%%
\DD{dd:424a}
{% Titel
\emph{replace} does not allow overlaps, only later calls with bigger reagions make earlier calls obsolete
}
{% Kurzbeschreibung
The behaviour of \emph{replace} mostly matches the behavior of \emph{remove}, as described in cases 1 to 4 of \DesLink{dd:424}. You only have to replace \emph{remove} by \emph{replace} in the description of \DesLink{dd:424} :-). \emph{replace} interacts with an insert the same way as described in \DesLink{dd:422} for the inverse order which are cases 5 to 7:
\begin{enumerate}
\item[1.] to 4. Exactly the same as described in \DesLink{dd:424} with \emph{replace} as first step.
\item[5.] Step 1: \emph{replace}, Step 2: \emph{insert} at the same offset: These operations do not influence each other.
\item[6.] Step 1: \emph{replace} $m$ bytes by $n$, starting at offset $y$, Step 2: \emph{insert} at offset $x$, where $x>y+m$, i.e. the insertion does not happen within the replacement region, but behind: These operations do not influence each other. This includes the case that $m>n$, i.e. an override operation with a removal, and $x\in[y,y+m)$, i.e. the insertion does not happen within the replacement region, but behind.
\item[7.] Step 1: \emph{replace} $m$ bytes by an arbitrary number of new bytes, starting at offset $y$, Step 2: \emph{insert} at offset $x$, where $x\in (y,y+m)$: Put in other words, the bytes to replace contain the later insertion. Here, the second call is invalid and rejected with an exception.
\item[8.] Step 1: \emph{replace} at offset $x$, Step 2: \emph{remove} or \emph{replace} at offset $y$ without any overlaps: Do not influence each other.
\end{enumerate}
}
{% Begründung
See \DesLink{dd:422}, cases 1 to 4 and \DesLink{dd:422}, cases 3 to 5
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Another problem: How to map the actual data to a data block before a \emph{flush}? The offset alone is not unique anymore in the face of multiple \emph{insert}s at the same offset before their \emph{flush}. If you now want to relate an action (\emph{insert}, \emph{remove}, \emph{replace}) data to its (current or future) offset, the offset alone is not sufficient to state clearly which action happened first at the offset.

An answer is given in the following design decision that explains how action, data and offset are brought into close relation:
%%%% DD --> %%%%
\DD{dd:424b}
{% Titel
Each of the writing operations returns an instance of a class \MediumAction{} to describe the action in more detail
}
{% Kurzbeschreibung
This class contains following data:
\begin{itemize}
\item The kind of action (\emph{insert}, \emph{replace}, \emph{remove}); \textbf{Motivation:} The user must be able to know the kind of change
\item \IMediumReference{} of the action; \textbf{Motivation:} It must be clear where the change happened or must happen
\item Data of the action (length or bytes to write); \textbf{Motivation:} It must be clear what needs to be changed.
\item Number of actually affected medium bytes (0 for \emph{insert}, number of bytes to remove for \emph{remove}, number of bytes to replace for \emph{replace}; \textbf{Motivation:} For \texttt{replace} only one length is not enough as the number of bytes to replace may be different from the length of the replacement bytes.
\item Validty: Handle is already persisted by a \emph{flush} or still pending; \textbf{Motivation:} Thus it can be clearly state from outside whether the data must still be persisted and thus must be taken from the instance of the user requires to read them, or the data has already been written to the external medium.
\end{itemize}
}
{% Begründung
According to \DesLink{dd:410c}, the user can only read data that is currently persisted.

Nevertheless it is necessary that application code can also re-read data previously registered for writing, but not yet persisted by a \emph{flush}. That now becomes possible with the \MediumAction{} class that is returned by \emph{insert}, \emph{replace} and \emph{remove}. Is the \MediumAction{} still pending, the application code can return the pending bytes from the \MediumAction{}, otherwise by directly accessing the  \COMPmedia{} read functionality to fetch the currently persisted bytes.

Instances of \MediumAction{} can ideally be used for internal data management by \COMPmedia{}.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{End medium access}
\label{sec:ZugriffEinesTERMmediumBEEN}

We still need an operation to end the medium access, thus we define:
%%%% DD --> %%%%
\DD{dd:419ac}
{% Titel
Operation \emph{close} ends the medium access and empties the cache, consecutive operations are not possible on the medium
}
{% Kurzbeschreibung
A user can manually end medium access by calling \emph{close}. It is then no longer possible to access the medium via the closed access way. The user must explicitly reopen the medium to access it again.
}
{% Begründung
The implementation works with OS resources such as files that must be closed. Furthermore cache content and other memory is not freed anytime if you could not close the medium.

Closing cannot be implemented automatically but must be explicity called by the user.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{The public API of medium access}
\label{sec:ZugriffEinesTERMmedium}

Based on the previous design decisions we now design the public API of the component \COMPmedia{}. Until now, we only introduced the classes \IMediumReference{}, \IMedium{} and \MediumAction{} as well as some abstract operations to deal with media. How do we offer these operations to users? This is explained by the following design decision.

%%%% DD --> %%%%
\DD{dd:419c}
{% Titel
Access to a medium is done using the \IMediumStore{} 
}
{% Kurzbeschreibung
The reading and writing access to a medium (both random-access as well as byte stream according to \DesLink{dd:407}) is offered via interface \IMediumStore{} with the operations listed in table \hyperref[tab:MediaOps]{\ref{tab:MediaOps}}.
}
{% Begründung
A further subdivision of functionality into more than one interface is neither necessary nor helpful. It would just be an unneccessary complex API, and despite the single interface, the implementation can still be modularized as needed. The individual operations are motivated in the table itself.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

\small
\begin{landscape}
\begin{longtable}{|p{0.2\linewidth}|p{0.25\linewidth}|p{0.25\linewidth}|p{0.25\linewidth}|}
	\hline
	\rowcolor[gray]{.9}\textbf{Operation} & \textbf{Description} & \textbf{Features and motivation random-access} & \textbf{Features and motivation \texttt{InputStream}} \\
	\endhead
	\hline
	\texttt{cache(x, n)} & Buffers $n$ bytes according to \DesLink{dd:409} and \DesLink{dd:412b} permanently in the internal cache, starting at the given offset $x$. If caching is disabled (specifically for byte array media, see \DesLink{dd:412a}), this call is ignored. The method might reach the end of medium which it signals as an exception. & User code can prefetch data to work on it later, he himself gets the possibility to efficiently read and process data. & If $x$ is bigger than the last read end position, the bytes up to the new offset are read and possibly cached. If $x$ is smaller instead, a \texttt{InvalidMediumReferenceException} is thrown. The last read end position is advanced correspondingly. \\
	\hline
	\texttt{getCachedByteCountAt(x)} & According to \DesLink{dd:409} and \DesLink{dd:412b}, it provides the number of bytes that are consecutively cached at offset $x$. & See \texttt{cache}. User (and test) code must be able to additionally check whether enough data is already buffered or not. & See random-access.\\
	\hline
	\texttt{getMedium()} & Returns the \IMedium{} instance this \IMediumStore{} is associated with. &  & \\
	\hline
    	\texttt{getData(x, n)} & Reads $n$ bytes at offset $x$ according to \DesLink{dd:410c}, \DesLink{dd:412c}, \DesLink{dd:412d}. & Calls \texttt{cache} to ensure all bytes are cached, then returns the data in a consolidated \texttt{ByteBuffer}. & Same as for random-access media. This indicates that this method also might throw an \texttt{InvalidMediumReferenceException}. \\
	\hline
	\texttt{isAtEndOfMedium(x)} & Checks if offset $x$ is at the end of the \TERMmedium{}. & Based on this knowledge, the user code can skip further reading and does not need to check for exceptions. & The provided offset is ignored, it is tried to read bytes from current offset. Is this resulting in return code -1, we are at the end of the stream, otherwise the byte is added to the cache. \\
	\hline
	\texttt{insertData(x, data)} & Implements the writing operation \emph{insert} according to \DesLink{dd:410}, \DesLink{dd:410d} and  \DesLink{dd:422}: Adds data at the given offset $x$, consecutive bytes are shifted ``to the back'', the changes first get written only with \texttt{flush()}. & The insertion of new metadata is a common case in \LibName{} and must be supported. & \texttt{ReadOnlyMediumException} \\
	\hline
	\texttt{removeData(x, n)} & Implements the writing operation \emph{remove} according to \DesLink{dd:410}, \DesLink{dd:410d} and \DesLink{dd:424}: Removes $n$ bytes at offset $x$. Consecutive bytes are shifted ``to front'', the changes first get written only with \texttt{flush()} & Removing existing metadata is a standard case in \LibName{} and must be supported. & \texttt{ReadOnlyMediumException} \\
	\hline
	\texttt{replaceData(x, n, data)} & Implements the writing operation \emph{replace} according to \DesLink{dd:410}, \DesLink{dd:410d} and  \DesLink{dd:422}: Replaces $n$ bytes at offset $x$ with new bytes of length $m$. The changes first get written only with \texttt{flush()} & It often happens that \--- instead of entirely removing or newly inserting data \--- existing data must be overwritten. This is - especially at the beginning of a file - a much more efficient operation than insertion and deletion and must thus directly be supported. & \texttt{ReadOnlyMediumException}\\
	\hline
	\texttt{flush()} & Implements the writing operation \emph{flush} according to \DesLink{dd:410}: All \emph{changed} data currently in the temporary buffer are written in a suitable way to the external medium. It cannot be guaranteed that this operation is atomic. & This is a practical implementation of \DesLink{dd:410}: While \texttt{insertData()}, \texttt{removeData()} and \texttt{replaceData()} only write into a temporary buffer, this call directly writes to the external medium. & \texttt{ReadOnlyMediumException} \\
	\hline
	\texttt{createMediumReference(x)} & Creates a new \IMediumReference{} instance for the given offset $x$ according to \DesLink{dd:419} & Is needed for random-access & Is needed for \texttt{InputStream}s \\
	\hline
	\texttt{undo(mediumAction)} & Undoes the changes of the given \MediumAction{} according to \DesLink{dd:420}, as far as it is still pending. & Is needed for random-access & \texttt{InvalidMediumActionException} \\
	\hline
	\texttt{open()} & Opens access to the medium & Explicit open instead of constructor better for testing & Explicit open instead of constructor better for testing \\
	\hline
	\texttt{close()} & Closes all internal resources according to \DesLink{dd:419ac}, clears the complete cache contents and other internal data structures & See \DesLink{dd:419ac} & See \DesLink{dd:419ac} \\
	\hline
	\texttt{isClosed()} & Allows users to check if the medium is already closed and thus cannot be accessed anymore (returns true), or it is still accessible (returns false). & See \DesLink{dd:419ac} & See \DesLink{dd:419ac} \\
	\hline
\caption{Operations of the \COMPmedia{} API}
\label{tab:MediaOps}
\end{longtable}
\end{landscape}
\normalsize

%-----------------------------------------------------------------------------------------------

\subsubsection{The component interface}
\label{sec:ErrorConditionsSS}

How are the public functions exposed to the outside world? There must be a functionality that creates a \IMediumStore{} instance for a given \IMedium{}. The API for this looks as follows:

%%%% DD --> %%%%
\DD{dd:428}
{% Titel
\IMediaAPI{} is the central entry point with creation functions for \IMediumStore{}s
}
{% Kurzbeschreibung
The interface \IMediaAPI{} offers the central entry point for the component \COMPmedia{}. Using the method \texttt{createMediumStore()}, users can create an \IMediumStore{} instance.
}
{% Begründung
The necessity for a further interface in addition to \IMediumStore{} is clear enough: A \IMediumStore{} refers to just a single ``medium access session'' for a medium, and of course users want to be able to open multiple media at the same time using \COMPmedia{}. Pushing creation functions into \IMediumStore{} is not considered good practice as it would decrease comprehensibilty.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{Error Handling}
\label{sec:ErrorConditions}

In general violations of the interface contract according to \DesLink{dd:205} are acquitted with a runtime exception.

The following table summarizes all further error situations when working with \COMPmedia{}:

\begin{landscape}
\begin{longtable}{|p{0.15\linewidth}|p{0.31\linewidth}|p{0.31\linewidth}|p{0.18\linewidth}|}
	\hline
	\rowcolor[gray]{.9}\textbf{Error Scenario} & \textbf{Description} & \textbf{Reaction \LibName{}} & \textbf{API method} \\
	\endhead
	\hline
	Medium is already locked & The medium is already locked by another process. \LibName{} cannot work with the medium. It is the burden of the caller to ensure, that the medium is not used in parallel. & It is an abnormal situation, thus a \texttt{MediumAccessException} runtime exception is thrown. & \IMediaAPI{} \texttt{.createMediumStore()} \\
	\hline
	Unknowm media type & A \IMedium{} implementation is specified by the caller which is unsupported. & This is an abnormal situation violating the interface contract, thus the same exception as for contract violations is thrown. & \IMediaAPI{} \texttt{.createMediumStore()} \\
	\hline
	End of medium during reading & Of course each medium has an end sometimes. When reading, this end can be reached. When writing, this is not actually possible - there, we assume that all output media virtually are unlimited. If there is no more memory for writing, \COMPmedia{} usually reacts with a \texttt{MediumAccessException} following an \texttt{IOException}. It cannot be requested from the calling code during reading, that it knows where the end of the input medium is. Reaching its end during reading can be an error, but it needs not - this depends on the current usage situation. The calling code thus must handle this depending on current context. & Because it is not necessarily an abnormal situation, a \texttt{EndOfMediumException} checked exception is thrown. & \IMediumStore{} \texttt{.cache()}, \IMediumStore{} \texttt{.getData()} \\
	\hline
	Write to read-only medium & The user-provided \IMedium{} implementation is read-only, thus it only allowes read access. & If the user nevertheless tries to write, this is an abnormal sitation and is signalled by a \texttt{ReadOnlyMediumException} runtime exception. & \IMediumStore{} \texttt{.flush()}, \IMediumStore{} \texttt{.insertData()}, \IMediumStore{} \texttt{.removeData()}, \IMediumStore{} \texttt{.replaceData()}\\
	\hline
	Consecutive write calls overlap & Concecutive calls to \texttt{removeData} or \texttt{replaceData} before a \texttt{flush} overlap in an invalid way (see \DesLink{dd:424} and \DesLink{dd:424a}) & Is acquitted with an \texttt{InvalidOverlappingWriteException} runtime exception. & \IMediumStore{} \texttt{.removeData()}, \IMediumStore{} \texttt{.replaceData()}\\
	\hline
	Invalid cache offset & With \texttt{cache()} it is tried for an \texttt{InputStream} to cache an offset that is smaller than the last read offset. & This is a wrong usage of the API, thus it results in an \texttt{InvalidMediumReferenceException} runtime exception. & \IMediumStore{} \texttt{.cache()}, \IMediumStore{} \texttt{.getData()} \\
	\hline
	Stream data not available & Data requested with \texttt{getData()} for a given offset is not available (anymore) in the cache, and the underlying medium is an \texttt{InputStream}. & This is a wrong usage of the API, thus it results in an \texttt{InvalidMediumReferenceException}, a runtime exception. & \IMediumStore{} \texttt{.getData()} \\
	\hline
	Unknown or invalid \MediumAction{} & The user passes an unknown or invalid \MediumAction{} to any operation & This is an abnormal situation and is acquitted with the runtime exception \texttt{InvalidMediumActionException}  & \IMediumStore{}\texttt{.undo()} \\
	\hline
	\texttt{IOException} in the implementation & The Java implementation use throws an \texttt{IOException}, at any place where none of the already presented error situations are involved. & It is an abnormal situation, thus a \texttt{MediumAccessException} runtime exception is thrown. & \IMediumStore{} \texttt{.cache()}, \IMediumStore{} \texttt{.getData()}, \IMediumStore{} \texttt{.isAtEndOfMedium()}, \IMediumStore{} \texttt{.flush()} \\
	\hline
	The \IMediumStore{} was already closed using \texttt{close()} & \texttt{MediumStoreClosedException}, a runtime exception & \texttt{MediumStoreClosedException}, a runtime exception & all \\
	\hline
\caption{Error handling in the component \COMPmedia{}}
\label{tab:FBMedia}
\end{longtable}
\end{landscape}

To summarize:

%%%% DD --> %%%%
\DD{dd:427}
{% Titel
Reaching the end of medium is not necessarily an error, other problems with I/O are seen as abnormal events.
}
{% Kurzbeschreibung
\COMPmedia{} sees achieving at the end of a medium not as abnormal event, but it must be handled according to the current context by the user code. \LibName{} assumes output media to be virtually unlimited and thus does not implement any means of treating end of medium situations when writing (also in accordance to the Java API).

All other error sitations in \COMPmedia{} are abnormal situations according to table \hyperref[tab:FBMedia]{\ref{tab:FBMedia}}.
}
{% Begründung
See table
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------
%		Implementation Layer Design
%-----------------------------------------------------------------------------------------------

\subsection{Implementation Design}
\label{sec:ImplementationDesignCOMPmedia}

%-----------------------------------------------------------------------------------------------

\subsubsection{\TERMmedium{} Access}
\label{sec:ZugriffAufDasMedium}

Access to the \TERMmedium{} is implemented in own classes, as the following design decision states:

%%%% DD --> %%%%
\DD{dd:429}
{% Titel
Interface \IMediumAccessor{} with implementations for each \TERMmedia{} type access
}
{% Kurzbeschreibung
Access to a \TERMmedium{} is possible via an interface \IMediumAccessor{}, doing a great deal of ensuring \DesLink{dd:407}. It offest the following primitives:
\begin{itemize}
	\item \texttt{getMedium}: Returns the medium this instance is working on.
	\item \texttt{open}: Opens the medium for access. Opening creates an exclusive lock on the medium, as far as the medium supports this (see \DesLink{dd:404}, \DesLink{dd:405}, \DesLink{dd:406}).
	\item \texttt{isOpened}: Check if the medium is opened.
	\item \texttt{close}: Close the medium for access. A closed medium cannot be used anymore.
	\item \texttt{setCurrentPosition}: Sets the current position for the next \texttt{read}, \texttt{write}, \texttt{truncate} or \texttt{isAtEndOfMedium} call. Is ignored for non-random-access media.
	\item \texttt{getCurrentPosition}: gets the current position on the medium where the next \texttt{read}, \texttt{write}, \texttt{truncate} or \texttt{isAtEndOfMedium} will be executed.
	\item \texttt{read} at the current position: Read $n$ bytes from external medium by explicit access from the current position, return the bytes in a \texttt{ByteBuffer}. Advances the current position by the number of read bytes.
	\item \texttt{write} at the current position: Writes $n$ bytes to the external medium at the current position passed in a \texttt{ByteBuffer}. Throws an exception for read-only media, especially for \texttt{InputStream}. Advances the current position by the number of read bytes.
        \item \texttt{truncate} to new end offset at the current position: Truncates the medium to end at the current position. Throws an exception for read-only media, especially for \texttt{InputStream}.
	\item \texttt{isAtEndOfMedium}: Check if the current position is at end of the \TERMmedium{}.
\end{itemize}

There is one implementation of this interface for each distinct \TERMmedium{} type.

\IMediumStore{} exclusively accesses the \TERMmedium{} only via this interface.
}
{% Begründung
\IMediumStore{} itself can deal with caching and the complex implementation of writing functionality independently from the concrete medium, while the actual medium access can be abstracted away by concrete implementations generically. Classical separation of concerns to increase maintainability and comprehensibility of the solution.

Regarding the offset handling for read: This is necessary to ensure readable and non-confusing use for non-random-access media. In that way, the user does not assume the medium is actually read-only.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

% -------------------------------------------------------------------------------------------------------
\subsubsection{Management of \IMediumReference{} instances}%
\label{sec:VerwaltungderIMediumReferenceInstanzen}%

According to \DesLink{dd:419}, \IMediumReference{} instances must be maintained centrally by \IMediumStore{}. At the same time, we can have multiple \IMediumReference{} instances referring to the same offset of the same medium, but actually refer to different data - in the special case of the methode \texttt{insertData}. New data is inserted subsequently  at the same offset with \texttt{flush()}, see \DesLink{dd:422}. In the end, the \IMediumReference{} instances must be automatically updated with \texttt{flush()}, as described in \DesLink{dd:418b} and \DesLink{dd:419b}.

Thus, these things follow:
%%%% DD --> %%%%
\DD{dd:430}
{% Titel
No pooling of \IMediumReference{} instances for the same offsets is possible
}
{% Kurzbeschreibung
In contrast to Java strings, the reuse of \IMediumReference{} instances in \texttt{createMediumReference()} for same offsets is not possible, i.e. if an \IMediumReference{} instance for offset $x$ has already been created, the same instance cannot be returned for the same offset on the next call. A new \IMediumReference{} instance must be created instead.
}
{% Begründung
Assum we use pooling. Furthermore, assume there are two inserts of lengths $n_1$ and $n_2$ at the same offset $x$ scheduled via \texttt{insertData()}. The internal implementation would only have a single instance of \IMediumReference{} for offset $x$. \texttt{flush()} must keep the offset of the first insertion unchanged, as the data of this first insertion remain there. Howeder, the offset of the second insertion must be changed, as these inserted bytes are actually located at offset $x+n_1$ after \texttt{flush()}.
}
{% Nachteile
For many created \IMediumReference{} objects, there could be a bigger memory footprint.
}
%%%% <-- DD %%%%

Furthermore, the \IMediumReference{} objects must be maintained in a dedicated data structure:
%%%% DD --> %%%%
\DD{dd:431}
{% Titel
All instances ever created with \texttt{createMediumReference()} are maintained in a dedicated data structure that allows duplicates
}
{% Kurzbeschreibung
All instances are held in a data structure that allows duplicates. It must be dedicated, i.e. only be used for storing all ever created \IMediumReference{} objects.
}
{% Begründung
Dupllicates must be possible due to \DesLink{dd:430}. We cannot mix that data structure with the caching or pending change data structures, as on the one hand side there will be always more \IMediumReference{} instances, than cache entries or pending changes, and on the other hand cache and pending change list could be cleared, while the \IMediumReference{} instances must be kept until the explicit close of the mediums.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Are these entries of the dedicated data structure indicated by \DesLink{dd:430} in any way sorted?

%%%% DD --> %%%%
\DD{dd:432}
{% Titel
Unsorted ArrayList for keeping the \IMediumReference{} instances
}
{% Kurzbeschreibung
We use an \texttt{ArrayList} as data structure for maintaining all \IMediumReference{} instances. Insertion of \IMediumReference{} instances is done in creation order. The list is  unsorted.
}
{% Begründung
A list allows for duplicates. Sorting of the list after each addition would lead to $O(n\log n)$ runtime complexity on average when creating a new \IMediumReference{} instance, if $n$ is the current size of the list. Ascending sort order by offset would be a bit more efficient for \texttt{flush()}, but does hardly justify the effort during insertion, because the creation of a \IMediumReference{} instance is usually much more commonly done than a \texttt{flush()}. Following approaches have been rejected especially:
\begin{itemize}
\item A \texttt{Map<Long, List<\IMediumReference{}>}\texttt{>} with offsets as key and all \IMediumReference{} instances for the offset as value won't work, as the offsets would need to be shifted on each insertion, i.e. the keys of the map would either need to be \IMediumReference{} instances again, or would need to be updated expensively.
\item A \texttt{TreeSet<\IMediumReference{}>} can be excluded as it does not allow duplicates.
\item A combination of a \texttt{TreeSet} with a special \texttt{Comparator}, which assumes \IMediumReference{} instances only to be equal, if they are the same objects, and as bigger, if the offset is the same, but the object is different, would accept such ``duplicates'' with the same offsets and ensure correct sorting for every insert. However, the \texttt{Set} then is incompatible with \texttt{equals}, what is not a best practice according to the javadocs. Secondly: More time required for insertion as mentioned.
\end{itemize}
}
{% Nachteile
Finding all \IMediumReference{} instances within the \texttt{flush()} implementation, that are bigger than a given offset has $O(n)$ complexity, which can however be tolerated.
}
%%%% <-- DD %%%%

To handle the complexity of \IMediumStore{} we decide:
%%%% DD --> %%%%
\DD{dd:433}
{% Titel
The class \MediumReferenceRepository{} is used for maintaining \IMediumReference{} instances
}
{% Kurzbeschreibung
\MediumReferenceRepository{} implements the design decisions \DesLink{dd:431}, \DesLink{dd:432} as well as \DesLink{dd:419}. It offers following methods:
\begin{itemize}
\item \texttt{createMediumReference()} to create \IMediumReference{} instances
\item \texttt{updateReferences()} for implementation of \DesLink{dd:418b}, where a \MediumAction{} instance is passed
\item \texttt{getAllReferences()} returns all maintained instances
\item \texttt{getAllReferencesInRegion()} returns all maintained instances with given offset range
\item \texttt{getAllReferencesBehindOrEqual()} returns all maintained instances with offsets bigger than the given offset
\item \texttt{clear()} removes all maintained instances
\end{itemize}

}
{% Begründung
Reduction of total complexity of the \IMediumStore{}.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

The last question for \IMediumReference{} instances that still has to be answered: How to deal with the method \texttt{advance()} mentioned in \DesLink{dd:416}. It creates \IMediumReference{} instances. Do they have to be maintained in \MediumReferenceRepository{}, too?

%%%% DD --> %%%%
\DD{dd:433b}
{% Titel
The  \IMediumReference{} instances created with \IMediumReference{}\texttt{.advance()} need to be maintained with \MediumReferenceRepository{}, too.
}
{% Kurzbeschreibung
Initially, the new \IMediumReference{} instance must get a reference to its creator, i.e. \MediumReferenceRepository{}, during construction. To still enable a simple creation of instances of \IMediumReference{} implementation classes (e.g. in unit tests), the constructor is public.
}
{% Begründung
The client code can arbitrarily use \IMediumReference{}\texttt{.advance()}, and the returned references can be used as usual, e.g. for newly created data blocks. Thus it is clear that even these references are auto-corrected with \MediumReferenceRepository{}\texttt{.updateReferences()}.
}
{% Nachteile
Close coupling between \IMediumReference{} and \MediumReferenceRepository{}, as both are knowing each other.
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{Internal Data Structures  for Caching}
\label{sec:Datenstrukturen}

The cache on first sight maintains data bytes per offset, always assuming that the data in cache is exactly identical to the data on the external medium, according to \DesLink{dd:404}. It was already defined that there is an explicit \IMediumStore{}.\texttt{cache()} method for reading data into the cache and a method \IMediumStore{}.\texttt{getCachedByteCount()} for querying connected bytes from the cache (see table \hyperref[tab:MediaOps]{\ref{tab:MediaOps}}, as well as \DesLink{dd:409} and \DesLink{dd:412b}). Querying data from the cache is done using \IMediumStore{}.\texttt{getData()}, which can on the one hand skip the cache, on the other hand it can automatically update the cache with missing data (\DesLink{dd:412c} and \DesLink{dd:412d}). Finally, the maximum cache size can be set or caching can even be entirely inactive (see \DesLink{dd:411c} and \DesLink{dd:411e}).

In most cases we want to query which parts of data to read, write or remove is within the cache. The cache might be fragmented arbitrarily due to multiple fill operations. The make the code easier to understand and maintain, we create a specific class for representing the so called regions, i.e. added cache fragments:
%%%% DD --> %%%%
\DD{dd:435}
{% Titel
Class \MediumRegion{} for consecutive regions of a medium, especially also for cache regions
}
{% Kurzbeschreibung
The class \MediumRegion{} represents a consecutive byte range with start offset, size and contained bytes of a medium, that may or may not be cached. It offers the following methods:
\begin{itemize}
\item \texttt{getStartReference()}: Query start \IMediumReference{} of the region
\item \texttt{getSize()}: Query length of the region
\item \texttt{isCached()}: Returns true if cached, false otherwise
\item \texttt{getBytes()}: Returns null if the region is not cached, otherwise the \texttt{ByteBuffer} with the cached region data
\item \texttt{isContained()}: Returns true if the given \IMediumReference{} is contained within the region, false otherwise
\item \texttt{overlapsOtherRegionAtBack()}: Returns true if the this region overlaps the other region at its back, i.e. shares bytes with it at its end, otherwise returns false.
\item \texttt{overlapsOtherRegionAtFront()}: Returns true if the this region overlaps the other region at its front, i.e. shares bytes with it at its front, otherwise returns false.
\item \texttt{getOverlappingByteCount()}: Returns the number of bytes that this region shares with another region or zero if it does not share any bytes with it.
\item \texttt{split()}: Splits this region into two regions at the given offset
% \item \texttt{discardbytesAtFront()}: Allows to trim the region at its beginning by discarding a given number of bytes
% \item \texttt{discardbytesAtEnd()}: Allows to trim the region at its back by discarding a given number of bytes
\end{itemize}
}
{% Begründung
The cache regions and the non-cached regions of the medium can be treated in the same way. Implementing caching is easier when not based on primitive types (e.g. byte[]) only, but using this helper class.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Maintenance of cache content is done by a helper class:
%%%% DD --> %%%%
\DD{dd:436}
{% Titel
Cache maintenance by \MediumCache{}, ensuring maximum cache size and no overlapping regions
}
{% Kurzbeschreibung
Cache maintenance is done by the class \MediumCache{}. This class has the following invariants at any point in time before and after public method calls:
\begin{itemize}
\item The \MediumRegion{}s stored in the cache do never overlap
\item The maximum cache size is never exceeded
\item The maximum size of a cache region is never exceeded by any region
\end{itemize}

It offers the following methods:
\begin{itemize}
\item \texttt{getAllCachedRegions()}: Returns a list of all cached \MediumRegion{} instances currently contained in this cache, ordered by offset ascending
\item \texttt{getCachedByteCountAt()}: Returns the number of bytes cached consecutively starting from offset $x$
\item \texttt{getRegionsInRange()}: Returns a list of \MediumRegion{} instances overlapping the offset range $[x,x+n]$, which represent the cached and non-cached ranges within the offset range. I.e. whenever there is a gap in the cache, this gap is also represented by a single \MediumRegion{} instance without data
\item \texttt{addRegion()}: Adds a \MediumRegion{} to the cache. Previously cached data is overridden.
\item \texttt{clear()}: Frees all data in the cache
\item \texttt{getMaxRegionSizeInBytes()}: Returns the maximum size of a region in bytes. Default is \texttt{Integer.MAX\_VALUE}, which is represented by a constant named \texttt{UNLIMITED\_CACHE\_REGION\_SIZE}. The cached regions will have at most the given size.
\item \texttt{getMaxCacheSizeInBytes()}: Returns the maximum size of the cache in bytes. Default is \texttt{Long.MAX\_VALUE}, which is represented by a constant named \texttt{UNLIMITED\_CACHE\_SIZE}. The cache size will at no time exceed this number of bytes.
\item \texttt{getCurrentCacheSizeInBytes()}: Returns the current size of the cache in bytes.
\end{itemize}
}
{% Begründung
Reducing complexity of \IMediumStore{}
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

For the cache sizes, we saw already that we can query the maximum and current cache size as well as the maximum region size. However, why can we not change the maximum sizes dynamically?

%%%% DD --> %%%%
\DD{dd:436b}
{% Titel
The maximum cache and maximum region size of a cache instance can never be changed throughout its life time.
}
{% Kurzbeschreibung
The maximum cache size and the maximum region size are passed to the constructor of the \MediumCache{} class and they must not be changed later.
}
{% Begründung
Otherwise complex methods for reorganizing the cache are necessary, splitting and discarding existing regions. It is very unlikely that the user needs to change the cache size during accessing the medium. It if fully sufficient that he can configure the maximum size of the cache and its regions before the first access to the medium.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

How are the cache regions internally managed?

%%%% DD --> %%%%
\DD{dd:437}
{% Titel
A \texttt{TreeMap} is used for managing the cache contents, an additional \texttt{LinkedList} for freeing up according to FIFO
}
{% Kurzbeschreibung
A \texttt{TreeMap<}\IMediumReference{}, \MediumRegion{}\texttt{>} is used for managing the cache contents. An additional \texttt{LinkedList} is used for freeing up cache data according to FIFO.
}
{% Begründung
Content must be read based on offsets. Thus a data structure sorted by offset is necessary. It allows the efficient retrieval of all \MediumRegion{}s bigger or smaller than a given offest. This operation should most probably need a runtime complexity of only $O(log(n))$ instead of $O(n)$.

The \texttt{LinkedList} is necessary to efficiently remove the first added cache regions when freeing up is necessary due to max cache size reached, see \DesLink{dd:411e}.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

We should also think about cache fragementation. Let us assume that, by subsequent calls to \texttt{addRegion()}, we would add a single byte to the cache 20 times for a consecutive offset range. Will this result in 20 different \MediumRegion{}s with a length of one byte each? The same question arises for calls to \IMediumStore{}.\texttt{getData()}, which spans over an offset range with gaps in the cache coverage. Assume we have a cache that contains 20 bytes starting at offset $x$, further 50 bytes at offset $y:=x+30$, i.e. it has a gap of 10 bytes between the two regions. If there is a now a call to \IMediumStore{}.\texttt{getData()} for range $x-10$ with length of 100, we would result in five regions:
\begin{itemize}
\item Region 1: $[x-10,x)$ not in the cache
\item Region 2: $[x,x+20)$ in the cache
\item Region 3: $[x+20,y)$ not in the cache
\item Region 4: $[y,y+50)$ in the cache
\item Region 5: $[y+50,y+60)$ not in the cache
\end{itemize}

\IMediumStore{}.\texttt{getData()} will then add regions 1, 3 and 5 to the cache, according to \DesLink{dd:412d}. So, do we have 5 \MediumRegion{}s in the cache after the call? Another extreme case is that the user reads 20 single bytes each with an offset gap of just one byte to the next one. This would result in 20 cache regions each with a size of one byte.

To ease the implementation complexity, we nevertheless decide:

%%%% DD --> %%%%
\DD{dd:437d}
{% Titel
Fragmentation of cache regions is not actively avoided
}
{% Kurzbeschreibung
\COMPmedia{} does not try to mitigate or avoid the following situations:
\begin{itemize}
\item Direct consecutive cache regions are not joined, even if their total size is smaller than the maximum allowed region size
\item ``Nearby'' but unconnected (i.e. non-consective) cache regions of small sizes are not handled in any special way.
\end{itemize}
}
{% Begründung
It would lead to even higher complexity of the implementation of \texttt{addRegion()}.

In contrast to that high complexity, we can ask the caller to ensure that he only adds data for reasonably connected offset ranges.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{Internal Data Structures for Managing Pending Changes}
\label{sec:DatenstrukturenZweist}

For the two-stage write protocol, changes scheduled via \texttt{insertData()}, \texttt{removeData()} and \texttt{replaceData()} must be managed in a reasonable way, such that they later can be processed during \texttt{flush()}. Any change is represented as a \MediumAction{}.

We first state the following:

%%%% DD --> %%%%
\DD{dd:434}
{% Titel
\MediumAction{} has a sequence number for distinguishing actions at the same offset
}
{% Kurzbeschreibung
\MediumAction{} defines a sequence number (starting at 0) for distinguishing actions at the same offset. It is incremented by consecutive actions (no matter which type) at the same offset by 1. This sequence number is not thus only used for \texttt{insert}s at the same offset, but also for all other types of actions.
}
{% Begründung
Two distinct \MediumAction{} instances referring to the same offset cannot be sorted without this mechanism. However, this is especially important for \texttt{insert}s that are allowed to refer to the same offset (see \DesLink{dd:422}). Furthermore, it is also important for other types, as \texttt{insert} allows a later \texttt{remove} or \texttt{replace} at the same offset (see \DesLink{dd:422}).
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

We now have to define comparisons between two \MediumAction{}s in a reasonable way, as sorted data structures for efficient retrieval and iteration in order can be used correspondingly:

%%%% DD --> %%%%
\DD{dd:434a}
{% Titel
Comparisons of \MediumAction{}s is done based on \IMediumReference{} and the sequence number
}
{% Kurzbeschreibung
A \MediumAction{} \texttt{a} is smaller than another \MediumAction{} \texttt{b} according to Javas \texttt{compareTo}, if and only if one of the following criteria are met:
\begin{itemize}
\item The \IMediumReference{} of \texttt{a} is smaller than the \IMediumReference{} of \texttt{b},
\item Or the \IMediumReference{} of \texttt{a} is equal to the \IMediumReference{} of \texttt{b}, and the sequence number of \texttt{a} is smaller than the sequence number of \texttt{b}
\end{itemize}

A \MediumAction{} \texttt{a} is equal to a \MediumAction{} \texttt{b} according to Javas \texttt{equals} and \texttt{compareTo}, if all attributes of \texttt{a} are equal to all attributes of \texttt{b} (in terms of \texttt{equals}).

A \MediumAction{} \texttt{a} is bigger than a \MediumAction{} \texttt{b} according to Javas \texttt{compareTo}, if \texttt{a} is neither smaller than \texttt{b} nor equals \texttt{b}. This is especially true if the \IMediumReference{} is bigger, or for equal \IMediumReference{}s, if the sequence number is bigger. Furthermore it is defined: If \IMediumReference{}s and sequence numbers are identical, then \texttt{a} is still bigger than \texttt{b} in the case that any of the other attribute of the \MediumAction{}s differs.
}
{% Begründung
Sorting of \MediumAction{}s should be done according to their order on the medium (i.e. their \IMediumReference{}s) and creation order (i.e. their sequence number), because behaviour of consecutive operations is based on call order, according to \DesLink{dd:422}, \DesLink{dd:424} and \DesLink{dd:424a}. In addition, the \MediumAction{}s must be processesed in a defined order during \texttt{flush}. \texttt{equals} must return true exactly in the case that \texttt{compareTo} returns 0.
}
{% Nachteile
Might cause confusion, as smaller and bigger are not symmetric. The implementation must thus ensure that  \MediumAction{}s with same offset always get different sequence numbers that strictly increase with creation order.
}
%%%% <-- DD %%%%

Now we can define in which way the \MediumAction{}s are stored:

%%%% DD --> %%%%
\DD{dd:435b}
{% Titel
\MediumAction{}s are stored in a sorted data structure without duplicates
}
{% Kurzbeschreibung
The \MediumAction{}s created before a \texttt{flush()} are held in a datastructure sorted by offset and sequence number (according to \DesLink{dd:434}), which does not allow duplicates (e.g. \texttt{TreeSet}).
}
{% Begründung
The sort order is necessary for in-order-processing via \texttt{flush()}, two \MediumAction{}s with same offset, same sequence number and same type should not show up twice.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Now regarding management of \MediumAction{}s:
%%%% DD --> %%%%
\DD{dd:436a}
{% Titel
For managing \MediumAction{}s, the class \MediumChangeManager{} is responsible
}
{% Kurzbeschreibung
For managing \MediumAction{}s, the class \MediumChangeManager{} is defined, which internally implements \DesLink{dd:435b}, with following methods:
\begin{itemize}
\item \texttt{scheduleInsert()} for scheduling an \emph{insert}, implements \DesLink{dd:422}, gets a \MediumRegion{} as parameter and returns a \MediumAction{} of the given type and with correct sequence number, i.e. should there be other actions at the same offset, the new action is guaranteed to have a sequence number higher than the action with the biggest sequence number already present for the same offset.
\item \texttt{scheduleRemove()} for scheduling an \emph{remove}, implements \DesLink{dd:424}, gets a \MediumRegion{} as parameter and returns a \MediumAction{} of the given type and with correct sequence number, i.e. should there be other actions at the same offset, the new action is guaranteed to have a sequence number higher than the action with the biggest sequence number already present for the same offset.
\item \texttt{scheduleReplace()} for scheduling an \emph{replace}, implements \DesLink{dd:424a}, gets a \MediumRegion{} and the length of the range to replace as parameter, returns a \MediumAction{} of the given type and with correct sequence number, i.e. should there be other actions at the same offset, the new action is guaranteed to have a sequence number higher than the action with the biggest sequence number already present for the same offset.
\item \texttt{undo()} for undoing actions, implements \DesLink{dd:420}
\item \texttt{iterator()} returns an \texttt{Iterator<}\MediumAction{}\texttt{>} for reading traversation of the changes in correct order, \texttt{Iterator.remove()} is not implemented
\item \texttt{clearAll()} removes all changes
\end{itemize}
Here, the three \texttt{schedule} methods create \MediumAction{}s according to \DesLink{dd:424b} and \DesLink{dd:434}.
}
{% Begründung
Reduction of overall complexity of \IMediumStore{}.

The iterator allows reading of changes in order, but is not needed for processing, as we see later. \texttt{remove} on this iterator is not necessary, as \texttt{undo()} can undo an action.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

At the end, we highlight some commonalities between \MediumAction{}s and \MediumRegion{}s, and define:
%%%% DD --> %%%%
\DD{dd:436b}
{% Titel
\MediumAction{} aggregates a \MediumRegion{} instance
}
{% Kurzbeschreibung
\MediumAction{} aggregate a \MediumRegion{} instance which holds that offset and length of the action, BUT NOT the bytes related to the action itself, which are held in a separate attribute of the \MediumAction{}.
}
{% Begründung
\MediumAction{} needs a start \IMediumReference{}, a length of the change as well as possibly the bytes to change, if any. However, we only implement start and length in form of a \MediumRegion{} instance. You can interpret \MediumAction{} as a class that refers to a \MediumRegion{}. It is a classical ``has a'' instead of an ``is a'' relationship, which requires aggregation instead of inheritance. The reason to not keep the bytes in the aggregated \MediumRegion{} but in the \MediumAction{} itself lies in the special form of the  \texttt{replace} operation. For detecting non-allowed overlaps, only the number of bytes to replace is important (see \DesLink{dd:424} and \DesLink{dd:424a}) and not the replacement bytes themselves. In that way, we can get a common implementation of overlap detection.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{Implementation of flush}
\label{sec:flushing}

The most complex functionality of \IMediumStore{} is \texttt{flush()}, because:
\begin{itemize}
\item \texttt{flush()} must iterate all pending changes,
\item align them with the current cache content,
\item cut reasonable blocks of the data bytes to write,
\item update all \IMediumReference{} and \MediumAction{} instances,
\item update the cache
\end{itemize}

We can add that the writing operations have some additional oddities:
\begin{itemize}
\item \texttt{insertData()} and \texttt{removeData()} require that data behind the insertion or removal offset is read and written again
\item \texttt{replaceData()} should also not be underestimated, as depending on the number of existing bytes to replaces with a different number of new bytes, it can either lead to no shifts at all (number of bytes to replace equal to number of replacement bytes), to an \texttt{insert} (number of bytes to replace smaller than number of replacement bytes) or a \texttt{remove} (number of bytes to replace bigger than number of replacement bytes)
\item If these operations are done at the beginning of files, reading data up to the end of file is possibly not possible in one large chung, as it could lead to \texttt{OutOfMemoryError} for large files
\item Thus blockwise reading is necessary
\item At this point, the writing operations differ from each other:
\begin{itemize}
\item For an \texttt{insertData()} of $n$ bytes at offset $x$, data must be read and written block-wise starting from the end of medium down to offset $x$. I.e. first the last $k$ bytes of the medium at offset $r$ are read and then written to offset $r+k$, then $k$ bytes at offset $r-k$ are read, to be written at $r$ and so on until offset $x$. Another way is not working if you do not want to overwrite and thus lose existing bytes.
\item For \texttt{removeData()} of $n$ bytes at offset $x$, we must read and write data starting at offset $x+n$ block-wise until the end of mediums. First, $k$ bytes at offset $x+n$ are read and then written at $x$, then $k$ bytes at offset $x+n+k$ are read to be written to $x+n$ and so on, until the last offset on the medium.
\item For \texttt{replaceData()} we have to distinguish corresponding cases, it could either behave like \texttt{insert} or \texttt{remove}, or a simple overwrite (if number of bytes to replace equals number of replacement bytes).
\end{itemize}
\end{itemize}

We can first confirm that the configuration of a maximum block size for writing is necessary:
%%%% DD --> %%%%
\DD{dd:438}
{% Titel
A maximum write block size must be configurable for the user
}
{% Kurzbeschreibung
It must be between 1 and N (any integer) bytes
}
{% Begründung
Necessary due to the block-wise reading and writing operations behind affected regions caused by inserts and removes. By making it configurable, the user can himself decide how much bytes should be processed in a single pass.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Finding out wich operations must be executed during a flush is a complex task. We need to perform this complex task within a method:
%%%% DD --> %%%%
\DD{dd:439}
{% Titel
\texttt{createFlushPlan()} creates a read-write-plan for a flush in form of a \texttt{List<}\MediumAction{}\texttt{>}
}
{% Kurzbeschreibung
\texttt{createFlushPlan()} creates a read-write-plan for a flush and returns a \texttt{List<}\MediumAction{}\texttt{>}.  The read-write-plan contains the actions to be executed in the given order. The list of possible actions is extended by \texttt{READ}, \texttt{WRITE} and \texttt{TRUNCATE}. Which are defined as:
\begin{itemize}
\item READ primitive reading of $n$ bytes starting at offset $x$
\item WRITE primitive writing (i.e. overwriting) of $n$ bytes starting at offset $x$
\item TRUNCATE explicit shortening of a file, which is especially necessary for removing data
\end{itemize}

Each returned \texttt{READ} action must be followd by a \texttt{WRITE} action, otherwise the plan is invalid. \texttt{INSERT} and \texttt{REPLACE} operations (if more replacement bytes than bytes to replace) lead to \texttt{WRITE} actions. For all \texttt{READ} and \texttt{WRITE} actions: the number of bytes is between 0 and the (configured) maximum write block size. \texttt{createFlushPlan()} also returns the original \texttt{REMOVE}, \texttt{REPLACE} and \texttt{INSERT} actions explicitly in the plan, although they are implemented implicitly by \texttt{READ} and \texttt{WRITE} actions.

The read-write-plan thus contains \MediumAction{}s in addtion to those caused by scheduling actions by a user. These additional actions are, however, not added to the internal data structures of the \MediumChangeManager{}.

The created plan can be processed afterwards.
}
{% Begründung
Determining the necessary operations is a complex process, which should be done separately. A direct execution of the plan would be an alternative, but testability of the code would heavily suffer.

\MediumChangeManager{} is the correct place for this operation, as here all \MediumAction{}s are managed anyways. The additional \MediumAction{}s in the plan are not added to any internal data structures to ensure the operation is stateless and ideally repeatable. 

Adding another \texttt{WRITE} primitive seems unnecessary, as there is already an operation named \texttt{REPLACE}. However, \texttt{WRITE} differs insofar as the bytes to write are not yet known when the action is created, in contrast to \texttt{REPLACE}.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Now we have all credentials to imnplement writing in \texttt{flush()}:
\begin{enumerate}
\item Create the read-write-plan according to \DesLink{dd:439}
\item Iterate all entries of the read-write-plan, the following steps are done per each entry:
\item Execute the \MediumAction{} at the indicated offset by the following steps:
\begin{itemize}
\item If action = \texttt{READ}: Read $n$ bytes \-- that are written in the subsequent action \-- where $n$ is smaller than the maximum write block size and bigger than 0. For that, first all regions are determined using \MediumCache{}\texttt{.getData()}. Those that are not cached are read by direct access to the medium via \IMediumAccessor{}. Then a corresponding \texttt{ByteBuffer} is built up step-wise.
\item If action = \texttt{WRITE}: Write the bytes which where read by the previous \texttt{READ} operation with direct access to the medium via \IMediumAccessor{}
\item If action = \texttt{REPLACE}: Write the bytes in the \MediumAction{} with direct access to the medium via \IMediumAccessor{}
\item If action = \texttt{INSERT}: Write the bytes in the \MediumAction{} with direct access to the medium via \IMediumAccessor{}
\item If action = \texttt{REMOVE}: Ignore the action, as it implicitly gets implemented by \texttt{READ}, \texttt{WRITE} and \texttt{TRUNCATE}
\item If action = \texttt{TRUNCATE}: Execute an explicit truncation of the medium.
\end{itemize}
\item Update the cache (part 1): If action = \texttt{REMOVE}, then call \MediumCache{}\texttt{.discardData()} to remove the bytes from the cache.
\item Only if action = \texttt{INSERT} or if action = \texttt{REMOVE}: Call \MediumReferenceRepository{}\texttt{.updateReferences()} for the region, such that all consecutive  \IMediumReference{} instances are updated.
\item Update the cache (part 2): If action = \texttt{WRITE}, \texttt{INSERT} or \texttt{REPLACE}, then call \MediumCache{}\texttt{.addData()} to add the bytes to the cache.
\item If action = \texttt{INSERT}, \texttt{REMOVE} or \texttt{REPLACE}: Call \MediumChangeManager{}\texttt{.undo()} to remove the action
\end{enumerate}

%%%% DD --> %%%%
\DD{dd:440}
{% Titel
\texttt{flush()} is implemented according to the process defined above
}
{% Kurzbeschreibung
\texttt{flush()} is implemented according to the process defined above
}
{% Begründung
The read-write-plan must contain all operations explicitly, i.e. including those triggered by the user - \texttt{REPLACE}, \texttt{INSERT} and \texttt{REMOVE}, even if \texttt{READ} and \texttt{WRITE} would be sufficient for their implementation. The reason for that is that the actions of the user must explicitly be removed from the \MediumChangeManager{} and their influence on \IMediumReference{} instances behind must explicitly be executed. For this, you need the concrete types, \texttt{WRITE} is not sufficient.

\texttt{undo()} is only executed for user operations, as only those are maintained in the internal data structures of \MediumChangeManager{}, according to \DesLink{dd:439}.

The cache update is divided into two parts: In case of a \texttt{REMOVE}, \emph{first} the cache is updated, and \emph{then} the \IMediumReference{} instances are updated. The reaseon for that is that otherwise, at the same offset, there could be multiple cache regions \--- for example, if you have a remove of 10 bytes at offset 0 and an insert at offset 10, if you update the medium references first, the cache would contain the previous (to be removed) region from 0 to 10, and a new region from 0 to 10 (the newly inserted one, as the offsets were updated). This would bring the cache into an inconsistent state. With the same reason, the other writing operations are only updated in the cache (part 2) \emph{after} the update of the \IMediumReference{} instances.

The cache management is completely done within \MediumCache{}\texttt{.addData()}, such that maximum size and consecutive reagions can be optimized there.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Let us think about the error handling of this process:
\begin{itemize}
\item Is there a failure during creation of the read-write-plan (step 1), the user can try again, as all changes are still existing and nothing was changed yet (at least nothing by the current OS process and using \LibName{})
\item Is there a failure during access to the external medium (step 3), then previously, some actions of the read-write-plan might already have been executed successfully, the external medium thus was already changed. This corresponds to what \DesLink{dd:410b} says. As the previous operations were already removed from the plan and other data structures, we have a clean ``recovery point'', at least, i.e. the user can retry the flush.
\item Is there a failure in updating the cache in steps 4 or 6, neither the action is removed, nor the medium references are updated. Similar things happen if something goes wrong in step 5. In these cases, either the \MediumCache{} or the \MediumReferenceRepository{} is in an inconsistent state, basically it is out-of-sync with reality. The question is: Is there anything left to be saved? This is clarified by the following design decision.
\end{itemize}

%%%% DD --> %%%%
\DD{dd:441}
{% Titel
Undo of changes always happens, cache is emptied in case of update failures
}
{% Kurzbeschreibung
Should a failure of the \texttt{flush()} occur during steps 4 to 6, i.e. any \texttt{Exception} is thrown, the action must nevertheless be undone.

Further measures are not taken, because faulure in steps 4 to 6 might only happen in case of programming errors or system failures. In these situations, recovery is anyway quite hard or even impossible.
}
{% Begründung
\texttt{flush()} is a reasonable operation, that does however not support ACID, but at least the whole system is left in as sane state as possible. This includes that actions already executed successfully are removed such that they are not executed again by mistake.

The attempt to also handle failures during cache management or \MediumReferenceRepository{} accesses has a very high complexity that is not justifiable compared to the scarcity of such events. Even then the system is actually not in a consistent state. Such error handling that believes it can rescue the overall system from failure probably makes things even worse.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{Implementation of \texttt{createFlushPlan}}
\label{sec:flushingPlan}

The next step is to go into more detail regarding implementation of \texttt{createFlushPlan}, as it is anything but trivial. Here we develop a general algorithm that creates based on operations \texttt{insert}, \texttt{remove} and \texttt{replace} a sequence of necessary read and write operations to transform the current medium state into the target state.

Before that, we list some testcases that should be implemented to demonstrate the intended behaviour:

\begin{landscape}
\begin{longtable}{|p{0.03\linewidth}|p{0.08\linewidth}|p{0.45\linewidth}|p{0.35\linewidth}|}
	\hline
	\rowcolor[gray]{.9}\textbf{ID} & \textbf{Testcase} & \textbf{Variations} & \textbf{Expectation} \\
	\endhead
	\hline
CF0 & No operation & - & The plan created is empty \\
	\hline
CF1 & Single \texttt{insert} &\begin{enumerate}\item[a.] At start, intermediate or end offset of the medium
\item[b.] bytes behind: None, or whole-numbered multiple of the maximum write block size, or no whole-numbered multiple, or fewer bytes than the maximum write block size
\item[c.] Insertion bytes: The same cases as for the bytes behind
\end{enumerate}
& No read/write operations before insert offset; bytes behind remain unchanged and get shifted by $k$ bytes towards increasing offsets, such that medium length grows by $k$ bytes; The CFP contains $N$ pairs of read/ write operations for the bytes behind, where $N$ is the number of started blocks of at most ``maximum write block size'' bytes that are located behind the insert offset; the read/write pairs start from the last block backwards down to the first block after the insert offset, where the writes occur exactly $k$ bytes behind the reads; After this sequence, for the insertion bytes, there are $X$ corresponding write operations (one per starting block) with increasing offsets starting at the insert offset; The \texttt{insert} action follows after these actions in the plan \\
	\hline
CF2 & Single \texttt{remove} &\begin{enumerate}\item[a.] At start, intermediate or towards the end offset of the medium
\item[b.] bytes behind: None, or whole-numbered multiple of the maximum write block size, or no whole-numbered multiple, or fewer bytes than the maximum write block size
\item[c.] Removed byte count: The same cases as for the bytes behind
\item[d.] Extreme case: All bytes of the medium are removed
\end{enumerate}
& No read/write operations before remove offset; bytes behind remain unchanged and get shifted by $k$ bytes towards decreasing offsets, such that medium length shrinks by $k$ bytes; the CFP contains $N$ pairs of read/ write operations for the bytes behind, where $N$ is the number of started blocks of at most ``maximum write block size'' bytes that are located behind the last removed byte; the read/write pairs start from the first block after the last removed byte forward up to the last block of the medium, where the writes occur exactly $k$ bytes before the reads; the \texttt{remove} action follows after these actions in the plan; at the end there is a \texttt{truncate} operation \\
	\hline
CF3 & Single \texttt{replace} &\begin{enumerate}\item[a.] At start, intermediate or towards the end offset of the medium
\item[b.] bytes behind: None, or whole-numbered multiple of the maximum write block size, or no whole-numbered multiple, or fewer bytes than the maximum write block size
\item[c.] bytes to replace: The same cases as for the bytes behind
\item[d.] Replacement bytes: The same cases as for the bytes behind
\item[e.] Number of bytes to replace ($:=m$) smaller, equal to or bigger than the number of replacement bytes ($:=n$)
\item[f.] Extreme case: All bytes of the medium are replaced
\end{enumerate}
& No read/write operations before remove offset; If $m>n$: Behaves like a \emph{remove} of $m-n$ bytes; If $m<n$: Behaves like an \emph{insert} of $n-m$ bytes; If $m=n$: No read/write pairs for bytes behind; In every case there, there are $X$ corresponding write operations (one per starting block) for the replacement bytes with increasing offsets starting at the replacement offset; The \texttt{replace} action follows after these actions in the plan \\
	\hline
CF4 & Multiple \texttt{insert}s &\begin{enumerate}\item[a.] All inserts directly subsequent, or with gaps between
\item[b.] bytes in-between/behind: None, whole-numbered multiple of the maximum write block size, or no whole-numbered multiple, or fewer bytes than the maximum write block size
\item[c.] Bytes to remove: None, whole-numbered multiple of the maximum write block size, or no whole-numbered multiple, or fewer bytes than the maximum write block size
\end{enumerate}
& No read/write operations before the first insertion; bytes behind the last insertion: They remain unchanged and are shifted by $k$ bytes to the back, such that the overall length of the medium increases by $k$ bytes; bytes in between insertions: remain unchanged and are shifted to the back by the number of up-to-then inserted bytes; For these bytes, $N$ read/write operations are returned, where $N$ is the number of at least started blocks of maximum write block size, that are behind or between the insert operation on the medium; the \texttt{insert} action follows after these actions in the plan \\
	\hline
CF5 & Multiple \texttt{remove}s &\begin{enumerate}\item[a.] All removes at the same offset or at different offsets
\item[b.] bytes in-between/behind: None, whole-numbered multiple of the maximum write block size, or no whole-numbered multiple, or fewer bytes than the maximum write block size
\item[c.] Bytes to insert: None, whole-numbered multiple of the maximum write block size, or no whole-numbered multiple, or fewer bytes than the maximum write block size
\end{enumerate}
& No read/write operations before the first remove; bytes behind: Remain unchanged and are shifted to the front by $k$ bytes, such that the overall medium length decreases by exactly $k$ bytes; $N$ read/write operations are returned for these operations, where $N$ is the number of at least started blocks of maximum write block size, that are behind the remove operation on the medium; a \texttt{truncate} operation follows in the plan \\
	\hline
\caption{Test cases for checking \texttt{createFlushPlan}}
\label{tab:createFlushPlan}
\end{longtable}
\end{landscape}

% -------------------------------------------------------------------------------------------------------
\subsubsection{Configurating Medium Access}%
\label{sec:Konfigurationsparameter}%

So far, we have identified several mechanisms the user can use to influence the behaviour of medium access: He can set the maximum cache size, he can disable caching alltogether, and he can also change the maximum read-write block size. But how? In \DesLink{dd:207a}, we explicitly said that for now, \LibName{} will not offer the possibility to change such parameters dynamically. Still we have to offer the user the corresponding API without exposing him to the internal details of the implementation.

We thus first define:
%%%% DD --> %%%%
\DD{dd:441b}
{% Titel
The configuration of the medium access parameters is done per \IMedium{} instance
}
{% Kurzbeschreibung
The configuration of \COMPmedia{} is done per \IMedium{} instance. By doing this, all configuration parameters correlate to an \IMedium{}, have the same lifetime and scope. The setting of the parameters is done by passing them directly to the constructor of the media created by the user, with constructors setting the parameters to sensitive defaults.
}
{% Begründung
The whole internal implementation of the most important classes, i.e. \IMediumStore{}, \IMediumAccessor{}, \MediumCache{} and so on works on exactly one medium. The user can create \IMedium{} instances directly himself and configure them as needed, independent of other \IMedium{} instances. As these parameters must not change after creation of the medium, it is correct to pass them to the constructor and to not offer setters.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Now the question arises: Which configuration parameters are needed in detail? We summarize them again in detail in table \hyperref[tab:ConfigMedia]{\ref{tab:ConfigMedia}}.

First of all, we exclude one potential parameter:
%%%% DD --> %%%%
\DD{dd:441c}
{% Titel
The maximum cache region size is not configurable by the user, but is automatically set to the maximum read-write block size
}
{% Kurzbeschreibung
The user can only configure the maximum read-write block size, but not the maximum cache region size which is just set to the configured maximum read-write block size.
}
{% Begründung
For a usual user, it is not clear what the maximum cache region size really is and which size it should have; there is not much ``tuning'' potential in setting it to another value than the maximum read-write block size. By doing so, we have usually a one to one match betwen a read block of bytes and the medium region added to the cache. This is good performance-wise, as it does not require to e.g. read the content of a not-yet-cached medium region below maximum cache region size block-wise, in case the maximum read-write block size is smaller than the maximum cache region size. Instead, we just automatically set them to the same value, the user can only influence the maximum read-write block size. It is clearly documented to the user what it does. As additional plus, the configuration interface of a medium gets easier.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%


\begin{landscape}
\begin{longtable}{|p{0.1\linewidth}|p{0.24\linewidth}|p{0.07\linewidth}|p{0.1\linewidth}|p{0.4\linewidth}|}
	\hline
	\rowcolor[gray]{.9}\textbf{Medium} & \textbf{Parameter Name} & \textbf{Type} & \textbf{Default Value} & \textbf{Description} \\
	\endhead
	\hline
	\texttt{File}, \texttt{InputStream} & \texttt{enableCaching} & boolean & \texttt{true} & Enables or disables caching for a medium according to \DesLink{dd:411c}. Setting this to \texttt{false} after creation of the \IMediumStore{} will clear the cache content directly. Implicitly set to \texttt{false} for \texttt{byte}-Array media according to \DesLink{dd:410c} \\
	\hline
	\texttt{File}, \texttt{InputStream} & \texttt{maxCacheSize} & long $> 0$ & 1 MB & Sets the maximum cache size according to \DesLink{dd:436b}. Changes to this parameter do not have any effect after the \IMediumStore{} was already created, so callers need to ensure to set this before creating the \IMediumStore{}. \\
	\hline
	\texttt{File}, \texttt{byte}-Array & \texttt{maxReadWriteBlockSize} & int $> 0$ & 8192 & The maximum size of read-write-actions in bytes, that is triggered by \texttt{INSERT}s or \texttt{REMOVE}s during a  \texttt{flush()}, see \DesLink{dd:440}. \\
	\hline
\caption{Configuration parameters of medium access}
\label{tab:ConfigMedia}
\end{longtable}
\end{landscape}



%###############################################################################################
%###############################################################################################
%
%		File end
%
%###############################################################################################
%###############################################################################################