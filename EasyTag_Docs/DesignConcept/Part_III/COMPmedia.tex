%-----------------------------------------------------------------------------------------------
%		\COMPmedia{} Design
%-----------------------------------------------------------------------------------------------

\section{\COMPmedia{} Design}
\label{sec:COMPmediaDesign}

In this section, the design of the component \COMPmedia{} is described. Basic task of the component is to provide access to memory areas which contain multimedia data. Primarily these are files.

The term \TERMmedium{} needs to be sharpened here: In \SectionLink{sec:Medium} we had defined:
``A \TERMmedium{} defines the storage medium of \TERMdataBlocks{}. It can be a file or a \TERMmediaStream{}, or the main memory itself.''

In detail, the term summarizes the aspects ``physical storage'' and ``access mechanism'' (e.g. file-based random-access, or byte stream). Thus there might perfectly be two different media which access the same physical storage, but using different access mechanism. The term \TERMmedium{} is an abstraction and potentially allows even more special possibilities, like media streams, databases etc.

%-----------------------------------------------------------------------------------------------
%		Designentscheidungen \COMPmedia{}
%-----------------------------------------------------------------------------------------------

\subsection{Basic  Design Decisions \COMPmedia{}}
\label{sec:InterfaceDesignCOMPdataPartManagementDES2}

Here, the fundamental design decisions of the component \COMPmedia{} beschrieben.

%-----------------------------------------------------------------------------------------------

\subsubsection{Supported \TERMmedia{}}
\label{sec:SuppMedia}

This section lists decisions about supported \TERMmedia{}. To start with, it is clear that \LibName{} must support files as basic medium.

%%%% DD --> %%%%
\DD{dd:400}
{% Titel
Support for random-access file access
}
{% Kurzbeschreibung
\LibName{} supports the use of files as input and output medium via \COMPmedia{} with access mechanism ``Random Access''.
}
{% Begründung
Files are \emph{the} fundamental and most common digital media containers, even in 2016. Of course MP3 files, AVI files etc. with multimedia content are wide-spread. A library such as \LibName{} must support files as core element. To more efficiently process files, random-access is inevitable. Especially reading at arbitrary offsets \-- e.g. tags at end of file \-- as well as skipping of unimportant content is efficient to implement with random-access.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

But also reading streams shall be supported to increase the flexibility of the library:

%%%% DD --> %%%%
\DD{dd:401}
{% Titel
Support for sequential, reading byte streams
}
{% Kurzbeschreibung
\LibName{} supports the use of reading byte streams, i.e. \texttt{InputStream}s for input in mode ``sequential access''.
}
{% Begründung
\texttt{InputStream} represents the most general alternative of a \TERMmedium{} from Java perspective, which ensures a potentially higher flexibility for using \LibName{}. E.g. multimedia files can be read from ZIP or JAR archives using streams, and support for media streams might be easier to implement in later releases \-- However: To state clearly: media streams do have nothing to do with this design decision. They might be implemented completely different in upcoming releases.
}
{% Nachteile
An \texttt{InputStream} supports by definition only sequential access and no random-access (e.g. via \texttt{FileInputStream}). Thus there might be higher complexity for implementation, as well as signficant performance drawbacks because of lacking random-access.
}
%%%% <-- DD %%%%

Last but not least, the library offers access to RAM contained data, due to flexibility:

%%%% DD --> %%%%
\DD{dd:402}
{% Titel
Support for random-access to byte arrays
}
{% Kurzbeschreibung
\LibName{} allows for random-access to byte arrays as input medium and output medium.
}
{% Begründung
Already loaded memory content can be parsed with \LibName{} without need for artistic climbs, increasing flexibility of the library.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

What about \texttt{OutputStream}s? That is discussed in the following:

%%%% DD --> %%%%
\DD{dd:403}
{% Titel
No support for writing byte streams
}
{% Kurzbeschreibung
\LibName{} does not support writing byte streams, i.e. \texttt{OutputStream}s.
}
{% Begründung
\texttt{OutputStream}s are write-only, but still not random-access. Thus we would need \-- provided we want to access random-access media in a random-access style \-- a second implementation next to writing random-access. A combined usage of \texttt{InputStream}s and \texttt{OutputStream}s for Read-/Write access on the same medium is not designed into the Java API and leads to diverse problems. As \LibName{} already implements writing to output files and byte arrays, for reasons of effort, \texttt{OutputStream}s are not supported as output media. The user might implement \texttt{OutputStream}s easily by him- or herself, e.g. by first writing into byte arrays, then into an \texttt{OutputStream}.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{Consistency of  \TERMmedium{} Accesses}
\label{sec:KonsPerfMedia}

Parallel access to the same medium from different processes or threads, reading by one and writing by the other, might lead to unpredictable difficulties - even without using any caching. If you e.g. have some parsing metadata like the length of a block in bytes at hand, but a parallel process shortens the block, your read access trying to fetch the whole block will run into unexpected end of file or read inconsistent data.

To avoid such problems, there are special locking mechanisms for exclusive access to the bottleneck ressource, at least for files. We define:

%%%% DD --> %%%%
\DD{dd:404}
{% Titel
Locking of files during \LibName{} access
}
{% Kurzbeschreibung
Files are \emph{always} locked during access by \LibName{} explicitly. File content are protected by exclusive locks from corruption by other processes and threads. See \cite{PWikIO}, where we show that a file in Java must be explicitly opened for writing to be able to lock it. ``During access'' means: After opening it and until closing it. The lock thus might be long-term. \LibName{} opens a file for writing (and locking) even if the user explicitly requested read-access only.
}
{% Begründung
Other processes and threads of the same JVM cannot access the files and corrupt any data, which avoids consistency problems.
}
{% Nachteile
It is not possible to access the same file in parallel threads when using \LibName{}. It seems rather unlikely that such parallel access to the same file (e.g. reading at different places) can speedup an application. But for future media this might indeed be a drawback.
}
%%%% <-- DD %%%%

The locking of byte streams or memory regions does not make sense, as discussed in the following desing decisions:

%%%% DD --> %%%%
\DD{dd:405}
{% Titel
No locking of byte streams 
}
{% Kurzbeschreibung
Byte streams are not locked
}
{% Begründung
The interface \texttt{InputStream} does not offer any locking mechanisms. \LibName{} will not try to guess the kind of stream and lock it (e.g. by checking if it is a \texttt{FileInputStream}).
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

For different processes, the os usually protects access of memory regions. The question is whether \LibName{} should protect access to byte arrays:

%%%% DD --> %%%%
\DD{dd:406}
{% Titel
No locking of byte arrays
}
{% Kurzbeschreibung
Byte arrays are not locked
}
{% Begründung
This makes not much sense as the user anyways gets a reference to the byte array by the API, and thus can access and manipulate the raw bytes arbitrarily in a multi- or single-threaded way. Protecting it by thread locking mechanisms increases complexity and does not seem to generate any benefits whatsoever.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{Unified API for Media Access}
\label{sec:PerfMediaZUGR}

In the wiki article \cite{PWikIO}, we have shown clearly the differences between byte streams and random-file-access. With so many difference the question arises: Can this be unified at all and does the effort make sense here? The least common demoninator for random-file-access and \texttt{InputStream}s is the linear reading of all bytes in the medium. This is clearly too less. It denies all advantages of random-access. The intersection of features for a unification is therefore not making sense.

Moreover, we want a unifying combination of both approaches:

%%%% DD --> %%%%
\DD{dd:407}
{% Titel
Unified access to all supported media types in one API
}
{% Kurzbeschreibung
\COMPmedia{} offers a common abstraction for accessing files via random-access, \texttt{InputStream}s as well as byte arrays. This API provides the advantages of both access mechanisms via a common interface. The implementation throws exceptions of kind ``Operation not supported'' in some cases, if a feature is not supported by the medium. In other cases, a meaningful alternative behaviour is implemented. The using code must perform branche decisions at some places depending on the medium type.

While byte arrays are no problem for the abstraction, even random-access files and \texttt{InputStream}s have more in common as you might think at first glance:
\begin{itemize}
	\item The operations Open, (sequential) Read, Close.
	\item \texttt{InputStream}s can also (at least technically) be assigned a beginning, offsets and an end.
	\item Files can be read-only, too, which \texttt{InputStream}s are always by definition.
\end{itemize}

Writing access to a read-only medium are acquitted with a runtime exception (especially for an \texttt{InputStream}).

The main difference between files and \texttt{InputStream}s is of course: Random access is possible for files, while \texttt{InputStream}s can only be read sequentially. This difference can be potentially decreased using mechanisms such as buffering.
}
{% Begründung
The API of the component \COMPmedia{} gets easier for outside users, its usage feels more comfortable. Using components of \COMPmedia{} can offer their users in turn an easier interface. At the same time, the advantages of both approaches (random-access and better performance for files, generality and flexibility for streams) are still available. 
}
{% Nachteile
A few operations of the API cannot be implemted for both media types, which makes case decisions in the client code necessary in some cases.
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{Two-Stage Write Protocol}
\label{sec:GrundSchreiben}

When Writing, it is all about bundeling accesses and buffering. We want optimum performance und thus want to implement these mechanisms. Therefore we commit to following design decisionfor implementing writing in \LibName{} in general:

%%%% DD --> %%%%
\DD{dd:410}
{% Titel
\COMPmedia{} uses a two-stage write protocol controlled by the user
}
{% Kurzbeschreibung
The first stageis the mere registration of changes, that need to written to the external medium. In this first stage, there is no access to the external medium yet. The second stage is the operation \emph{flush}, the final writing and commiting of all changes to the external medium. The underlying implementation bundles the write actions according to its needs into one or several packets and execute the write only in the second stage.
}
{% Begründung
An efficient write implementation is possible. Internally, write actions can be bundled as needed to perform better. And this can be done without forcing the user to do it himself. The user can perform write (registration) actions whenever his code architecture needs it. Saying this, the user code is not burdened with too much restrictions or rules. Furthermore, the potential possibility of an ``undo'' of already registered actions comes into view.
}
{% Nachteile
Errors that occur when actually flushing changes to the external medium are recognizes potentially quite late. Thus the registration of changes is quite fast while the flush itself can be a long taking process. Bugs might be introduced by user code forgetting to implement the second step, the flush.
}
%%%% <-- DD %%%%

Even if we implement this, it must be clearly stated that this is not in any way a transaction protocol as implemented by some O/R mappers (e.g. hibernate) or application servers. The mentioned protocol is much simpler and not in the least capable to provide ACID! Thus the following exclusion:

%%%% DD --> %%%%
\DD{dd:410b}
{% Titel
Writing in \COMPmedia{} does not guarantee ACID, in case of errors during \emph{flush}, there is no rollback
}
{% Kurzbeschreibung
ACID (atomicity, consistency, isolation and durability) is not ensured neither by the implementation ofn \COMPmedia{} nor in gerenal by the Java File I/O. If e.g. an error occurs during Writing in the \emph{flush} stage, some data has been written already, while upcoming data will not get written anymore. There is no undo of already written data. The operation \emph{undo} must not be mixed up with a rollback and it is no action that is done automatically. While isolation and durability can be more or less provided, the user is responsible for consistency and atomicity himself.
}
{% Begründung
A transaction manager that guarantees ACID, and this for files, is really hard to implement (correctly). This requirement is somehow out of scope, no other competing library is doing something similar. \LibName{} will not be a database!
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%


% -------------------------------------------------------------------------------------------------------
\subsubsection{Requirements for the Two-Stage Write Protocol }%
\label{sec:AnforderungenandaszweistufigeSchreibprotokoll}%

Which writing operations must be offered? One method write() \-- at the end it is the only really writing primitive of the Java File I/O \-- is not sufficient. How do you remove with this method? write() equals \textit{overwriting}, which is not convenient at all. \COMPmedia{} must offer a better API, taken some of the burdens of I/O from the user. Here, we only specify the necessary operations, without going into details with their  implementation - this will be done later.

To develop a good design, however, you must first list down the user's requirements to \COMPmedia{}. This especially includes the requirements for a two-stage write protocol. Main users of the component is definitely the component \COMPdataPartManagement{}. It uses \COMPmedia{} to extract and write metadata from and into tags. Without going into the design details of \COMPdataPartManagement{}, here we nevertheless list detailed requirements that \COMPdataPartManagement{} has for \COMPmedia{} regarding two-stage writing, see table \hyperref[tab:AnfDBlocks]{\ref{tab:AnfDBlocks}}.

\begin{landscape}
\begin{longtable}{|p{0.07\linewidth}|p{0.44\linewidth}|p{0.44\linewidth}|}
	\hline
	\rowcolor[gray]{.9}\textbf{ID} & \textbf{Requirement} & \textbf{Motivation} \\
	\endhead
	\hline
	\texttt{AMed01} & It must be possible to insert bytes & Formats such as ID3v2 can be dynamically extended and have a payload of flexible length. Before an already present data block, it must be possible to insert another one. There is especially a need for an insertion operation in the case when metadata with dynamic length need to be written at the beginning of a file. \\
	\hline
	\texttt{AMed02} & It must be possible to remove bytes & With the same motivation as for insertion. It must be especially possible to remove entire metadata tags. \\
	\hline
	\texttt{AMed03} & It must be possible to replace bytes and not only overwrite, but also grow or shrink an existing byte area with replacement bytes & In metadata formats, there are both static fields with fixed length as well as dynamic fields such as null-terminated strings. If bytes are already present, it must be possible to overwrite them to save costly remove and insert operations. The growing and shrinking is especially useful and represents a higher level of abstration. If this would not be possible, replacing a previous small string value by a new longer or shorte one would need to be implemented with two operations (overwrite and insert or remove, respectively). \\
	\hline
	\texttt{AMed04} & Inserted data (Anforderung \texttt{AMed01}) must be changeable before a \texttt{flush} e.g. by extending, overwriting or removing of child fields inside the inserted data block & Based on the two-stage write protocol, an arbitrary number of writing changes can be made before a \texttt{flush}, and these might correct each other. E.g. a new ID3v2 tag footer is inserted, that stores the length of the tag. Assume that after this, a new frame is inserted into the tag, before the flush. This requires the \texttt{size} field in the firstly inserted footer to be changed afterwards again, before the flush. \\
	\hline
	\texttt{AMed05} & Replaced data (Anforderung \texttt{AMed03}) must be changeable before a \texttt{flush} e.g. by extending, overwriting or removing of child fields inside the replaced data block & A prominent example is insertion of and step-by-step extension of a frame into an ID3v2 tag: For the first creation as well as each extension, the \texttt{size} field of the tag must be changed, which induces a replace operation each time. E.g. it is allowed that users first only create and insert the new frame, and then insert new child fields afterwards, step by step. \\
	\hline
	\texttt{AMed06} & The padding feature of several data formats should be used by \LibName{} & Formats such as ID3v2 allow padding, i.e. using an overwrite buffer are to avoid newly writing the whole file. \LibName{} must use this feature when writing data, such that e.g. an insert only affects the file content until the padding area, effectively decreasing the padding, while a remove increases the padding, but the overall tag size remains the same. It is rather an indirect requirement which needs not necessarily be implemented by \COMPmedia{} only. \\
	\hline
	\texttt{AMed07} & The operations replace, remove and insert must be undoable before a \texttt{flush} & This allows to avoid unnecessary accesses to the medium and to undo mistakes by end users. \\
	\hline
\caption{Requirements for the two-stage write protocol by \COMPdataPartManagement{}}
\label{tab:AnfDBlocks}
\end{longtable}
\end{landscape}

Based on these requirements, we can first define the following basic design decisions for writing:

%%%% DD --> %%%%
\DD{dd:410d}
{% Titel
\COMPmedia{} offers the writing operations \emph{insert}, \emph{replace} and \emph{remove}
}
{% Kurzbeschreibung
The user can:
\begin{itemize}
\item \emph{insert} $N$ bytes at a given offset
\item \emph{replace} $N$ bytes at a given offset by $M$ new bytes
\item \emph{remove} $N$ bytes at a given offset
\end{itemize}
}
{% Begründung
These are operations, that are in principle already necessary for a metadata library: \texttt{replace} is needed for formats with static length (such as ID3v1) and those allowing a padding mechanism or similar (such as ID3v2). For dynamically extensible formats such as ID3v2, additional possibilities to \texttt{insert} and \texttt{remove} data blocks are necessary. A dynamic replacement (replace $N$ bytes by $M=N$ or $M\neq N$ bytes) is necessary to easily change fields with dynamic lengths, without the need to inconveniently call several different operations (e.g. first \texttt{replace}, then \texttt{remove} when decreasing the length of a string by setting a new value).

The burden to implemen these convenient operations using the Java File I/O, which essentially only offers write() and truncate(), is taken over by \COMPmedia{}, such that the user need not care.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

As we have a two-stage write protocol, the \emph{undo} of not yet flushed changes is possible, and according to the requirements also necessary.

%%%% DD --> %%%%
\DD{dd:420}
{% Titel
Writing operations on a medium can be undone with \emph{undo} before a \emph{flush}
}
{% Kurzbeschreibung
Writing operations lead to pending changes according to \DesLink{dd:410}. These can be undone according to the requirements defined above.
}
{% Begründung
The application logic can require \emph{undo} in some cases, e.g. for corrections of mistakes done by an end user. Instead of requiring to call the inverse operation (if any at all), the user is much more convenient with undoing the operation itself directly. This also ensures that the using code does not need to trace changes to be able to find which is the inverse operation.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%


%-----------------------------------------------------------------------------------------------

\subsubsection{Caching}
\label{sec:PerfMedia}

The component \COMPmedia{} takes over I/O tasks with potentially slow input and output media. Thus, it is here where the basic performance problems of the whole library need to be solved. We will approach these topics with some motivation and deductions.

In \cite{PWikIO}, basic stuff regarding performance with file access is discussed. The ground rule for performant I/O is minimizing accesses to the external, potentially slow medium. For writing, we already introduced \DesLink{dd:410}. The question is, how you can make reading perform better, too.

At first it is quite clear that for reading, you should help yourself with buffering to improve performance:

%%%% DD --> %%%%
\DD{dd:409}
{% Titel
Reading access can be done using a buffering mechanism, controlled by the component's user
}
{% Kurzbeschreibung
For each reading access, the calling code can specify the number of bytes to read, which corresponds to a buffering. The code controls the size of the buffer by itself. It potentially can also read only 1 byte. It lies in the responsibility of the calling code to read an amount of bytes that makes sense and minimizes read accesses.
}
{% Begründung
A hardcoded fixed length buffering would rather lead to performance disadvantages, as there might be read too much bytes, more than usually necessary in average. Furthermore, reading two or severeal times, depending on the size of this fixed length, would be necessary. According to \cite{PWikIO}, there is no ``one size fits all'' for buffer sizes in file I/O. The logical consequence is to let the user decide.
}
{% Nachteile
No disadvantages known.
}
%%%% <-- DD %%%%

A further important aspect is caching: With \emph{Caching}, we understand the possibly persistent storage of \TERMmedium{} contents in RAM to support faster access to the data. Buffering differs from caching in a sense that buffering is only a short-lived temporary storage without the necessity of synchronisation.

To start with, we can see - besides the already mentioned buffering - different kinds of ``Caching'' in an application that is based on \LibName{}:
\begin{itemize}
	\item During file access there are caches on hardware level, in the OS and file system.
	\item Java supports temporary buffering via the \texttt{BufferedInputStream}, and Caching explicitly via \texttt{MappedByteBuffer}s.
	\item Applications that mostly are interested in human-readaable metadata read these, convert them via \LibName{} in a clear-text representation and show this representation in their GUI. The GUI model represents in this cases a kind of caching, as in case of changes of the attributes via this GUI, it is not necessary to re-read again from the medium. This is surely not a hardware-related caching of raw data.
\end{itemize}

If we look at all these alternatives, the question arises why at all an additional built-in caching in \LibName{} would be needed? For answering this question, we should look at some use case szenarios for the library: One scenario is the already mentioned reading of metadata from a file to display it in a GUI. For such a case, caching would usually not be very useful. You read once, and maybe twice, if the user wishes to update the screen. It would be an acceptable performance without caching. Another use case is the arbitrary jumping between parts of a container format file using a low-level API to process specific contents. This is true ``random access''. The question is: Do you want to read the same place twice? Possibly yes. Instead, would you want a direct medium access again? Possibly yes or no.

The last question brings up a general problem with caching: The problem of synchronizity with the external medium. If the medium has been changed in between, the cache content is probably aged and invalid. Code that accesses the cache can usually not recognize this.

We first sum up the determined advantages and disadvantages:

\begin{longtable}{|p{0.5\textwidth}|p{0.5\textwidth}|}
	\hline
	\rowcolor[gray]{.9}\textbf{Advantages} & \textbf{Disadvantages} \\
	\endhead
	\hline
	$+$ Performance improvement when reading the same offset multiple times, as cache access is much faster than the access to the external medium & $-$ When only accessing once there is of course no performance improvement \\
	\hline
  $+$ In a cache you are - in principle - more flexible to reorganize data than on an external medium, making it easier to correct, undo or bundle changes. & $-$ Changes on the \TERMmedium{} cannot be recognized and lead to invalid cache content that might lead to erroneous behaviour or data corruption in follow-up write actions. \\
	\hline
	 & $-$ There is additional code necessary for caching, e.g. questions such as ``when is the data freed?'' must be answered. For consistency topics, even more complex code is necessary.\\
	\hline
	 & $-$ Move heap space required\\
	\hline
\caption{Advantages and disadvantages of caching in \LibName{}}
\label{tab:CachingProCon}
\end{longtable}

The disadvantages outweight the advantages. Why should you then use caching in \LibName{}? Some of the previous design decisions combine well with a caching approach:
\begin{itemize}
\item \DesLink{dd:410} may or may not be easier to implement using a cache. In this case the cache would be used to store the registered changes before a flush. However, if it would only be this, a cache would be greatly too complex, Easier solutions are possible for holding the not-yet-flushed data.
\item \DesLink{dd:409} can be merged with a cache, i.e. anything that has been buffered should directly go into the cache for upcoming read actions
\item \DesLink{dd:407} can be achieved using a cache, as we see just a little later
\end{itemize}

Thus we decide:

%%%% DD --> %%%%
\DD{dd:411}
{% Titel
\COMPmedia{} uses permanent fast storage (Caching) for read medium data
}
{% Kurzbeschreibung
\COMPmedia{} uses a RAM based, permanent fast storage (Cache) to store already read content of the \TERMmedium{}. Upcoming read accesses access the cache content (if present) only.
}
{% Begründung
\begin{itemize}
\item We provide faster repeated read access to already read data to the end-user
\item This can be used for direct implementation of \DesLink{dd:409} in a sense of buffering when reading. The cache works as the buffer for \DesLink{dd:409}.
\item To achieve \DesLink{dd:407} is possible using a cache
\end{itemize}
}
{% Nachteile
Were given in table \hyperref[tab:CachingProCon]{\ref{tab:CachingProCon}}. The alternative is a direct medium access. To summarize the disadvantages against a direct medium access:
\begin{itemize}
\item Higher code complexity
\item More heap required, the cache is durable
\item The medium might change by external processes, such that the cache content is not in synch anymore.
\end{itemize}
Note that this last mentioned disadvantage is mostly mitigated by \DesLink{dd:404}.
}
%%%% <-- DD %%%%

How to use caching to better achieve \DesLink{dd:407}?

%%%% DD --> %%%%
\DD{dd:411b}
{% Titel
Caching is used to better mitigate the differences between \texttt{InputStream}s and files according to \DesLink{dd:407}.
}
{% Kurzbeschreibung
The data that has been read from an \texttt{InputStream} are always put into a cache. Reading actions are therefore allowed to ``go back'' to already read data, by not issuing another direct access (which is anyway not possible using an \texttt{InputStream}), but by taking the data from the cache. ``Read ahead'' for areas that have not yet been reached on the \texttt{InputStream} lead to the behaviour tha all data up to the future offset us read and cached.
}
{% Begründung
This implements \DesLink{dd:407} nearly entirely, ``transparent'' to the user.
}
{% Nachteile
Even more heap space is necessary for \texttt{InputStream}s, as in extreme cases the whole medium might end up in the cache, which might lead to \texttt{OutOfMemoryError}s.
}
%%%% <-- DD %%%%

Of course, the disadvantages mentioned in \DesLink{dd:411b} are heavy-weigth. If you wouldn't do anything about it to mitigate this disadvantage, then \DesLink{dd:411b} would be nonsense, as the advantages of this approach would be dramatically overshadowed by its disadvantages.

As a first step, the following three design decisions are necessary:
%%%% DD --> %%%%
\DD{dd:411c}
{% Titel
The user can release cache content explicitly and can even disable caching entirely
}
{% Kurzbeschreibung
Releasing cache data can be done fine-grained for a specified offset range.

Thus the user himself can control the size of the cache, whereas it must be clear that any follow-up random-access reading will lead to repeated slow read access to the external medium (in case of a random-access medium) or to an exception (in case of an \texttt{InputStream}), respectively. The behaviour for \texttt{InputStream}s cannot be different as there is no data to return, and it cannot simple be read again, the stream has already progressed, there is no turning back in that case.

Moreover the user can disable caching entirely. Here, too, access to previously cached offsets is not possible for \texttt{InputStream}s and will be acquitted by an exception.
}
{% Begründung
The user is responsible to decide about the memory footprint: E.g. if the medium is comparatively small, caching can be tolerated. If it is a big medium, the user has two possibilities: Cleaning up the cache regularly (e.g. data first read starting at a size threshold), or he can even disable caching, however demanding a step-wise processing of the data.
}
{% Nachteile
The implementation of \COMPmedia{} gets more complex due to corresponding case decisions.
}
%%%% <-- DD %%%%

%%%% DD --> %%%%
\DD{dd:411d}
{% Titel
The \COMPmedia{} API allows the skipping of bytes for \texttt{InputStream}s
}
{% Kurzbeschreibung
Bytes must not necessarily be read and delivered to the user. Instead, skipping is possible via  (\texttt{skip}). For \texttt{InputStream}s skipping is a built-in functionality. For random-access skipping is not needed.
}
{% Begründung
The user can explicitly skip data that is not needed and can be ignored.

Second motivation is that \DesLink{dd:411b} in case of \texttt{InputStream}s makes it necessary to read a big number of bytes in case of reading data from higher offsets (i.e. areas that were not read yet) to finally get to the demanded offset were actually reading is to start. That of course might bloat the cache: E.g. assume current offset is 0, and the user wants to read 100 bytes starting from offset 1000. What to be done with the bytes between offsets 0 and 1000? Accorind to \DesLink{dd:411b}, these bytes must be read into the cache. However, with skipping there would be a second possible alternative.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%%%% DD --> %%%%
\DD{dd:411e}
{% Titel
Performance drawbacks of \texttt{InputStream}s are explicitly documented
}
{% Kurzbeschreibung
Reducing differences between \texttt{InputStream}s and files by caching in accordance to \DesLink{dd:411b} means: You must deal with the fact that you cannot store virtually unlimited \texttt{InputStream}s in a cache. For file access, the user can also choose between \texttt{FileInputStream} and more direct access via \texttt{RandomAccessFile}s. The performance drawbacks induced by using \texttt{FileInputStream} compared to  random-access \-- which are introduced by a unified API according to \DesLink{dd:411b} \-- are explicity described in the \LibName{} documentation. The mitigation mechanisms (skipping of bytes, releasing cache data, disabling caching) are explicitly described with their corresponding consequences.
}
{% Begründung
There are no wrong expectations by providing the unified API. The contract is described clearly enoughto the user. He must choose the medium best suited for his purpose.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

After these results, the disadvantages previously listed in table \hyperref[tab:CachingProCon]{\ref{tab:CachingProCon}} and in \DesLink{dd:411} need a closing look:
\begin{itemize}
\item Code Complexity: The higher code complexity cannot be disregarded. You have to accept it when implementing a permanent caching. It implies you need very good unit and integration tests to ensure it works as expected.
\item More Heap Memory: It is usual to achieve a better runtime performance by increasing the memory footprint. So it it shere. To nevertheless avoid \texttt{OutOfMemoryError}s, we have defined \DesLink{dd:411c}, \DesLink{dd:411d} and \DesLink{dd:411e} and thus give enough room for the user to avoid these situations.
\item Data Corruption due to Out-Of-Synch Medium: That the cache receives updates that are not yet persisted on the external medium is allowed according to \DesLink{dd:410}. A problem might arise due to changes by other processes or threads. These cannot be handeled in a general way by \LibName{}. Thus we have introduced the locking of media in \DesLink{dd:404}. Even this cannot give a full protection for some OSs. The user is in any case informed about irresolvabe inconsistencies by a runtime exception.
\end{itemize}

Implementing the discussed caching mechanisms is a big challenge. It will be more detailed in the implementation part of this component. Here, we can only exclude one way of implementing it:

%%%% DD --> %%%%
\DD{dd:412}
{% Titel
\texttt{MappedByteBuffer} will not be used to implement caching
}
{% Kurzbeschreibung
You could come with the idea to use the Java NIO class \texttt{MappedByteBuffer} for implementing the caching of \DesLink{dd:411}. However, we do not use it and implement another solution ``by hand''.
}
{% Begründung
It is not guaranteed, that the any OS supported by Java also supports a \texttt{MappedByteBuffer}. It is also not guaranteed that the data ``cached'' is really in RAM. For each concecutive region of a medium a new \texttt{MappedByteBuffer} instance including new OS call would need to be created. Thus this approach is unpredictable and might not in any case yield the wished for results.
}
{% Nachteile
The ``by hand'' caching is harder to implement.
}
%%%% <-- DD %%%%

At the end we shortly list a special case for of caching for byte array media:
%%%% DD --> %%%%
\DD{dd:412a}
{% Titel
For byte array media, caching is always disabled
}
{% Kurzbeschreibung
For byte array media, caching is always disabled
}
{% Begründung
byte arrays already are in RAM, caching would just be unncessary overhead
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%


% -------------------------------------------------------------------------------------------------------
\subsubsection{Reading Access to the Medium}%
\label{sec:LesenderZugriffaufdasMedium}%

The two-stage write protocol introduced in \SectionLink{sec:GrundSchreiben} brings up some questions regarding reading the data. The most important among these: What does the user need to consider after calling a writing operation (stage 1) and before \emph{flush}ing these changes (stage 2)? Especially: What do reading calls return after already having made changes, that are however not yet \emph{flush}ed? The possibilities we have:
\begin{enumerate}
\item Either the last persisted state on the medium after opening it or the last successful \emph{flush}, respectively,
\item Or already a state the includes any ``pending'' changes introduced by writing calls before the \emph{flush}?
\end{enumerate}
 
You could base your answer on the following: For sure alternative (2), as it is this way that transactions mostly work on databases: What you have already written during the transaction, you re-read later, too, even if the transaction is not yet persisted. However, the view of \LibName{} is as follows:

%%%% DD --> %%%%
\DD{dd:410c}
{% Titel
The user can only read what is currently persisted on the medium
}
{% Kurzbeschreibung
Even if there are pending changes not yet \emph{flush}ed (e.g. inserts, removes), with \COMPmedia{} the user can only see the latest flushed state.
}
{% Begründung
The changes the user has registered are coming form the user, and he thus could potentially keep bookmarks of them. Therefore their sole management by \COMPmedia{} is - at this point in time - not strictly necessary. Furthermore it must still be possible to read the data of a datablock that is threatened by a pending remove. 

Another good reason for this behaviour is that  the reading operations are much less complex, as they do not need to consider any pending changes. The code that reads data can be sure to always only work on a persistent state. Thus it cannot occur that logic is basing on data that is not yet persisted.
}
{% Nachteile
The expectation that ``what I have written before - even if pending - I can re-read afterwards'' is not fulfilled. The user must manage this for changed data by himself, at least temporarily until the next flush. 
}
%%%% <-- DD %%%%

In \SectionLink{sec:PerfMedia}, caching has been discussed in detail. For buffering, we first need an operation to do buffering without actually returning the buffered data:
%%%% DD --> %%%%
\DD{dd:412b}
{% Titel
Explicit operation for buffering of media data
}
{% Kurzbeschreibung
There is an operation \emph{cache} which buffers $n$ data bytes starting at a given offset, without returning this data. Additionally, there is an operation to query the number of bytes buffered concecutively starting at a given offset.
}
{% Begründung
Necessary for implementing \DesLink{dd:409}.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Additionally, you must be able to get your hands at the buffered data:
%%%% DD --> %%%%
\DD{dd:412c}
{% Titel
Explicit operation to get read data
}
{% Kurzbeschreibung
There is an operation \emph{getData} which returns $n$ data bytes starting at a given offset
}
{% Begründung
Without it there would not be any possibility to read data from a medium
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Now the question areises, how the operation \emph{getData} interacts with the cache, which is answered here:
%%%% DD --> %%%%
\DD{dd:412d}
{% Titel
\emph{getData} combines data from the cache with data form the medium and updates the cache thereby, if necessary
}
{% Kurzbeschreibung
\emph{getData} reads data from the cache, if they are entirely contained in it. Are they not entirely contained, \emph{getData} reads the bytes present in the cache, and reads the non-present ones from the medium, adding it to the cache afterwards. Thus data is combined from the two sources. The user can control for each call, if \emph{getData} behaves as mentioned previously or in any case directly accesses the medium, i.e. ignoring the cache, while still updating it.
}
{% Begründung
To ensure efficient reading, \emph{getData} can be used as such to fetch data from the cache, if anyhow possible, and only in other cases the medium must be accessed. The forced direct access is offered as additional possibility. Updating the cache by read data is useful, e.g. if the cache is very fragmented and the \emph{getData} result would reduce fragmentation.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

We want to define now how the read media data is represented:
%%%% DD --> %%%%
\DD{dd:412e}
{% Titel
Read media data is represented as read-only \texttt{ByteBuffer}
}
{% Kurzbeschreibung
Read data is not returned in the form of \texttt{byte} arrays, but as \texttt{ByteBuffer} instances that are read-only.
}
{% Begründung
Firstly, users can directly gain profit from conversion functions offered by \texttt{ByteBuffer}, on the other hand the implementation is more flexible when it comes to the content of the \texttt{ByteBuffer}, as only the bytes between \texttt{position()} and \texttt{limit()} can be read. Using this e.g. an internally managed, much bigger \texttt{ByteBuffer} object can be returned as a read-only view instead of copying it.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Let's discuss the topic of timeouts. In Java, each reading and writing I/O call might block. How to deal with this? The following design decision clearly states how.

%%%% DD --> %%%%
\DD{dd:426}
{% Titel
\LibName{} supports only reading timeouts, and this only for byte streams
}
{% Kurzbeschreibung
\COMPmedia{} only offers the possibility to configure timeouts in milliseconds for reading from byte streams.
}
{% Begründung
We assume that reading data from files takes a while and take into account that it might block. Reading data from files is, however, usually not a candidate for long or even any blocking. As the implementation of a timeout mechanism can be quite complex, we avoid to to this for files. For \texttt{InputStream}s, like media streams or socket connections, however, blocking is a quite possible case. Thus timeouts when reading from byte streams are really useful and \LibName{} offers to configure them. Writing operations forr byte streams are not supported according to \DesLink{dd:403}.
}
{% Nachteile
Higher complexity for byte stream implementation.
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------
%		API Layer Design
%-----------------------------------------------------------------------------------------------

\subsection{API Design}
\label{sec:InterfaceDesignCOMPmedia}

On the basis of the design decisions made in the previous section, we can now develop an API design for the component \COMPmedia{}. The API is the public interface of the component, i.e. all classes that can be used by other components to access the \COMPmedia{} functionality.

%-----------------------------------------------------------------------------------------------

\subsubsection{Reprasentation of a  \TERMmedium{}}
\label{sec:RepraesentationEinesTERMmedium}

The medium has appeared a lot of times already as a term, thus a representation as a class makes sense.

%%%% DD --> %%%%
\DD{dd:413}
{% Titel
Media are represented as interface and implementation class with following properties
}
{% Kurzbeschreibung
A medium is represented as Java interface \IMedium{} and allows users of \LibName{} to specify a concrete physical medium (i.e. the implementations of the interface \IMedium{}). As implementations we support a \FileMedium{} according to \DesLink{dd:400}, according to \DesLink{dd:401} aan \InputStreamMedium{} and according to \DesLink{dd:402} a \InMemoryMedium{}.

A medium has the following properties:
\begin{itemize}
	\item Is random-access: Yes/No \-- \textbf{Motivation:} This property has strong impact on the read and write process, yet it is an intrinsic property of the \TERMmedium{} itself and not of the access mechanism. Thus it is directly available for at a \TERMmedium{}.
	\item Currently exists: Yes/No \-- \textbf{Motivation:} Checking existence in Java can be done at the \TERMmedium{} level itself.
	\item Read-only: Yes/No \-- \textbf{Motivation:} This property disables writing in practice if set to ``Yes''. Some \TERMmedia{} can never be written (e.g. \texttt{InputStream}s), for others it is possible. This flag shall be used to also give the \LibName{} user a possibility to signal he wants to only access read-only.
	\item Current lenght in bytes (only relevant for random-access) \-- \textbf{Motivation:} Java offers queries for each kind of \IMedium{} except \texttt{InputStream}. Thus this should be implemented directly in the \IMedium{} implementation. For \texttt{InputStream} and non-random-access media in general, terms like length to not make much sense. Thus here there is no value, but a constant indicating an unknown length. In spirit pf design decision \DesLink{dd:410}, it is a currently persisted lenght and not a length including any not-yet persisted changes.
	\item A clear text name of the \TERMmedium{} \-- \textbf{Motivation:} This is helpful for identification purposes of the \IMedium{} e.g. in log output. It can be derived from e.g. a file name, depending on the medium type.
	\item The ``wrapped'' object representing the raw medium or its access mechanism, e.g. the file, the \texttt{InputStream} or the byte array.
\end{itemize}
}
{% Begründung
It can be controlled in detail which medium types are supported. The user can specify the medium to use in a comfortable way. Further API parts get more easier, as their interfaces must not distinguish between different media types, but rather only use the abstaction that \IMedium{} offers. Motivation for each of the properties see the listing above.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Due to consistency reasons there are some restrictions regarding the manipulation of media properties:

%%%% DD --> %%%%
\DD{dd:414}
{% Titel
If a \IMedium{} implementation is writable, it must also be random-access
}
{% Kurzbeschreibung
Every in principle writable \IMedium{} implementation must be random-access, too. 
}
{% Begründung
The \LibName{} APIs for writing content can thus concentrate on random-access output media. No separate API design and implementation for output media that are not random-access is necessary. The API gets easier for end-users. Lack of non-random-access output media such as \texttt{OutputStream}s can be mitigated via the examples in \DesLink{dd:403}.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Here is a very importante note for byte array media:
%%%% DD --> %%%%
\DD{dd:414b}
{% Titel
For byte array media, a writing method for resetting the whole byte array is necessary
}
{% Kurzbeschreibung
The user can reset the bytes of the medium via a public method \texttt{setBytes()} of class \InMemoryMedium{}.
}
{% Begründung
It is mostly not harmful to offer the method as public, it is even an advantage for the users, as he can set the bytes himself. Only between registering write operations and a flush, this call leads to unexpected behaviour.

This methode is very important for the implementation: Via writing actions, the byte array must be extended or shrinked in some situations. This basically means reacreating and copying the array. The method must thus be public, as the corresponding implementation funcitonality will be for sure placed in another package.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{Positions in and Lengths of a \TERMmedium{}}
\label{sec:PositiZugriffEinesTERMmedium}

In each case where dare is read from or written to a \TERMmedium{}, the question ``where?'' arises. Usually libraries use integer or long variables to represent offsets. It must be said however: Offsets do not only make sense for random-access media. You could also interpret them as offset since start of reading from an \texttt{InputStream}, which is actually the way it is done in \LibName{}. We decide:

%%%% DD --> %%%%
\DD{dd:415}
{% Titel
Byte offsets are used for any kind of \TERMmedia{}
}
{% Kurzbeschreibung
Byte offsets that refer to a position on a \TERMmedium{} are used for all media types: random-access and non-random-access. For byte streams they refer to the position of the current byte since start of reading the first byte after opening the stream, which has offset 0. The offset-based reading is simulated as specified in \DesLink{dd:407} and \DesLink{dd:411b}, because when directly reading from an \texttt{InputStream} via Java API, offsets are not needed, it is always read from the current position of the stream. 
}
{% Begründung
We must therefore distinguish between random-access and non-random-access only at a few places in the implementation. Users can use the API uniformly and irrespective of the actual medium type (with restrictions: see \DesLink{dd:411e}).
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

It makes not so much sense to represent offsets only via a primitve data type. Instead, the representation as a user-defined data type offers some advantages:

%%%% DD --> %%%%
\DD{dd:416}
{% Titel
\LibName{} uses the interface \IMediumReference{} to represent offsets on a \TERMmedium{}.
}
{% Kurzbeschreibung
The interface binds both the \TERMmedium{} and the offset on this \TERMmedium{} together, and thus is a kind of ``global'' address of a byte. Next to reading medium and of offset, it offers some helper methods:
\begin{itemize}
\item \texttt{behindOrEqual():} Returns true if another \IMediumReference{} is located on the same medium behind of at the same position as this instance.
\item \texttt{before():} Returns true if another \IMediumReference{} is located on the same medium before the position of this instance.
\item \texttt{advance():} Creates a new \IMediumReference{} that is located by the given byte number before (negative argument) or after (positive argument) this instance.
\end{itemize}
}
{% Begründung
We clearly state how the library deals with offsets. We can thus implement some helper functions into the datatype (e.g. validation, offset comparison, advance etc.) which ensure reuse and ease working with offsets in general.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Now we come to a central decision when it comes to dealing with lengths and offsets:

%%%% DD --> %%%%
\DD{dd:417}
{% Titel
\LibName{} uses long for length and offset specifications, byte is always its unit
}
{% Kurzbeschreibung
In \LibName{}, lenghts and offsets are always specified using the Java datatyp long. The lenght is in any case the number of bytes, offsets are zero-based, linearly increasing byte offsets.
}
{% Begründung
This guarantees uniformity. However, we also want to meet the requirement \SectionLink{sec:ANF009LesenSchreibenGrosse}. Integer with a maximum of 4.3 GB is already too limited, which leaves only long as a viable option. The datatype long allows for positive numbers up to $2^{63}-1=9223372036854775807$, i.e. approximately $9\cdot 10^{18}$ bytes, which is 9 exabytes or 9 billion gigabytes. From current point of view, such lenghts and offsets for input media, even for streams, should be sufficient for some decades to come. Furthermore, big data chunks are almost in any case subdivided in small units that can be easier handled, and these small units will not have big lengths. Even the Java file I/O uses long as offset and length datatype in most cases.
}
{% Nachteile
More memory for saving offsets and lengths is necessary. If we look at the development of storage media, storage needs and processing speed it might be that in 100 years the maximum data volume of long will be reached. If \LibName{} is still used in these future scenarios, a change request would be worth it!
}
%%%% <-- DD %%%%

A rather seldom special case is dealt with in the following design decision:

%%%% DD --> %%%%
\DD{dd:418}
{% Titel
No special handling of long overflows
}
{% Kurzbeschreibung
For unusal long uninterrupted reading from \texttt{InputStream} you could think that even when using long, it could come to an overflow in some time. This is however very unlikely, thus this case is not treated. The implementation always assumes taht the current offset is positive and can be incremented without reaching the max long number.
}
{% Begründung
Even here it holds true: The datatype long allows positive numbers up to $2^{63}-1=9223372036854775807$. Let us assume that an implementation could make it to process 10 GB per second, then it would still need 9 billion seconds, i.e. nearly 30 years, to reach the offset limit and create an overflow.
}
{% Nachteile
No disadvantages knownn
}
%%%% <-- DD %%%%

Now the problem arises that the medium changes due to writing access. How do the offsets change in this case? Is it necessary to update already created \IMediumReference{} instances according to the changes on the mediums, or not? If yes, when this needs to happen? In principle, we could see following alternatives:
\begin{enumerate}
\item Never update already created \IMediumReference{} instances
\item Update already created \IMediumReference{} instances directly for each pending change registered (see \DesLink{dd:410})
\item Update already created \IMediumReference{} instances only when an explicit \emph{flush} according to \DesLink{dd:410} occurs
\end{enumerate}

Assume that \IMediumReference{} instances are not updated when writing. That means the user code remembers a position of an element in form of a \IMediumReference{} instance, and uses it to read or write data. If e.g. an inseration operation takes place on the medium before the offset of the \IMediumReference{} instance, then the instance refers to another data byte than before, and thus not anymore to the object it was referring to initially. We should not only think of raw bytes but - as necessary for data formats - \emph{objects}, i.e. parts of the binary data that form a specific unit with which has a specific meaning, representing something. Then failure to update the offset is fatal. Code using \COMPmedia{} locates an object at the wrong place if the medium changed before that offset meanwhile.

To formulate the following design decision a bit easier, the vague term of ``Object'' used above is now defined a bit sharper: An object is a consecutive byte unit starting at aspecific offset $x$ and it has a length of $n$ bytes. \texttt{remove}, \texttt{insert} and \texttt{replace} in the offset interval $[x,x+n]$ change these objects, which cannot be in any case specifically treated by \COMPmedia{}.

%%%% DD --> %%%%
\DD{dd:418b}
{% Titel
\COMPmedia{} needs to automatically update \IMediumReference{} instances after medium changes
}
{% Kurzbeschreibung
All \IMediumReference{} instances ever created for a medium must be updated automatically whenever this medium changes. The kind of update needed is more complex than you would think on first glance. 

Let $y$ be the insert or remove offset and $k$ the number of bytes to insert or remove. Let $\overline{x}$ be the offset of the \IMediumReference{} instance after updating. Then the following detailed rules apply:
\begin{itemize}
\item \emph{\texttt{insert} before the object start offset:} Is $y\leq x$, then $\overline{x}:=x+k$. I.e. this includes the case that new bytes are inserted exactly at offset $x$.
\item \emph{\texttt{insert} behind the object start offset:} Is $y>x$, then $\overline{x}:=x$, i.e. it does not change the start offset of the object, and this even in the case that $y<x+n$, i.e. the action happens \emph{within} the object. If and how this changes the object semantically is lying in the hands of the user and cannot be recognized or interpreted by \LibName{}.
\item \emph{\texttt{remove} before the object start offset without overlap:} Is $y+k \leq x$, then $\overline{x}:=x-k$. Thus $k$ bytes are removed before the object, however the removed region does not overlap with the object.
\item \emph{\texttt{remove} before the object start offset with overlap:} Is $y \leq x$, but $y+k > x$, then the removed region overlaps the object. It is thus a \emph{truncation} of the object starting at front, and it might even reduce the object to length 0. Thus the start offset of the object shifts $x-y$ to be equal to $y$, thus it follows that $\overline{x}:=y$. If and how this changes the object semantically is lying in the hands of the user and cannot be recognized or interpreted by \LibName{}.
\item \emph{\texttt{remove} behind the object start offset:} Is $y>x$, then $\overline{x}:=x$, i.e. the object start offset remains unchanged, of course also in the case that $y<x+n$. In the latter case, however, the object is truncated at its end. If and how this changes the object semantically is lying in the hands of the user and cannot be recognized or interpreted by \LibName{}.
\item \emph{\texttt{replace}:} Replacing $n$ bytes by $m>n$ bytes has the same effect to existing objects as an \texttt{insert}, with the very same case distinctions. Likewise, \texttt{replace} behaves like \texttt{remove} if $m<n$. The case $m=n$, i.e. an \emph{overwrite} operation does not lead to any offset changes of existing objects.
\end{itemize}
}
{% Begründung
The connection between an \IMediumReference{} instance and an object is a viable picture and quite illustrates the real use case behind manipulating raw binary data. Due to this design decision, this connection persists - from point of view of the caller - even in case of writing changes to the medium. We cannot burden the user with keeping track of these changes as he would need to manage \IMediumReference{} himself in a complex way, listing which operations he has done. This complex book-keeping is what you would expec from a component such as \COMPmedia{}.

If all bytes of the object are removed, then the \IMediumReference{} instance still refers to the ``previous'' location of the object. The user must not ensure that the \IMediumReference{} instance still refers to the same object.
}
{% Nachteile
A central management of \IMediumReference{} instances must be implemented (see \DesLink{dd:419}).
}
%%%% <-- DD %%%%

As already indicated by \DesLink{dd:418b} the automatic updating of already created \IMediumReference{} instances requires that only \COMPmedia{} may create \IMediumReference{} instances. These must be managed in a kind of pool to be able to automatically update them in case of writing operations.

%%%% DD --> %%%%
\DD{dd:419}
{% Titel
\IMediumReference{} instances are centrally managed by \COMPmedia{} and cannot be directly created by users of the component
}
{% Kurzbeschreibung
The lifecycle of \IMediumReference{} instances is controlled by \COMPmedia{}. They are created and returned to the user via a factory method.
}
{% Begründung
It is strictly required to implement \DesLink{dd:418b}. Instances that have been created by the user cannot be update automatically, thus we have to ensure the manual creation by the user does not happen.
}
{% Nachteile
More complex instantiation of \IMediumReference{} instances.
}
%%%% <-- DD %%%%

The question \emph{when} to update \IMediumReference{} instances has still not been answered yet. The following design decision clearly defines this:

%%%% DD --> %%%%
\DD{dd:419b}
{% Titel
\IMediumReference{} instances are only updated after a \emph{flush}
}
{% Kurzbeschreibung
According to \DesLink{dd:418} \IMediumReference{} instances are automatically updated in case of medium changes. This automatic update only happens at \emph{flush} time.
}
{% Begründung
Assumed that \IMediumReference{} instances would already be updated whenever a pending change is registered using \emph{insert}, \emph{replace} or \emph{remove}. In this case the following would be necessary:
\begin{itemize}
\item When reading data, this data is not necessarily in a cache. This indicates that reading from external medium is necessary. If all \IMediumReference{} instances would reflect a state including any pending changes, they would no longer correspond to the state of the external medium. If you would now want to read or write to the external medium, the real offset on the external medium would need to be ``reconstructed'' based on the changes made so far, everytime you want to know where current data resides on the medium. This implies a complex coding overhead that would not ease debugging errors or understanding the current state of instances.
\item The operation \texttt{undo} according to \DesLink{dd:420} requires that offsets would need to be ``re-adapted'' if a pending changes is undone again. Again this is additional complexity.
\end{itemize}
If \IMediumReference{} instances in contrast are first updated after a \emph{flush}, then no reconstruction of original offsets based on already made changes is necessary.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

This directly implies the following design decision:

%%%% DD --> %%%%
\DD{dd:421}
{% Titel
In \COMPmedia{}, offset specifications always are offsets on the external medium as it was looking like after the last \emph{flush} or after opening it initially
}
{% Kurzbeschreibung
For operations of \COMPmedia{} that take an offset as argument, this offset refers to a location on the external \TERMmedium{} after the last \emph{flush} or the initial opening - in case no \emph{flush} has occurred yet. These offsets must especially be located within the interval $[0, \text{length}]$, where ``length'' is the current length of the medium in bytes.
}
{% Begründung
Naturally follows from \DesLink{dd:419b}. For users, the offset situation remains stable and logical, he does not need to maintain a history of \emph{insert}, \emph{replace} and \emph{remove} operations. Likewise, the offsets stay stable for the implementation, too: Checking offsets and organisation of internal data structures can be based on this invariant.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{Semantic of Writing Operations}
\label{sec:SemantikSchreib}

In \DesLink{dd:410d}, we have defined the primitive writing operations \emph{insert}, \emph{replace} and \emph{remove} that are essential for \COMPmedia{}. In the same section, we have listed basic requirements for writing that lead to these operations. The API of \COMPmedia{} includes their guaranteed behavior. It is very important to define interrelations between these operations, especially how they behave for overlapping offset areas of the medium. These things are defined by the following design decisions. The behaviors are part of the API contract and must be documented as such for the API users.

We start with the operation \emph{insert}:

%%%% DD --> %%%%
\DD{dd:422}
{% Titel
\emph{insert} concatenates insertions in call order, the operation is not influenced by any other writing operations
}
{% Kurzbeschreibung
The temporal order of calls have the following semantics:
\begin{enumerate}
\item Step 1: \emph{insert}, Step 2: \emph{insert} at the same offset: \emph{insert} concats, each call with the same offset determines a new, consecutive insertion, i.e. insertions at the same medium location are done with increasing offsets. Let's take two calls to \emph{insert} at the same offset $x$. Let ``Call 1'' be the earlier call with insertion length $n_1$, ``Call 2'' the later call at $x$ with insertion length $n_2$. The end result on the medium after \emph{flush} is:
\begin{itemize}
\item At offset $x$, the insertion data of ``Call 1'' is located
\item At offset $x+n_2$, the insertion data of ``Call 2'' is located
\end{itemize}
\item Step 1: \emph{insert}, Step 2: \emph{remove} at same offset: Do not influence each other.
\item Step 1: \emph{insert}, Step 2: \emph{replace} at same offset: Do not influence each other.
\item Step 1: \emph{insert} at offset $x$, Step 2: \emph{replace} $m$ bytes by $n$, starting at offset $y$, where $x>y+m$, i.e. the insertion does not happen within the replacement region, but behind: These operations do not influence each other. This includes the case that $m>n$, i.e. an override operation with a removal, and $x\in[y,y+m)$, i.e. the insertion does not happen within the replacement region, but behind.
\item Step 1: \emph{insert} at offset $x$, Step 2: \emph{replace} $m$ bytes by an arbitrary number of new bytes, starting at offset $y$, where $x\in (y,y+m)$: Put in other words, the bytes to replace contain the prior insertion. Here, the second call is invalid and rejected with an exception.
\item Step 1: \emph{insert} at offset $x$, Step 2: \emph{insert} at offset $y\neq x$: Do not influence each other.
\end{enumerate}
}
{% Begründung
For (1): You could alternatively interpret ``insert'' as such that the second call inserts data \emph{before} the previous earlier one. However, the design decision says that ``insert'' inserts before the currently persisted medium byte at the insertion offset. Concatenating allows user code to linearly insert stuff with increasing offsets, which is in most cases the convenient and expected behavior. For (2), (3) and (4): As offsets refer to offsets on the external medium according to \DesLink{dd:410b}, \emph{remove} and \emph{replace} only affect bytes that are currently persisted on the external medium, they thus cannot remove any pending content of a prior \emph{insert} not yet \emph{flush}ed. For (5): Otherwise complex logic is necessary to mix insertion bytes into replacement bytes. The user can achieve the same by simply including the insertion bytes in the replacement bytes starting at offset $y$.
}
{% Nachteile
For (1): You could alternatively interpret ``insert'' as such that the second call inserts data \emph{before} the previous earlier one. However, the design decision says that ``insert'' inserts before the currently persisted medium byte at the insertion offset. With concatenating, user code can linearly insert stuff with increasing offsets, which is mostly the expected behavior.
}
%%%% <-- DD %%%%

The operation \emph{remove} behaves as follows:

%%%% DD --> %%%%
\DD{dd:424}
{% Titel
\emph{remove} allows no overlaps, only later calls with bitter region make earlier calls obsolete
}
{% Kurzbeschreibung
The following temporal order of calls have the described semantics:
\begin{enumerate}
\item Step 1: \emph{remove} $n$ bytes at offset $x$, Step 2: \emph{remove} or \emph{replace} $m$ bytes at offset $y\leq x$ with $y+m\geq x+n$: When calling \emph{remove} twice or first \emph{remove}, then \emph{replace}, where the second call fully contains the offset region of the first, the earlier call is declared as invalid and is not processed during a \emph{flush}. Of course this is also true for all earlier calls, not only the last one.
\item Step 1: \emph{remove} $n$ bytes at offset $x$, Step 2: \emph{remove} or \emph{replace} $m$ bytes at offset $y\in (x,x+n)$ with $y+m<x+n$: The first call fully contains the region of the second call. The second call is invalid and rejected with an exception.
\item Step 1: \emph{remove} $n$ bytes at offset $x$, Step 2: \emph{remove} or \emph{replace} $m$ bytes at offset $y\in (x,x+n)$ with $y+m\geq x+n$: The second call is an overlapping call, that probably removes additional bytes behind the first remove call, but still includes the end of the first call. The second call is invalid and rejected with an exception.
\item Step 1: \emph{remove} $n$ bytes at offset $x$, Step 2: \emph{remove} or \emph{replace} $m$ bytes at offset $y \leq x$ with $y+m<x+n$: In this case there is an overlap from the start. The second call is invalid and rejected with an exception.
\item Step 1: \emph{remove} $n$ bytes at offset $x$, Step 2: \emph{insert} at offset $y\in [x,x+n)$: As the insert call according to \DesLink{dd:410b} refers to offsets on the external medium, here first $n$ bytes present on the medium are removed, then the new bytes are inserted after the last byte persisted, i.e. at offset $x$.
\item Step 1: \emph{remove} $n$ bytes at offset $x$, Step 2: \emph{remove} or \emph{replace} at offset $y$ without any overlaps to $[x,x+n)$: Do not influence each other.
\end{enumerate}
}
{% Begründung
There are no accidental multiple removals or replaces. For (1): It may happen that the user first removes a chield field, and additionally still before the flush \texttt{flush}, he removes the parent block. For (2) to (4): Would we allow the second calls, we would need to change the remove areas of the first calls. This leads to a more complex logic, that is not necessary according to the requirements stated in \SectionLink{sec:AnforderungenandaszweistufigeSchreibprotokoll}. A very important reason to not allow this is implementation of \texttt{undo}: Would we allow later changes of already made calls, then \texttt{undo} would be quite complex, because it would need to also undo such changes to removed regions, what basically means keeping a history of all changes made for the same region.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

The operation \emph{replace} behaves like this:

%%%% DD --> %%%%
\DD{dd:424a}
{% Titel
\emph{replace} does not allow overlaps, only later calls with bigger reagions make earlier calls obsolete
}
{% Kurzbeschreibung
The behaviour of \emph{replace} mostly matches the behavior of \emph{remove}, as described in cases 1 to 4 of \DesLink{dd:424}. You only have to replace \emph{remove} by \emph{replace} in the description of \DesLink{dd:424} :-). \emph{replace} interacts with an insert the same way as described in \DesLink{dd:422} for the inverse order which are cases 5 to 7:
\begin{enumerate}
\item[1.] to 4. Exactly the same as described in \DesLink{dd:424} with \emph{replace} as first step.
\item[5.] Step 1: \emph{replace}, Step 2: \emph{insert} at the same offset: These operations do not influence each other.
\item[6.] Step 1: \emph{replace} $m$ bytes by $n$, starting at offset $y$, Step 2: \emph{insert} at offset $x$, where $x>y+m$, i.e. the insertion does not happen within the replacement region, but behind: These operations do not influence each other. This includes the case that $m>n$, i.e. an override operation with a removal, and $x\in[y,y+m)$, i.e. the insertion does not happen within the replacement region, but behind.
\item[7.] Step 1: \emph{replace} $m$ bytes by an arbitrary number of new bytes, starting at offset $y$, Step 2: \emph{insert} at offset $x$, where $x\in (y,y+m)$: Put in other words, the bytes to replace contain the later insertion. Here, the second call is invalid and rejected with an exception.
\item[8.] Step 1: \emph{replace} at offset $x$, Step 2: \emph{remove} or \emph{replace} at offset $y$ without any overlaps: Do not influence each other.
\end{enumerate}
}
{% Begründung
See \DesLink{dd:422}, cases 1 to 4 and \DesLink{dd:422}, cases 3 to 5
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Another problem: How to map the actual data to a data block before a \emph{flush}? The offset alone is not unique anymore in the face of multiple \emph{insert}s at the same offset before their \emph{flush}. If you now want to relate an action (\emph{insert}, \emph{remove}, \emph{replace}) data to its (current or future) offset, the offset alone is not sufficient to state clearly which action happened first at the offset.

An answer is given in the following design decision that explains how action, data and offset are brought into close relation:
%%%% DD --> %%%%
\DD{dd:424b}
{% Titel
Each of the writing operations returns an instance of a class \MediumAction{} to describe the action in more detail
}
{% Kurzbeschreibung
This class contains following data:
\begin{itemize}
\item The kind of action (\emph{insert}, \emph{replace}, \emph{remove}); \textbf{Motivation:} The user must be able to know the kind of change
\item \IMediumReference{} of the action; \textbf{Motivation:} It must be clear where the change happened or must happen
\item Data of the action (length or bytes to write); \textbf{Motivation:} It must be clear what needs to be changed.
\item Number of actually affected medium bytes (0 for \emph{insert}, number of bytes to remove for \emph{remove}, number of bytes to replace for \emph{replace}; \textbf{Motivation:} For \texttt{replace} only one length is not enough as the number of bytes to replace may be different from the length of the replacement bytes.
\item Validty: Handle is already persisted by a \emph{flush} or still pending; \textbf{Motivation:} Thus it can be clearly state from outside whether the data must still be persisted and thus must be taken from the instance of the user requires to read them, or the data has already been written to the external medium.
\end{itemize}
}
{% Begründung
According to \DesLink{dd:410c}, the user can only read data that is currently persisted.

Nevertheless it is necessary that application code can also re-read data previously registered for writing, but not yet persisted by a \emph{flush}. That now becomes possible with the \MediumAction{} class that is returned by \emph{insert}, \emph{replace} and \emph{remove}. Is the \MediumAction{} still pending, the application code can return the pending bytes from the \MediumAction{}, otherwise by directly accessing the  \COMPmedia{} read functionality to fetch the currently persisted bytes.

Instances of \MediumAction{} can ideally be used for internal data management by \COMPmedia{}.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{End medium access}
\label{sec:ZugriffEinesTERMmediumBEEN}

We still need an operation to end the medium access, thus we define:
%%%% DD --> %%%%
\DD{dd:419ac}
{% Titel
Operation \emph{close} ends the medium access and empties the cache, consecutive operations are not possible on the medium
}
{% Kurzbeschreibung
A user can manually end medium access by calling \emph{close}. It is then no longer possible to access the medium via the closed access way. The user must explicitly reopen the medium to access it again.
}
{% Begründung
The implementation works with OS resources such as files that must be closed. Furthermore cache content and other memory is not freed anytime if you could not close the medium.

Closing cannot be implemented automatically but must be explicity called by the user.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{The public API of medium access}
\label{sec:ZugriffEinesTERMmedium}

Based on the previous design decisions we now design the public API of the component \COMPmedia{}. Until now, we only introduced the classes \IMediumReference{}, \IMedium{} and \MediumAction{} as well as some abstract operations to deal with media. How do we offer these operations to users? This is explained by the following design decision.

%%%% DD --> %%%%
\DD{dd:419c}
{% Titel
Access to a medium is done using the \IMediumStore{} 
}
{% Kurzbeschreibung
The reading and writing access to a medium (both random-access as well as byte stream according to \DesLink{dd:407}) is offered via interface \IMediumStore{} with the operations listed in table \hyperref[tab:MediaOps]{\ref{tab:MediaOps}}.
}
{% Begründung
A further subdivision of functionality into more than one interface is neither necessary nor helpful. It would just be an unneccessary complex API, and despite the single interface, the implementation can still be modularized as needed. The individual operations are motivated in the table itself.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

\small
\begin{landscape}
\begin{longtable}{|p{0.2\linewidth}|p{0.25\linewidth}|p{0.25\linewidth}|p{0.25\linewidth}|}
	\hline
	\rowcolor[gray]{.9}\textbf{Operation} & \textbf{Description} & \textbf{Features and motivation random-access} & \textbf{Features and motivation \texttt{InputStream}} \\
	\endhead
	\hline
	\texttt{cache()} & Buffers $n$ bytes according to \DesLink{dd:409} and \DesLink{dd:412b} permanently in the internal cache, starting at the given offset $x$. Has effect if caching is enabled. & User code can prefetch data to work on it later, he himself gets the possibility to efficiently read and process data. & If $x$ is smaller than the current highest read offset, a \texttt{InvalidMediumReferenceException} is thrown. Additionally: Is it bigger than the current highest read offset, the bytes up to the new offset are read or \emph{skip}ped (depending on current configuration). Afterwards the actually requested bytes are read. This ensures that all bytes are available in principle. The last read offset is advanced correspondingly. \\
	\hline
	\texttt{getCachedByteCountAt()} & According to \DesLink{dd:409} and \DesLink{dd:412b}, it provides the nuimber of bytes that are consecutively cached at offset $x$. & See \texttt{cache()}. User code must be able to additionally check whether enough data is already buffered or not. & See random-access.\\
	\hline
    	\texttt{getData()} & Reads $n$ bytes at offset $x$ with the given mode (\texttt{forceMediumAccess} = \texttt{true} or \texttt{false}) according to \DesLink{dd:410c}, \DesLink{dd:412c}, \DesLink{dd:412d} & With \texttt{forceMediumAccess} = \texttt{false}: It first tries to read the data from the cache, are they (partly) not available, the missing data is directly read from external medium. With \texttt{forceMediumAccess} = \texttt{true}: Data is always directly read from external medium, cache is ignored. In both cases, the cache will be updated with data newly read from external medium. Furthermore, only when caching is active, the method actually accesses the cache, in both cases. & \texttt{forceMediumAccess} is ignored. If there is data for the given offset in the cache, the data is returned. If it is not, a \texttt{InvalidMediumReferenceException} is thrown. Thus, for \texttt{InputStream}s, a call to \texttt{cache()} is mandatory before reading can actually start. \\
	\hline
	\texttt{isAtEndOfMedium()} & Checks if offset $x$ is at the end of the \TERMmedium{}. & Based on this knowledge, the user code can skip further reading and does not need to check for exceptions. & The provided offset is ignored, it is tried to read bytes from current offset. Is this resulting in return code -1, we are at the end of the stream, otherwise the byte is added to the cache. \\
	\hline
	\texttt{skip()} & Skips $n$ bytes according to \DesLink{dd:411d} & Simply does nothing, as skipping does not give any advantages here. & Skips $n$ bytes by calling \texttt{InputStream.skip(n)}. It allows users to ignore unimportant bytes explicitly, to e.g. save memory when caching is active. The last read offset is advanced correspondingly. \\	
	\hline
	\texttt{discard()} & Removes up to $n$ bytes from the cache starting at offset $x$ according to \DesLink{dd:411c}. Allows user code to free up memory to avoid unnecessarily allocated heap. & Buffering and reading data again with \texttt{getData()} is always possible. & After freeing up memory with \texttt{discard()}, the attempt to access freed offset ranges for an \texttt{InputStream} using \texttt{getData()} leads to an \texttt{InvalidMediumReferenceException}.\\
	\hline
	\texttt{insertData()} & Implements the writing operation \emph{insert} according to \DesLink{dd:410}, \DesLink{dd:410d} and  \DesLink{dd:422}: Adds data at the given offset, consecutive bytes are shifted ``to the back'', the changes first get written only with \texttt{flush()}. & The insertion of new metadata is a common case in \LibName{} and must be supported. & \texttt{ReadOnlyMediumException} \\
	\hline
	\texttt{removeData()} & Implements the writing operation \emph{remove} according to \DesLink{dd:410}, \DesLink{dd:410d} and \DesLink{dd:424}: Removes $n$ bytes at offset $x$. Consecutive bytes are shifted ``to front'', the changes first get written only with \texttt{flush()} & Removing existing metadata is a standard case in \LibName{} and must be supported. & \texttt{ReadOnlyMediumException} \\
	\hline
	\texttt{replaceData()} & Implements the writing operation \emph{replace} according to \DesLink{dd:410}, \DesLink{dd:410d} and  \DesLink{dd:422}: Replaces $n$ bytes at offset $x$ with new bytes of length $m$. The changes first get written only with \texttt{flush()} & It often happens that \--- instead of entirely removing or newly inserting data \--- existing data must be overwritten. This is - especially at the beginning of a file - a much more efficient operation than insertion and deletion and must thus directly be supported. & \texttt{ReadOnlyMediumException}\\
	\hline
	\texttt{flush()} & Implements the writing operation \emph{flush} according to \DesLink{dd:410}: All \emph{changed} data currently in the temporary buffer are written in a suitable way to the external medium. It cannot be guaranteed that this operation is atomic. & This is a practical implementation of \DesLink{dd:410}: While \texttt{insertData()}, \texttt{removeData()} and \texttt{replaceData()} only write into a temporary buffer, this call directly writes to the external medium. & \texttt{ReadOnlyMediumException} \\
	\hline
	\texttt{createMediumReference()} & Creates a new \IMediumReference{} instance for the given offset $x$ according to \DesLink{dd:419} & Is needed for random-access & Is needed for \texttt{InputStream}s \\
	\hline
	\texttt{undo()} & Undoes the changes of the given \MediumAction{} according to \DesLink{dd:420}, as far as it is still pending. & Is needed for random-access & \texttt{InvalidMediumActionException} \\
	\hline
	\texttt{close()} & Closes all internal resources according to \DesLink{dd:419ac}, clears the complete cache contents and other internal data structures & See \DesLink{dd:419ac} & See \DesLink{dd:419ac} \\
	\hline
\caption{Operationen der \COMPmedia{} API}
\label{tab:MediaOps}
\end{longtable}
\end{landscape}
\normalsize

%-----------------------------------------------------------------------------------------------

\subsubsection{The component interface}
\label{sec:ErrorConditionsSS}

How are the public functions exposed to the outside world? There must be a functionality that creates a \IMediumStore{} instance for a given \IMedium{}. The API for this looks as follows:

%%%% DD --> %%%%
\DD{dd:428}
{% Titel
\IMediaAPI{} is the central entry point with creation functions for \IMediumStore{}s
}
{% Kurzbeschreibung
The interface \IMediaAPI{} offers the central entry point for the component \COMPmedia{}. Using the method \texttt{createMediumStore()}, users can create an \IMediumStore{} instance.
}
{% Begründung
The necessity for a further interface in addition to \IMediumStore{} is clear enough: A \IMediumStore{} refers to just a single ``medium access session'' for a medium, and of course users want to be able to open multiple media at the same time using \COMPmedia{}. Pushing creation functions into \IMediumStore{} is not considered good practice as it would decrease comprehensibilty.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{Error Handling}
\label{sec:ErrorConditions}

In general violations of the interface contract according to \DesLink{dd:205} are acquitted with a runtime exception.

The following table summarizes all further error situations when working with \COMPmedia{}:

\begin{landscape}
\begin{longtable}{|p{0.15\linewidth}|p{0.31\linewidth}|p{0.31\linewidth}|p{0.18\linewidth}|}
	\hline
	\rowcolor[gray]{.9}\textbf{Error Scenario} & \textbf{Description} & \textbf{Reaction \LibName{}} & \textbf{API method} \\
	\endhead
	\hline
	Medium does not exist & The medium does not exist, in \LibName{} however it must be an existing medium. & It is an abnormal situation, thus a \texttt{MediumAccessException}runtime exception is thrown. & \IMediaAPI{} \texttt{.createMediumStore()} \\
	\hline
	Medium is already locked & The medium is already locked by another process. \LibName{} cannot work with the medium. It is the burden of the caller to ensure, that the medium is not used in parallel. & It is an abnormal situation, thus a\texttt{MediumAccessException}runtime exception is thrown. & \IMediaAPI{} \texttt{.createMediumStore()} \\
	\hline
	Unknowm media type & A \IMedium{} implementation is specified by the caller which is unsupported. & This is an abnormal situation violating the interface contract, thus the same exception as for contract violations is thrown. & \IMediaAPI{} \texttt{.createMediumStore()} \\
	\hline
	End of medium during reading & Of course each medium has an end sometimes. When reading, this end can be reached. When writing, this is not actually possible - there, we assume that all output media virtually are unlimited. If there is no more memory for writing, \COMPmedia{} usually reacts with a \texttt{MediumAccessException} following an \texttt{IOException}. It cannot be requested from the calling code during reading, that it knows where the end of the input medium is. Reaching its end during reading can be an error, but it needs not - this depends on the current usage situation. The calling code thus must handle this depending on current context. & Because it is not necessarily an abnormal situation, a \texttt{EndOfMediumException} checked exception is thrown. & \IMediumStore{} \texttt{.cache()}, \IMediumStore{} \texttt{.getData()} \\
	\hline
	Timeout during reading & A reading call fo the medium does not return after a configured timeout. & It is an abnormal situation, thus a \texttt{ReadTimedOutException} runtime exception is thrown. & \IMediumStore{} \texttt{.cache()}, \IMediumStore{} \texttt{.getData()} \\
	\hline
	Write to read-only medium & The user-provided \IMedium{} implementation is read-only, thus it only allowes read access. & If the user nevertheless tries to write, this is an abnormal sitation and is signalled by a \texttt{ReadOnlyMediumException} runtime exception. & \IMediumStore{} \texttt{.flush()}, \IMediumStore{} \texttt{.insertData()}, \IMediumStore{} \texttt{.removeData()}, \IMediumStore{} \texttt{.replaceData()}\\
	\hline
	Consecutive write calls overlap & Concecutive calls to \texttt{removeData} or \texttt{replaceData} before a \texttt{flush} overlap in an invalid way (see \DesLink{dd:424} and \DesLink{dd:424a}) & Is acquitted with an \texttt{InvalidOverlappingWriteException} runtime exception. & \IMediumStore{} \texttt{.removeData()}, \IMediumStore{} \texttt{.replaceData()}\\
	\hline
	Invalid cache offset & With \texttt{cache()} it is tried for an \texttt{InputStream} to cache an offset that is smaller than the last read offset. & This is a wrong usage of the API, thus it results in an \texttt{InvalidMediumReferenceException} runtime exception. & \IMediumStore{} \texttt{.cache()} \\
	\hline
	Stream data not available & Data requested with \texttt{getData()} for a given offset are not any more available in the cache, and the underlying medium is an \texttt{InputStream}. & This is a wrong usage of the API, thus it results in an \texttt{InvalidMediumReferenceException}, a runtime exception. & \IMediumStore{} \texttt{.getData()} \\
	\hline
	Unknown or invalid \MediumAction{} & The user passes an unknwon or invalid \MediumAction{} to any operation & This is an abnormal situation and is acquitted with the runtime exception \texttt{InvalidMediumActionException}  & \IMediumStore{}\texttt{.undo()} \\
	\hline
	\texttt{IOException} in the implementation & The Java implementation use throws an \texttt{IOException}, at any place where none of the already presented error situations are involved. & It is an abnormal situation, thus a \texttt{MediumAccessException} runtime exception is thrown. & \IMediumStore{} \texttt{.cache()}, \IMediumStore{} \texttt{.getData()}, \IMediumStore{} \texttt{.isAtEndOfMedium()}, \IMediumStore{} \texttt{.flush()} \\
	\hline
	The \IMediumStore{} was already closed using \texttt{close()} & \texttt{MediumStoreClosedException}, a runtime exception & \texttt{MediumStoreClosedException}, a runtime exception & all \\
	\hline
\caption{Error handling in the component \COMPmedia{}}
\label{tab:FBMedia}
\end{longtable}
\end{landscape}

To summarize:

%%%% DD --> %%%%
\DD{dd:427}
{% Titel
Reaching the end of medium is not necessarily an error, other problems with I/O are seen as abnormal events.
}
{% Kurzbeschreibung
\COMPmedia{} sees achieving at the end of a medium not as abnormal event, but it must be handled according to the current context by the user code. \LibName{} assumes output media to be virtually unlimited and thus does not implement any means of treating end of medium situations when writing (also in accordance to the Java API).

All other error sitations in \COMPmedia{} are abnormal situations according to table \hyperref[tab:FBMedia]{\ref{tab:FBMedia}}.
}
{% Begründung
See table
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------
%		Implementation Layer Design
%-----------------------------------------------------------------------------------------------

\subsection{Implementation Desing}
\label{sec:ImplementationDesignCOMPmedia}

%-----------------------------------------------------------------------------------------------

\subsubsection{\TERMmedium{} Access}
\label{sec:ZugriffAufDasMedium}

Access to the \TERMmedium{} is implemented in own classes, as the following design decision states:

%%%% DD --> %%%%
\DD{dd:429}
{% Titel
Interface \IMediumAccessor{} with implementationen for \TERMmedia{} access
}
{% Kurzbeschreibung
Access to a \TERMmedium{} is possible via an interface \IMediumAccessor{} with following primitives:

\begin{itemize}
	\item Open: Opening creates an exclusive lock on the medium, as far as the medium supports this (see \DesLink{dd:404})
	\item Check if opened
	\item Close
	\item Read from offset $x$: Read $n$ bytes from external medium by explicit access, return the bytes in a \texttt{ByteBuffer}, the offset $x$ is ignored for non-random-access media
	\item Write to offset $x$: Schreibt $n$ bytes, die in einem \texttt{ByteBuffer} übergeben werden, nicht implementiert bei byte-Stream-media (der Aufruf wird ignoriert)
        \item Truncate to length $n$: Truncates the medium to a new length $n$; not implemented for byte-Stream media (call is ignored)
	\item Check if current offset is at end of \TERMmedium{}s, $x$ is ignored for non-random-access media
	\item Skipping bytes: Skips $n$ bytes, for random-access media, it does not do anything
\end{itemize}

\IMediumStore{} exclusively accesses the \TERMmedium{} only via this interface.
}
{% Begründung
\IMediumStore{} itself can deal with caching and the complex implementation of writing functionality independently from the concrete medium, while the actual medium access can be abstracted away by concrete implementations generically. Classical separation of concerns to increase maintainability and comprehensibility of the solution.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%


% -------------------------------------------------------------------------------------------------------
\subsubsection{Management of \IMediumReference{} instances}%
\label{sec:VerwaltungderIMediumReferenceInstanzen}%

According to \DesLink{dd:419}, \IMediumReference{} instances must be maintained centrally by \IMediumStore{}. At the same time, we can have multiple \IMediumReference{} instances referring to the same offset of the same medium, but actually refer to different data - in the special case of the methode \texttt{insertData}. New data is inserted subsequently  at the same offset with \texttt{flush()}, see \DesLink{dd:422}. In the end, the \IMediumReference{} instances must be automatically updated with \texttt{flush()}, as described in \DesLink{dd:418b} and \DesLink{dd:419b}.

Thus, these things follow:
%%%% DD --> %%%%
\DD{dd:430}
{% Titel
No pooling of \IMediumReference{} instances for the same offsets is possible
}
{% Kurzbeschreibung
In contrast to Java strings, the reuse of \IMediumReference{} instances in \texttt{createMediumReference()} for same offsets is not possible, i.e. if an \IMediumReference{} instance for offset $x$ has already been created, the same instance cannot be returned for the same offset on the next call. A new \IMediumReference{} instance must be created instead.
}
{% Begründung
Assum we use pooling. Furthermore, assume there are two inserts of lengths $n_1$ and $n_2$ at the same offset $x$ scheduled via \texttt{insertData()}. The internal implementation would only have a single instance of \IMediumReference{} for offset $x$. \texttt{flush()} must keep the offset of the first insertion unchanged, as the data of this first insertion remain there. Howeder, the offset of the second insertion must be changed, as these inserted bytes are actually located at offset $x+n_1$ after \texttt{flush()}.
}
{% Nachteile
For many created \IMediumReference{} objects, there could be a bigger memory footprint.
}
%%%% <-- DD %%%%

Furthermore, the \IMediumReference{} objects must be maintained in a dedicated data structure:
%%%% DD --> %%%%
\DD{dd:431}
{% Titel
All instances ever created with \texttt{createMediumReference()} are maintained in a dedicated data structure that allows duplicates
}
{% Kurzbeschreibung
All instances are held in a data structure that allows duplicates. It must be dedicated, i.e. only be used for storing all ever created \IMediumReference{} objects.
}
{% Begründung
Dupllicates must be possible due to \DesLink{dd:430}. We cannot mix that data structure with the caching or pending change data structures, as on the one hand side there will be always more \IMediumReference{} instances, than cache entries or pending changes, and on the other hand cache and pending change list could be cleared, while the \IMediumReference{} instances must be kept until the explicit close of the mediums.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Are these entries of the dedicated data structure indicated by \DesLink{dd:430} in any way sorted?

%%%% DD --> %%%%
\DD{dd:432}
{% Titel
Unsorted ArrayList for keeping the \IMediumReference{} instances
}
{% Kurzbeschreibung
We use an \texttt{ArrayList} as data structure for maintaining all \IMediumReference{} instances. Insertion of \IMediumReference{} instances is done in creation order. The list is  unsorted.
}
{% Begründung
A list allows for duplicates. Sorting of the list after each addition would lead to $O(n\log n)$ runtime complexity on average when creating a new \IMediumReference{} instance, if $n$ is the current size of the list. Ascending sort order by offset would be a bit more efficient for \texttt{flush()}, but does hardly justify the effort during insertion, because the creation of a \IMediumReference{} instance is usually much more commonly done than a \texttt{flush()}. Following approaches have been rejected especially:
\begin{itemize}
\item A \texttt{Map<Long, List<\IMediumReference{}>}\texttt{>} with offsets as key and all \IMediumReference{} instances for the offset as value won't work, as the offsets would need to be shifted on each insertion, i.e. the keys of the map would either need to be \IMediumReference{} instances again, or would need to be updated expensively.
\item A \texttt{TreeSet<\IMediumReference{}>} can be excluded as it does not allow duplicates.
\item A combination of a \texttt{TreeSet} with a special \texttt{Comparator}, which assumes \IMediumReference{} instances only to be equal, if they are the same objects, and as bigger, if the offset is the same, but the object is different, would accept such ``duplicates'' with the same offsets and ensure correct sorting for every insert. However, the \texttt{Set} then is incompatible with \texttt{equals}, what is not a best practice according to the javadocs. Secondly: More time required for insertion as mentioned.
\end{itemize}
}
{% Nachteile
Finding all \IMediumReference{} instances within the \texttt{flush()} implementation, that are bigger than a given offset has $O(n)$ complexity, which can however be tolerated.
}
%%%% <-- DD %%%%

To handle the complexity of \IMediumStore{} we decide:
%%%% DD --> %%%%
\DD{dd:433}
{% Titel
The class \MediumReferenceRepository{} is used for maintaining \IMediumReference{} instances
}
{% Kurzbeschreibung
\MediumReferenceRepository{} implements the design decisions \DesLink{dd:431}, \DesLink{dd:432} as well as \DesLink{dd:419}. It offers following methods:
\begin{itemize}
\item \texttt{createMediumReference()} to create \IMediumReference{} instances
\item \texttt{updateReferences()} for implementation of \DesLink{dd:418b}, where a \MediumAction{} instance is passed
\item \texttt{getAllReferences()} returns all maintained instances
\item \texttt{getAllReferencesInRegion()} returns all maintained instances with given offset range
\item \texttt{getAllReferencesBehindOrEqual()} returns all maintained instances with offsets bigger than the given offset
\item \texttt{clearAll()} removes all maintained instances
\end{itemize}

}
{% Begründung
Reduction of total complexity of the \IMediumStore{}.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

The last question for \IMediumReference{} instances that still has to be answered: How to deal with the method \texttt{advance()} mentioned in \DesLink{dd:416}. It creates \IMediumReference{} instances. Do they have to be maintained in \MediumReferenceRepository{}, too?

%%%% DD --> %%%%
\DD{dd:433b}
{% Titel
The  \IMediumReference{} instances created with \IMediumReference{}\texttt{.advance()} need to be maintained with \MediumReferenceRepository{}, too.
}
{% Kurzbeschreibung
Initially, the new \IMediumReference{} instance must get a reference to its creator, i.e. \MediumReferenceRepository{}, during construction. To still enable a simple creation of instances of \IMediumReference{} implementation classes (e.g. in unit tests), the constructor is public.
}
{% Begründung
The client code can arbitrarily use \IMediumReference{}\texttt{.advance()}, and the returned references can be used as usual, e.g. for newly created data blocks. Thus it is clear that even these references are auto-corrected with \MediumReferenceRepository{}\texttt{.updateReferences()}.
}
{% Nachteile
Close coupling between \IMediumReference{} and \MediumReferenceRepository{}, as both are knowing each other.
}
%%%% <-- DD %%%%

\OpenIssue{Check: Use Weak References?}{Check: Use Weak References?}

%-----------------------------------------------------------------------------------------------

\subsubsection{Internal Datenstrukturen for das Caching}
\label{sec:Datenstrukturen}

Der Cache verwaltet zunächst einmal Datenbytes pro Offset, immer unter der Annahme, dass die im Cache gehalteten Daten exakt identisch with den media-Daten sind, according to \DesLink{dd:404}. Es wurde bereits definiert, dass es eine explizite Methode \texttt{cache()} zum Einlesen von Cache-Inhalten and eine Methode \texttt{getCachedByteCount()} zum Abfragen zusammenhängender Byte-Zahlen gibt (see Tabelle \hyperref[tab:MediaOps]{\ref{tab:MediaOps}} sowie \DesLink{dd:409} and \DesLink{dd:412b}).

Das Abfragen der Daten erfolgt dann über \texttt{getData()}, welche den Cache einerseits überspringen kann, andererseits jedoch diesen auch automatisch with fehlenden Daten aktualisiert (\DesLink{dd:412c} and \DesLink{dd:412d}).

Schließlich kann man Cache-Inhalte with \texttt{discard()} gezielt freigeben or das Caching komplett deaktivieren (see \DesLink{dd:411c}).

In vielen Fällen wollen wir abfragen, welche Anteile von zu lesenden, zu schreibenden or auch zu löschenden Daten im Cache sind. Der Cache kann durch mehrfache Fülloperationen beliebig fragmentiert sein. Daher benötigen wir eine Klasse dafür:
%%%% DD --> %%%%
\DD{dd:435}
{% Titel
Klasse \MediumRegion{} for zusammenhängende Abschnitte eines Mediums, insbesondere for Cache-Abschnitte
}
{% Kurzbeschreibung
Die Klasse \MediumRegion{} repräsentiert Bereiche eines Mediums, die unter Umständen gecacht sind. Dafor  bietet sie folgende Methoden:
\begin{itemize}
\item \texttt{getStartReference()}: Start-\IMediumReference{} des Bereiches abfragen
\item \texttt{getSize()}: Länge des Bereiches abfragen
\item \texttt{getbytes()}: Liefert null, falls nicht im Cache, sonst den \texttt{ByteBuffer} with den gecachten Daten der Region
\item \texttt{isCached()}: Liefert true, falls der Bereich gecacht ist, sonst false
\item \texttt{isContained()}: Liefert true, falls die angegebene \IMediumReference{} im Bereich enthalten ist, sonst false
\item \texttt{discardbytesAtFront()}: Ermöglich Verkleinerung des Bereiches durch Verwerfen von bytes an dessen Anfang
\item \texttt{discardbytesAtEnd()}: Ermöglich Verkleinerung des Bereiches durch Verwerfen von bytes an dessen Ende
\end{itemize}
}
{% Begründung
Die Cache-Bereiche and die nicht-gecachten Bereiche können einheitlich behandelt werden. 
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Die Verwaltung der Cache-Inhalte wird von einer Hilfsklasse erledigt:
%%%% DD --> %%%%
\DD{dd:436}
{% Titel
Cache-Verwaltung durch die Klasse \MediumCache{}
}
{% Kurzbeschreibung
Die Cache-Verwaltung erfolgt durch die Klasse \MediumCache{}, with folgenden Methoden:
\begin{itemize}
\item \texttt{getCachedByteCountAt()}: Liefert die Anzahl der am Offset $x$ zusammenhängend gecachten Daten zurück
\item \texttt{getData()}: Liefert for den Offsetbereich $[x,x+n]$ eine Liste von \MediumRegion{}-Instanzen, zurück, welche die gecachten and nicht gecachten Bereiche im Offset-Bereich angeben.
\item \texttt{getCachedRegions()}: Liefert eine Liste aller aktuell gecachten \MediumRegion{}-Instanzen zurück.
\item \texttt{addData()}: Fügt am Offset $x$ Daten in den Cache ein. Vorher dort gecachte Daten werden überschrieben.
\item \texttt{discardData()}: Gibt am Offset $x$ bis zu $n$ bytes aus dem Cache frei
\item \texttt{clearAll()}: Gibt alle Daten des Caches frei
\item \texttt{setMaxRegionSize()}: Setzt die maximal verwendete Größe einer Region. Default ist \texttt{Integer.MAX\_VALUE}. Die erzeugten Regionen werden nach Änderung maximal diese Größe erreichen. Die bestehenden Regionen bleiben unverändert.
\item \texttt{getMaxRegionSize()}: liefert die maximal verwendete Größe einer Region
\item \texttt{enableCaching()}: Aktiviert or deaktiviert das Caching
\item \texttt{isCachingEnabled()}: Frag ab, ob  das Caching aktiviert or deaktiviert ist
\end{itemize}
}
{% Begründung
Verringerung der Komplexität von \IMediumStore{}
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Wie werden die Cache-Regionen nun intern verwaltet?

%%%% DD --> %%%%
\DD{dd:437}
{% Titel
Es wird eine \texttt{TreeMap} for die Verwaltung der Cache-Inhalte verwendet
}
{% Kurzbeschreibung
Es wird eine \texttt{TreeMap<}\IMediumReference{}, \MediumRegion{}\texttt{>} for die Verwaltung der Cache-Inhalte verwendet.
}
{% Begründung
Die Inhalte müssen basierend of Offsets ausgelesen werden. Daher ist eine nach Offset sortierte Datenstruktur notwendig. Sie ermöglicht das effiziente Auslesen aller \MediumRegion{}s größer or kleiner einem bestimmten Offset. Diese Operation sollte statt $O(n)$ (vermutlich) sogar eine Laufzeitkomplexität von $O(log(n))$ haben.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Aus Performance-Gründen haben wir bereits die Möglichkeit for das Freigeben von Daten vorgesehen. Es zeichnet sich allerdings ab, dass man auch die Maximalgröße des Caches durch einen Automatismus regeln können muss:
%%%% DD --> %%%%
\DD{dd:437b}
{% Titel
Der Anwender kann die Maximalgröße des Caches einstellen
}
{% Kurzbeschreibung
Die Maximalgröße kann for \MediumCache{} über \texttt{setMaxCacheSize()} gesetzt and with \texttt{getMaxCacheSize()} abgefragt werden. Darüber hinaus kann die aktuelle Cache-Größe über \texttt{getCurrentCacheSize()} abgefragt werden. Standardmäßig ist die maximale Cache-Größe nicht limitiert, was durch eine Konstante \texttt{UNLIMITED} repräsentiert wird. Das Setzen der maximalen Cache-Größe führt zum Freigeben bzw. Verkleinern von vorhandenen Cache-Regionen, wird also sofort angewandt. Welche Cache-Regionen freigegeben werden, ist andefiniert.

\texttt{addData()} prüft, ob die aktuelle Cache-Größe plus die neu hinzuzufügenden bytes die maximale Cache-Größe überschreiten. Falls dem so ist, werden nur soviele bytes ab Beginn des zu cachenden \texttt{ByteBuffer}s hinzugefügt, bis die maximale Cache-Größe erreicht ist, unter Umständen also keine bytes. \texttt{addData()} liefert dann eine \MediumRegion{} zurück, welche die tatsächliche Regions-Größe angibt.
}
{% Begründung
Dies ermöglicht dem Anwender aktiv, die Cache-Größe zu beeinflussen and \texttt{OutOfMemoryError}s vorzubeugen
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Wir sollten uns noch über Fragementierungen des Caches Gedanken machen. Angenommen, durch aufeinanderfolgende Aufrufe von \texttt{addData()} würde 20 mal jeweils genau 1 Byte in einem zusammenhängenden Offset-Bereich der Länge 20 gecached werden. Entstehen dadurch 20 verschiedene \MediumRegion{}s with einer Länge von 1? Die analoge Fragestellung ergibt sich for einen Aufruf von \texttt{getData()}, der sich über einen Offsetbereich with Lücken in der Cache-Abdeckung ergibt. Nehmen wir beispielsweise an, der Cache enthält ab Offset $x$ 20 bytes, ab Offset $y:=x+30$ weitere 50 bytes, hat also eine Lücke von 10 bytes. Erfolgt nun ein Aufruf von \texttt{getData()} for den Bereich $x-10$ with Länge 100, dann haben wir fünf Regionen:
\begin{itemize}
\item Region 1: $[x-10,x)$ befindet sich nicht im Cache
\item Region 2: $[x,x+20)$ befindet sich im Cache
\item Region 3: $[x+20,y)$ befindet sich nicht im Cache
\item Region 4: $[y,y+50)$ befindet sich im Cache
\item Region 5: $[y+50,y+60)$ befindet sich nicht im Cache
\end{itemize}

\texttt{getData()} wird nun die Regionen 1, 3 and 5 according to \DesLink{dd:412d} im Cache ergänzen. Haben wir nach dem Aufruf dann also 5 \MediumRegion{}s im Cache?

Wir legen fest:
%%%% DD --> %%%%
\DD{dd:437c}
{% Titel
Fragmentierung zusammenhängender Cache-Bereiche wird vermieden
}
{% Kurzbeschreibung
Bei aufeinanderfolgenden Aufrufen von \texttt{addData()}, bei denen Aufruf 1 den Offsetbereich $[x,x+n)$ and Aufruf 2 den Offsetbereich $[x+n,x+n+m)$ abdeckt \-- die beiden Bereiche also direkt ohne Lücke aneinander grenzen \-- ist das Endergebnis eine \MediumRegion{}, die den Offsetbereich von $[x,x+n+m)$ abdeckt.

Bei einem Aufruf von \texttt{getData()}, dessen Offset-Bereich sich über mehrere durch Lücken getrennte gecachte \MediumRegion{}s erstreckt, werden die vom Medium gelesenen Lücken with den bereits im Cache befindlichen, bisher getrennten \MediumRegion{}s zu einer \MediumRegion{} verschmolzen.

In beiden Fällen setzen wir voraus, dass die Gesamtlänge des neuen Bereiches kleiner als die konfigurierte maximale Regionsgröße according to \DesLink{dd:436} ist. Wird diese überschritten, gilt: Sei die Gesamtlänge $n$ with konfigurierter maximaler Blockgröße $m$, also $n>m$. Ist dann $n$ durch $m$ teilbar, so entstehen $\frac{n}{m}$ verschiedene \MediumRegion{}s. Ist $n$ nicht durch $m$ teilbar, so entstehen $\lfloor\frac{n}{m}\rfloor+1$ \MediumRegion{}s.

Eine Fragmentierung von zusammenhängenden \MediumRegion{}s im Cache passiert also nur beim Überschreiten der maximalen Regionsgröße.
}
{% Begründung
Mehr Objekte benötigen mehr Speicher and erfordern einen höheren Verwaltungsaufwand. Die Fragmentierung bietet keinerlei Vorteile.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Eine verwandte Frage ist der Umgang with Lücken, auch bereits bei aufeinanderfolgenden Aufrufen von \texttt{addData()}: Wie im eingehenden Beispiel werden 20 bytes durch 20 Aufrufe von \texttt{addData()} in den Cache geladen. Jedoch befinde sich zwischen je zwei aufeinanderfolgenden bytes eine ``Lücke'' von einem Byte, das nicht im Cache enthalten ist. Auch hier darf man die Frage stellen: Entstehen dennoch 20 \MediumRegion{}s?

%%%% DD --> %%%%
\DD{dd:437d}
{% Titel
Fragmentierung unzusammenhängender Cache-Bereiche wird nicht unterbanden
}
{% Kurzbeschreibung
Die wie im oberen Abschnitt beschreibene Situation ``eng benachbarter'', aber unzusammenhängender Cache-Bereiche geringer Länge wird nicht vermieden.
}
{% Begründung
Dies würde zu noch höherer Komplexität in der implementation von \texttt{addData()} führen. Heuristiken, nach denen Zusammenfassungen erfolgen, müssten erst definiert werden. Denkbar wäre beispielsweise, dass ein Aufruf von \texttt{addData()} erkennt, dass es andere Offset-Bereiche gibt, die sich im Radius $[x-k,x+k]$ befinden, with einem zu definierenden $k$. In diesem Fall könnten auch die ``Lückenbytes'' zusätzlich gecacht werden. Hier muss allerdings einerseits sichergestellt werden, dass ebenso die maximale Größe einer Region wie die maximale Größe des Caches nicht überschritten wird. For \texttt{InputStream}s ist dieses ``Lückenfüllen'' nicht möglich and muss daher ohnehin unterbleiben. Zudem muss dieser Weg den Sonderfall des Endes des Mediums berücksichtigen.

Stattdessen ist der Anwender selbst in der Pflicht, for sinnvolle, d.h. zusammenhängende Cache-Bereiche durch entsprechende Verwendung der Methode zu sorgen.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{Internal Datenstrukturen for die Verwaltung schwebender Änderungen}
\label{sec:DatenstrukturenZweist}

For das zweistufige Schreiben müssen die durch \texttt{insertData()}, \texttt{removeData()} and \texttt{replaceData()} angemeldeten Änderungen sinnvoll verwaltet werden, dawith sie später durch \texttt{flush()} verarbeitet werden können. Eine Änderung wird dabei durch eine \MediumAction{} repräsentiert.

Halten wir zunächst Folgendes fest:

%%%% DD --> %%%%
\DD{dd:434}
{% Titel
\MediumAction{} hat eine Sequenznummer zur Unterscheidung von Aktionen at the same offset
}
{% Kurzbeschreibung
\MediumAction{} definiert eine Sequenznummer (beginnend bei 0) zur Unterscheidung von Aktionen at the same offset. Diese wird bei consecutiven Aktionen (egal welchen Typs) at the same offset um 1 inkrementiert. Diese Sequenznummer wird also nicht nur for \texttt{insert}s at the same offset verwendet, sondern auch for alle anderen Aktions-Arten.
}
{% Begründung
Zwei unterschiedliche \MediumAction{}-Instanzen, die sich auf dasselbe Offset beziehen, können als solche sonst nicht in eine Reihenfolge gebracht werden. Die Reihenfolge müsste lediglich in externen Strukturen gehalten werden. Eine Unterscheidung and Sortierung ist dann schwieriger möglich. Dies ist natürlich insbesondere for \texttt{insert}s wichtig, die sich auf dasselbe Offset beziehen dürfen (see \DesLink{dd:422}). Darüber hinaus ist dies aber auch for unterschiedliche Typen wichtig, denn auch \texttt{insert} lässt auch ein \texttt{remove} or \texttt{replace} at the same offset als gültig zu (see \DesLink{dd:422}).
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Es ist nun wichtig, Vergleiche zwischen zwei \MediumAction{}s sauber zu definieren, dawith entsprechende sortierte Datenstrukturen for effiziente Suche and Iteration in Reihenfolge genutzt werden können:

%%%% DD --> %%%%
\DD{dd:434a}
{% Titel
Vergleiche von \MediumAction{}s finden auf Basis der \IMediumReference{} and der Sequenznummer statt
}
{% Kurzbeschreibung
Eine \MediumAction{} \texttt{a} ist genau dann kleiner als eine \MediumAction{} \texttt{b} bezogen auf Javas \texttt{compareTo}, wenn eine der folgenden Bedingungen gilt:
\begin{itemize}
\item Die \IMediumReference{} von \texttt{a} kleiner als die \IMediumReference{} von \texttt{b} ist,
\item Or die \IMediumReference{} von \texttt{a} gleich der \IMediumReference{} von \texttt{b} ist, and die Sequenznummer von \texttt{a} kleiner der Sequenznummer von \texttt{b} ist
\end{itemize}

Eine \MediumAction{} \texttt{a} ist genau dann gleich einer \MediumAction{} \texttt{b} bezogen auf Javas \texttt{equals} and \texttt{compareTo}, wenn eine der folgenden gilt: Alle Attribute von \texttt{a} gleichen allen Attributen von \texttt{b} (im Sinne von \texttt{equals}).

Eine \MediumAction{} \texttt{a} ist genau dann größer als eine \MediumAction{} \texttt{b} bezogen auf Javas \texttt{compareTo}, wenn \texttt{a} weder kleiner als \texttt{b} noch gleich \texttt{b} ist. Insbesondere natürlich dann, wenn das \IMediumReference{} größer ist, or bie gleichen \IMediumReference{}s, wenn die Sequenznummer größer ist. Zudem gilt aber: Sind \IMediumReference{}s and Sequenznummer identisch, dann ist \texttt{a} dennoch größer als \texttt{b}, falls eines der anderen Attribute der \MediumAction{}s unterschiedlich ist.
}
{% Begründung
Die Sortierung der \MediumAction{}s soll anhand ihrer Reihenfolge auf dem Medium (also ihrer \IMediumReference{}s) and ihrer Erzeugungsreihenfolge (also ihrer Sequenznummer) erfolgen, denn das Verhalten aufeinanderfolgender Operationen ist according to \DesLink{dd:422}, \DesLink{dd:424} and \DesLink{dd:424a} auf Basis der Aufrufreihenfolge festgelegt. Zudem müssen die \MediumAction{}s anhand einer klaren Reihenfolge beim \texttt{flush} abgearbeitet werden. \texttt{equals} muss genau dann true ergeben, wenn \texttt{compareTo} gleich 0 liefert.
}
{% Nachteile
Ggf. Verwirrung, weil kleiner and größer nicht symmetrisch sind. Die implementation muss daher dafor sorgen, dass \MediumAction{}s with gleichem Offset immer unterschiedliche Sequenznummern erhalten, die with Erzeugungsreihenfolge strikt steigen.
}
%%%% <-- DD %%%%

Nun können wir festlegen, in welcher Form die \MediumAction{}s gespeichert werden:

%%%% DD --> %%%%
\DD{dd:435b}
{% Titel
\MediumAction{}s werden in einer sortierten Datenstruktur ohne Duplikate vorgehalten
}
{% Kurzbeschreibung
Die vor einem \texttt{flush()} erzeugten \MediumAction{}s werden in einer nach Offset and Sequenznummer (according to \DesLink{dd:434}) sortierten Datenstruktur vorgehalten, die keine Duplikate zulässt (z.B. \texttt{TreeSet}).
}
{% Begründung
Die Sortierung ist for die Abarbeitung in Reihenfolge durch \texttt{flush()} nötig, zwei \MediumAction{}s with gleichem Offset, gleicher Sequenznummer and desselben Typs sollen nicht als Duplikat auftauchen können.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Nun zur Verwaltung der \MediumAction{}s:
%%%% DD --> %%%%
\DD{dd:436a}
{% Titel
Zur Verwaltung dient die Klasse \MediumChangeManager{}
}
{% Kurzbeschreibung
Zur Verwaltung dient die Klasse \MediumChangeManager{}, die intern \DesLink{dd:435b} implementiert, with folgenden Methoden:
\begin{itemize}
\item \texttt{scheduleInsert()} zum Anmelden eines \emph{insert}, implementiert \DesLink{dd:422}, erhält als Eingabe eine \MediumRegion{} and liefert eine \MediumAction{} des entsprechenden Typs and with passender Sequenznummer zurück, d.h. sollte es andere Aktionen at the same offset geben, hat die Aktion garantiert eine Sequenznummer höher als die Aktion with der größen Sequenznummer am angegebenen Offset.
\item \texttt{scheduleRemove()} zum Anmelden eines \emph{remove}, implementiert \DesLink{dd:424}, erhält als Eingabe eine \MediumRegion{} and liefert eine \MediumAction{} des entsprechenden Typs and with passender Sequenznummer zurück, d.h. sollte es andere Aktionen at the same offset geben, hat die Aktion garantiert eine Sequenznummer höher als die Aktion with der größen Sequenznummer am angegebenen Offset.
\item \texttt{scheduleReplace()} zum Anmelden eines \emph{replace}, implementiert \DesLink{dd:424a}, erhält als Eingabe eine \MediumRegion{} and die Länge des zu ersetzenden Bereiches, liefert eine \MediumAction{} des entsprechenden Typs and with passender Sequenznummer zurück, d.h. sollte es andere Aktionen at the same offset geben, hat die Aktion garantiert eine Sequenznummer höher als die Aktion with der größen Sequenznummer am angegebenen Offset.
\item \texttt{undo()} zum Rückgängigmachen, implementiert \DesLink{dd:420}
\item \texttt{iterator()} liefert einen \texttt{Iterator<}\MediumAction{}\texttt{>} zum lesenden Iterieren der Änderungen in der korrekten Reihenfolge, \texttt{remove()} wird nicht implementiert
\item \texttt{clearAll()} löscht alle Änderungen
\end{itemize}
Dabei erzeugen die drei \texttt{schedule}-Methoden \MediumAction{}s according to \DesLink{dd:424b} and \DesLink{dd:434}.
}
{% Begründung
Verringerung der Gesamtkomplexität von \IMediumStore{}.

Der Iterator erlaubt das Lesen der Änderungen in Reihenfolge, wird aber for die Abarbeitung nicht benötigt, wie wir später sehen werden. \texttt{remove} auf dem Iterator ist unnötig, da \texttt{undo()} eine Aktion rückgängig macht.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Zuletzt stellen wir noch einige Gemeinsamkeiten zwischen \MediumAction{}s and \MediumRegion{}s fest, and definieren daher:
%%%% DD --> %%%%
\DD{dd:436b}
{% Titel
\MediumAction{} aggregiert eine \MediumRegion{}-Instanz
}
{% Kurzbeschreibung
\MediumAction{} aggregiert eine \MediumRegion{}-Instanz, welche Start and Länge der Aktion enthält, NICHT jedoch die dawith verknüpften bytes selbst, die als separates Attribut in \MediumAction{} gehalten werden müssen.
}
{% Begründung
\MediumAction{} benötigt eine Start-\IMediumReference{}, eine Länge der Änderung sowie ggf. die Änderungsbytes, falls vorhanden. Allerdings werden wir nur Start and Länge in Form einer \MediumRegion{}-Instanz implementieren. Man kann sie daher als Klasse interpretieren, die sich auf eine \MediumRegion{} bezieht. Dies ist eher eine ``hat ein''- statt eine ``ist ein''-Beziehung. Daher ist Aggregation hier angebrachter als Vererbung. Der Grand dafür, die bytes der Änderung (z.B. die einzufügenden, zu schreibenden or zu ersetzenden bytes) selbst nicht with in die \MediumRegion{} zu nehmen \-- obwohl diese ja bytes aufnehmen könnte \-- liegt in der speziellen Form der \texttt{replace}-Operation begründet. Bei dieser sind for die Detektion unerlaubter Überlappungen (see \DesLink{dd:424} and \DesLink{dd:424a}) in keinster Weise die Ersetzungsbytes wichtig, sondern ausschließlich die Anzahl zu ersetzender bytes. Um daher eine einheitliche implementation for alle Typen von \MediumAction{} zu ermöglichen, enthält deren \MediumRegion{} daher nur die Länge der Änderung (z.B. die Anzahl der zu ersetzenden bytes), and die dawith im Zusammenhang stehenden bytes werden als separates Attribut verwaltet.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{implementation von flush}
\label{sec:flushing}

Die wohl komplexeste Funktionalität von \IMediumStore{} ist \texttt{flush()}, denn:
\begin{itemize}
\item \texttt{flush()} muss alle bisher angemeldeten Änderungen durchgehen,
\item with den aktuellen Cache-Inhalten abgleichen,
\item sinnvolle Blöcke der zu schreibenden Daten bilden,
\item bei Einfügungen or Löschungen Daten hinter der Einfügestelle lesen and erneut schreiben,
\item die \IMediumReference{}- and \MediumAction{}-Instanzen aktualisieren,
\item den Cache aktualisieren
\end{itemize}

Dann kommt noch hinzu, dass die schreibenden Operationen einige Eigenarten haben:
\begin{itemize}
\item \texttt{insertData()} and \texttt{removeData()} erfordern, die Daten hinter der Einfügung or Löschung zu lesen, and dann wieder zu schreiben
\item \texttt{replaceData()} ist ebensowenig harmlos, denn je nachdem, wieviele alte bytes durch wieviele neue ersetzt werden, kann es entweder keinerlei Verschiebung (Anzahl alte bytes gleich Anzahl neuer bytes), ein \texttt{insert} (Anzahl alte bytes kleiner Anzahl neuer bytes) or ein \texttt{remove} (Anzahl alte bytes größer Anzahl neuer bytes) bedeuten
\item Erfolgen diese Operationen bei großen Dateien am Beginn, dann ist das Lesen einer großen Speichermenge bis zum Ende der Datei möglicherweise nicht möglich, ohne einen \texttt{OutOfMemoryError} zu erzeugen
\item Dawith muss blockweise gelesen and geschreiben werden
\item Hierbei unterscheiden sich die Operationen:
\begin{itemize}
\item Bei \texttt{insertData()} von $n$ bytes at offset $x$ müssen die Daten vom Ende des Mediums blockweise bis zum Offset $x$ gelesen and geschrieben werden. Zuerst werden also die letzten $k$ bytes at offset $r$ gelesen, and dann ab Offset $r+k$ geschrieben, dann wiederum $k$ bytes at offset $r-k$ gelesen, um dann bei $r$ geschrieben zu werden usw. bis zum Offset $x$. Ein anderer Weg funktioniert nicht, wenn man keine bytes der Datei verlieren möchte.
\item Hingegen bei \texttt{removeData()} von $n$ bytes at offset $x$ müssen die Daten beginnend vom Offset $x+n$ blockweise bis zum Ende des Mediums gelesen and geschrieben werden. Zuerst werden also die letzten $k$ bytes at offset $x+n$ gelesen, and dann ab Offset $x$ geschrieben, dann wiederum $k$ bytes at offset $x+n+k$ gelesen, um dann bei $x+n$ geschrieben zu werden usw. bis zum letzten Offset im Medium. Ein anderer Weg funktioniert nicht, wenn man keine bytes der Datei verlieren möchte.
\item Bei \texttt{replaceData()} verhält sich entsprechend der oben genannten Fälle entweder wie \texttt{insert} or wie \texttt{remove}, or es werden keinerlei nachfolgende Lese- and Schreibaktionen nötig, letzteres genau dann, wenn die Anzahl der Ersetzungsbytes gleich der Anzahl der zu ersetzenden bytes ist.
\end{itemize}
\end{itemize}

Fest steht dawith zunächst, dass wir die Konfiguration einer maximalen Block-Größe for das Schreiben benötigen:
%%%% DD --> %%%%
\DD{dd:438}
{% Titel
Eine maximale Schreibe-Block-Größe muss for den Anwender konfigurierbar sein
}
{% Kurzbeschreibung
Diese muss zwischen 1 and N bytes liegen
}
{% Begründung
Benötigt aufgrand der notwendigen Operationen beim Einfügen and Entfernen. Durch die Konfigurierbarkeit kann der Anwender selbst entscheiden, wie viele bytes in einem Rutsch gelesen and geschrieben werden sollen.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Das Herausfinden, welche Operationen durchgeführt werden müssen, ist also eine komplexe Aufgabe. Diese komplexe Aufgabe können wir in eine Methode gießen:
%%%% DD --> %%%%
\DD{dd:439}
{% Titel
\texttt{createFlushPlan()} erzeugt einen Schreib-Lese-Plan for ein flush in Form einer \texttt{List<}\MediumAction{}\texttt{>}
}
{% Kurzbeschreibung
\texttt{createFlushPlan()} erzeugt einen Schreib-Lese-Plan for ein flush and liefert eine \texttt{List<}\MediumAction{}\texttt{>}.  Der Schreib-Lese-Plan enthält die in gegebener Reihenfolge auszuführenden Aktionen. Die Liste der möglichen Aktionen wird um \texttt{READ}, \texttt{WRITE} and \texttt{TRUNCATE} erweitert. Dabei ist:
\begin{itemize}
\item READ primitives Lesen von $n$ bytes ab einem Offset
\item WRITE primitives Schreiben von $n$ bytes ab einem Offset
\item TRUNCATE das explizite Kürzen der Datei, was insbesondere bei Löschungen notwendig ist
\end{itemize}

Jeder gelieferten \texttt{READ}-Aktion muss eine \texttt{WRITE}-Aktion folgen, sonst ist der Plan ungültig. \texttt{INSERT}- and \texttt{REPLACE}-Operationen (falls mehr Ersetzungsbytes als ersetzte bytes) führen zu \texttt{WRITE}-Aktionen. For alle \texttt{READ} and \texttt{WRITE}-Aktionen gilt: die Anzahl der bytes liegt zwischen 0 and der maximalen Schreibblockgröße. \texttt{createFlushPlan()} liefert auch die ursprünglichen \texttt{REMOVE}-, \texttt{REPLACE}- and \texttt{INSERT}-Aktionen explizit, obwohl diese implizit durch \texttt{READ}-\texttt{WRITE}-Aktionen implementiert werden.

Der Schreib-Lese-Plan enthält dawith zusätzlich zu den bereits durch den Anwender hinzugefügten Aktionen neue \MediumAction{}s. Diese werden allerdings nicht in der internaln Datenstruktur des \MediumChangeManager{} eingefügt.

Der erzeugte Plan kann dann im Nachgang abgearbeitet werden.
}
{% Begründung
Die Ermittelung der notwendigen Operationen ist ein komplexer Vorgang, der separat erfolgen sollte. Ein sofortiges Ausführen einer Aktion wäre alternativ möglich, aber würde das Testen des entsprechenden Codes erschweren.

\MediumChangeManager{} ist der richtige Ort for diese Operation, da hier ohnehin alle \MediumAction{}s verwaltet werden. Die im Plan zusätzlich enthaltenen \MediumAction{}s werden nicht in die internal Datenstruktur eingefügt, weil die Operation so ideal wiederholbar and ``zustandslos'' ist. 

Die Erweiterung um \texttt{WRITE} scheint unnötig, da es bereits eine Operation \texttt{REPLACE} gibt. Jedoch unterscheidet sich \texttt{WRITE} insofern, dass die zu schreibenden bytes beim Erzeugen der Aktion noch nicht bekannt sind, im Gegensatz zu \texttt{REPLACE}.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Nun hätten wir alle Zutaten beisammen, um das Schreiben via \texttt{flush()} zu implementieren:
\begin{enumerate}
\item Erzeuge den Schreib-Lese-Plan according to \DesLink{dd:439}
\item Iteriere alle Einträge des Schreib-Lese-Plans, die folgenden Schritte gelten for jeden einzelnen Eintrag:
\item Führe die Aktion an der durch die \MediumAction{} angegebenen Stelle durch:
\begin{itemize}
\item Falls Aktion = \texttt{READ}: Lies $n$ bytes, die in der derauffolgenden Aktion geschrieben werden, wobei $n$ kleiner gleich der maximalen Schreibblockgröße and größer als 0 ist. Dazu werden zuerst via \MediumCache{}\texttt{.getData()} die Regionen ermittelt. Diejenigen, die nicht gecached sind, werden durch direkten Zugriff auf das Medium via \IMediumAccessor{} gelesen. Dann wird ein entsprechender \texttt{ByteBuffer} schrittweise aufgebaut.
\item Falls Aktion = \texttt{WRITE}: Schreibe die bytes, welche die vorherige \texttt{READ}-Operation geliefert hat, durch direkten Zugriff auf das Medium via \IMediumAccessor{} 
\item Falls Aktion = \texttt{REPLACE}: Schreibe die bytes in der \MediumAction{} durch direkten Zugriff auf das Medium via \IMediumAccessor{} 
\item Falls Aktion = \texttt{INSERT}: Schreibe die bytes in der \MediumAction{} durch direkten Zugriff auf das Medium via \IMediumAccessor{} 
\item Falls Aktion = \texttt{REMOVE}: Ignoriere die Aktion, weil sie implizit durch \texttt{READ}, \texttt{WRITE} and \texttt{TRUNCATE} durchgeführt wird
\item Falls Aktion = \texttt{TRUNCATE}: Führe ein explizites Verkürzen des Mediums durch.
\end{itemize}
\item Aktualisiere den Cache (Teil 1): Falls Aktion = \texttt{REMOVE}, dann rufe \MediumCache{}\texttt{.discardData()} auf, um die bytes aus dem Cache zu entfernen.
\item Nur wenn die Aktion = \texttt{INSERT} or Aktion = \texttt{REMOVE}: Rufe \MediumReferenceRepository{}\texttt{.updateReferences()} for den Bereich auf, sodass alle dahinter liegenden \IMediumReference{} instances aktualisiert werden
\item Aktualisiere den Cache (Teil 2): Falls Aktion = \texttt{WRITE}, \texttt{INSERT} or \texttt{REPLACE}, dann rufe \MediumCache{}\texttt{.addData()} auf, um die bytes in den Cache aufzunehmen.
\item Falls Aktion = \texttt{INSERT}, \texttt{REMOVE} or \texttt{REPLACE}: Rufe \MediumChangeManager{}\texttt{.undo()} auf, um die Aktion zu entfernen
\end{enumerate}

%%%% DD --> %%%%
\DD{dd:440}
{% Titel
\texttt{flush()} wird according to des oben angegebenen Ablaufs implementiert
}
{% Kurzbeschreibung
\texttt{flush()} wird according to des oben angegebenen Ablaufs implementiert
}
{% Begründung
Der Schreib-Lese-Plan muss explizit alle Operationen enthalten, also auch die vom User ausgelösten Operationen \texttt{REPLACE}, \texttt{INSERT} and \texttt{REMOVE}, selbst wenn eigentlich \texttt{READ} and \texttt{WRITE} for deren implementation ausreichen würden. Grand dafor ist einerseits, dass bei einem \texttt{WRITE} nicht klar ist, ob die bytes der vorherigen \texttt{READ}-Aktion verwendet werden sollen, or vorgegebene bytes. Darüber hinaus müssen die Aktionen des Anwenders explizit aus dem \MediumChangeManager{} entfernt, and deren Einfluss auf \IMediumReference{} instances explizit ausgeführt werden. Dazu benötigt man ihre konkreten Typen, \texttt{WRITE} reicht nicht aus.

\texttt{undo()} wird nur bei den Anwender-Operationen ausgeführt, weil nur diese according to \DesLink{dd:439} in den internaln Datenstrukturen von \MediumChangeManager{} verwaltet werden.

Die Cache-Aktualisierung ist zweigeteilt: Im Falle von \texttt{REMOVE} wird \emph{zuerst} der Cache aktualisiert, um \emph{danach} die \IMediumReference{} instances anzupassen. Dies liegt darin begründet, dass ansonsten at the same offset unter Umständen mehrere Cache-Regionen liegen würden. Dies würde den Cache also in einen inkonsistenten and fehlerhaften Zustand bringen. With der gleichen Begründung werden die anderen schreibenden Operationen erst \emph{nach} dem Aktualisieren der \IMediumReference{} instances angepasst.

Die Cache-Verwaltung wird komplett \MediumCache{}\texttt{.addData()} überlassen, sodass darin Maximalgröße, zusammenhängende Bereiche etc. optimiert werden können.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Denken wir über die Fehlerbehandlung dieser Abfolge nach:
\begin{itemize}
\item Geht beim Erzeugen des Schreib-Lese-Plans (Step 1) etwas schief, dann kann der Anwender es nochmal versuchen, da alle Änderungen noch vorhanden and auf dem externen Medium noch nichts geändert worden ist
\item Geht beim Zugriff auf das externe Medium (Step 3) etwas schief, dann sind ggf. vorher bereits Aktionen des Schreib-Lese-Plans erfolgreich durchgeführt worden, das externe Medium also bereits geändert worden. Dies entspricht den Aussagen in \DesLink{dd:410b}. Da die vorherigen Operationen bereits entfernt wurden, haben wir aber einen sauberen ``Wieder-Aufsetz-Stand'', d.h. der Anwender könnte das Ganze auch hier erneut versuchen.
\item Geht beim Aktualisieren des Caches in Step 4 or 6 etwas schief, dann wird weder die Aktion entfernt noch werden die Medium-Referenzen aktualisiert. Analog, wenn ewas im Step 5 schiefgeht. In diesen Fällen ist entweder \MediumCache{} or \MediumReferenceRepository{} in einem inkonistenten Zustand. Die Frage ist, ob dann noch etwas zu retten ist. Das klärt die folgende Designentscheidung
\end{itemize}

%%%% DD --> %%%%
\DD{dd:441}
{% Titel
Rückgängig-Machen der Änderungen erfolgt immer, Cache wird bei Update-Fehlern geleert
}
{% Kurzbeschreibung
Sollte beim \texttt{flush()} in den Schritten 4 bis 6 eine \texttt{Exception} geworfen werden, dann soll die Aktion dennoch rückgängig gemacht werden.

Weitere Maßnahmen werden nicht eingeleitet, denn das Fehlschlagen der Schritte 4 bis 6 tritt nur im Falle von Programmierfehlern or schweren Systemfehlern ein. In diesen Situationen ist Recovery ohne schwierig bis unmöglich.
}
{% Begründung
\texttt{flush()} ist eine sensible Operation, die zwar kein ACID erfüllen mag, aber zumindest im Fehlerfall das Gesamtsystem in einen halbwegs konsistenten Zustand belassen soll. Dazu gehört, dass bereits auf dem Medium erfolgte fehlerfreie Operationen auch nicht nochmals ausgeführt werden dürfen. Dawith muss die entsprechende Aktion auch entfernt werden.

Der Versuch, auch Fehler bei Cache-Verwaltung or \MediumReferenceRepository{}-Zugriffen zu behandeln, führt zu einer hohen Komplexität, die im Sinne der Wahrscheinlichkeit dieser Ereignisse unnötig ist. Zudem ist auch dann das System i.d.R. nach wie vor in einem inkonsistenten Zustand. Solche Fehlerbehandlungen, die glauben etwas retten zu können, machen die Dinge dann ggf. auch nur noch schlimmer.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

%-----------------------------------------------------------------------------------------------

\subsubsection{Implementation of \texttt{createFlushPlan}}
\label{sec:flushingPlan}

The next step is to go into more detail regarding implementation of \texttt{createFlushPlan}, as it is anything but trivial. Here we develop a general algorithm that creates based on operations \texttt{insert}, \texttt{remove} and \texttt{replace} a sequence of necessary read and write operations to transform the current medium state into the target state.

Before that, we list some testcases that should be implemented to demonstrate the intended behaviour:

\begin{landscape}
\begin{longtable}{|p{0.03\linewidth}|p{0.08\linewidth}|p{0.45\linewidth}|p{0.35\linewidth}|}
	\hline
	\rowcolor[gray]{.9}\textbf{ID} & \textbf{Testcase} & \textbf{Variations} & \textbf{Expectation} \\
	\endhead
	\hline
CF0 & No operation & - & The plan created is empty \\
	\hline
CF1 & Single \texttt{insert} &\begin{enumerate}\item[a.] At start, intermediate or end offset of the medium
\item[b.] bytes behind: None, or whole-numbered multiple of the maximum write block size, or no whole-numbered multiple, or fewer bytes than the maximum write block size
\item[c.] Insertion bytes: The same cases as for the bytes behind
\end{enumerate}
& No read/write operations before insert offset; bytes behind remain unchanged and get shifted by $k$ bytes towards increasing offsets, such that medium length grows by $k$ bytes; The CFP contains $N$ pairs of read/ write operations for the bytes behind, where $N$ is the number of started blocks of at most ``maximum write block size'' bytes that are located behind the insert offset; the read/write pairs start from the last block backwards down to the first block after the insert offset, where the writes occur exactly $k$ bytes behind the reads; After this sequence, for the insertion bytes, there are $X$ corresponding write operations (one per starting block) with increasing offsets starting at the insert offset; The \texttt{insert} action follows after these actions in the plan \\
	\hline
CF2 & Single \texttt{remove} &\begin{enumerate}\item[a.] At start, intermediate or towards the end offset of the medium
\item[b.] bytes behind: None, or whole-numbered multiple of the maximum write block size, or no whole-numbered multiple, or fewer bytes than the maximum write block size
\item[c.] Removed byte count: The same cases as for the bytes behind
\item[d.] Extreme case: All bytes of the medium are removed
\end{enumerate}
& No read/write operations before remove offset; bytes behind remain unchanged and get shifted by $k$ bytes towards decreasing offsets, such that medium length shrinks by $k$ bytes; the CFP contains $N$ pairs of read/ write operations for the bytes behind, where $N$ is the number of started blocks of at most ``maximum write block size'' bytes that are located behind the last removed byte; the read/write pairs start from the first block after the last removed byte forward up to the last block of the medium, where the writes occur exactly $k$ bytes before the reads; the \texttt{remove} action follows after these actions in the plan; at the end there is a \texttt{truncate} operation \\
	\hline
CF3 & Single \texttt{replace} &\begin{enumerate}\item[a.] At start, intermediate or towards the end offset of the medium
\item[b.] bytes behind: None, or whole-numbered multiple of the maximum write block size, or no whole-numbered multiple, or fewer bytes than the maximum write block size
\item[c.] bytes to replace: The same cases as for the bytes behind
\item[d.] Replacement bytes: The same cases as for the bytes behind
\item[e.] Number of bytes to replace ($:=m$) smaller, equal to or bigger than the number of replacement bytes ($:=n$)
\item[f.] Extreme case: All bytes of the medium are replaced
\end{enumerate}
& No read/write operations before remove offset; If $m>n$: Behaves like a \emph{remove} of $m-n$ bytes; If $m<n$: Behaves like an \emph{insert} of $n-m$ bytes; If $m=n$: No read/write pairs for bytes behind; In every case there, there are $X$ corresponding write operations (one per starting block) for the replacement bytes with increasing offsets starting at the replacement offset; The \texttt{replace} action follows after these actions in the plan \\
	\hline
CF4 & Multiple \texttt{insert}s &\begin{enumerate}\item[a.] All inserts direkt aneinandergrenzend, or with Lücken dazwischen
\item[b.] bytes dazwischen/dahinter: Keine, ganzzahliges Vielfaches der maximalen Schreibblockgröße, kein ganzzahliges Vielfaches, weniger bytes als maximale Schreibblockgröße
\item[c.] Löschbytes: Keine, ganzzahliges Vielfaches der maximalen Schreibblockgröße, kein ganzzahliges Vielfaches, weniger bytes als maximale Schreibblockgröße
\end{enumerate}
& Keine Lese/schreiboperationen vor der ersten Einfügung; bytes hinter der letzten Einfügung: Sie bleiben unverändert and werden um $k$ bytes nach hinten verschoben, sodass sich die medialänge um genau $k$ bytes vergrößert; bytes zwischen Einfügungen: bleiben unverändert and werden um die Anzahl der bis dahin eingefügten bytes nach hinten verschoben; Es werden for diese bytes $N$ Lese-/Schreiboperationen geliefert, wobei $N$ der Anzahl der angebrochenen Blöcke der maximalen Schreibblockgröße entspricht, die sich hinter or zwischen den Einfügeoperationen auf dem Medium befinden; die \texttt{insert}-Aktion folgt nach diesen Aktionen im Plan \\
	\hline
CF5 & Multiple \texttt{remove}s &\begin{enumerate}\item[a.] All removes at the same offset or an unterschiedlichen
\item[b.] bytes dazwischen/dahinter: Keine, ganzzahliges Vielfaches der maximalen Schreibblockgröße, kein ganzzahliges Vielfaches, weniger bytes als maximale Schreibblockgröße
\item[c.] Einfügebytes: Keine, ganzzahliges Vielfaches der maximalen Schreibblockgröße, kein ganzzahliges Vielfaches, weniger bytes als maximale Schreibblockgröße
\end{enumerate}
& Keine Lese/schreiboperationen vor der Löschung; bytes dahinter: Sie bleiben unverändert and werden um $k$ bytes nach vorne verschoben, sodass sich die medialänge um genau $k$ bytes verkleinert; Es werden for diese bytes $N$ Lese-/Schreiboperationen geliefert, wobei $N$ der Anzahl der angebrochenen Blöcke der maximalen Schreibblockgröße entspricht, die sich hinter der Löschoperation auf dem Medium befinden; es folgt eine \texttt{truncate}-Operation \\
	\hline
\caption{Testfälle for die Prüfung von \texttt{createFlushPlan}}
\label{tab:createFlushPlan}
\end{longtable}
\end{landscape}



% -------------------------------------------------------------------------------------------------------
\subsubsection{Konfigurationsparameter}%
\label{sec:Konfigurationsparameter}%

Auch wenn die durch den Anwender konfigurierbaren Parameter zur öffentlichen Schnittstelle gehören, so können sie erst hier aufgeführt werden, da erst nach Design der implementation klar geworden ist, was von Außen konfigurierbar sein muss.

Zunächst legen wir folgendes fest:
%%%% DD --> %%%%
\DD{dd:441b}
{% Titel
Die Konfiguration von \COMPmedia{} erfolgt auf einer \IMedium{}-Instanz
}
{% Kurzbeschreibung
Die Konfiguration von \COMPmedia{} erfolgt auf einer \IMedium{}-Instanz. Dawith haben alle Konfigurations-Parameter den Scope eines \IMedium{}s, beziehen sich also nur auf dieses. Es gibt entsprechend eine \texttt{setProperty()}- and eine \texttt{getProperty()}-Methode auf einem \IMedium{}.
}
{% Begründung
Die gesamte internal implementation der wesentlichen Klassen, also \IMediumStore{}, \IMediumAccessor{}, \MediumCache{} usw. arbeitet auf genau einem Medium. Der Anwender kann \IMedium{}-Instanzen direkt erzeugen and nach Belieben konfigurieren, unabhängig von anderen \IMedium{}-Instanzen.
}
{% Nachteile
No disadvantages known
}
%%%% <-- DD %%%%

Nun ist die Frage, welche Konfigurationsparameter wir benötigen. Diese sind in Tabelle \hyperref[tab:ConfigMedia]{\ref{tab:ConfigMedia}} aufgeführt.


\begin{landscape}
\begin{longtable}{|p{0.1\linewidth}|p{0.24\linewidth}|p{0.07\linewidth}|p{0.1\linewidth}|p{0.4\linewidth}|}
	\hline
	\rowcolor[gray]{.9}\textbf{Medium} & \textbf{Parameter-Name} & \textbf{Typ} & \textbf{Default-Wert} & \textbf{Beschreibung} \\
	\endhead
	\hline
	\texttt{File}, \texttt{InputStream} & \texttt{ENABLE\_CACHING} & boolean & \texttt{true} & Aktiviert or deaktiviert das Caching for das Medium according to \DesLink{dd:411c}. Der Cacheinhalt wird beim Setzen auf \texttt{false} sofort geleert. \\
	\hline
	\texttt{File}, \texttt{InputStream} & \texttt{MAX\_CACHE\_REGION\_SIZE} & int $> 0$ & \texttt{Integer} \texttt{.MAX\_VALUE} & Setzt die maximale Größe einer Cache-Region according to \DesLink{dd:436}. \\
	\hline
	\texttt{File}, \texttt{InputStream} & \texttt{MAX\_CACHE\_SIZE} & long $> 0$ & Long \texttt{.MAX\_VALUE} & Setzt die maximale Cache-Größe according to \DesLink{dd:437b}. \\
	\hline
	\texttt{File}, \texttt{byte}-Array & \texttt{MAX\_WRITE\_BLOCK\_SIZE} & int $> 0$ & 8192 & Die maximale Größe einer Lese-Schreib-Aktion in bytes, die durch \texttt{INSERT}s or \texttt{REMOVE}s beim \texttt{flush()} veranlasst wird, see \DesLink{dd:440}. \\
	\hline
	\texttt{InputStream} & \texttt{SKIP\_ON\_FORWARD\_READ} & boolean & \texttt{false} & Bei einem Aufruf von \IMediumStore{}\texttt{.cache()} for einen \texttt{InputStream} with einem bisher noch nicht gelesenen Offset werden bei einem Wert von \texttt{false} immer alle Daten zwischen aktuellem and angegebenem Offset in den Cache gelesene. Bei Angabe von \texttt{true} wird zukünftig stattdessen \IMediumStore{}\texttt{.skip()} verwendet. Vergleiche \DesLink{dd:411d} and die Beschreibung von cache() in \hyperref[tab:MediaOps]{\ref{tab:MediaOps}}. \\
	\hline
	\texttt{InputStream} & \texttt{READ\_TIMEOUT\_MILLIS} & int $> 0$ & Integer \texttt{.MAX\_VALUE} & Der maximale Lese-Timeout for \texttt{InputStream}s according to \DesLink{dd:426}, in Millisekanden. \\
	\hline
\caption{Konfigurationsparameter der component \COMPmedia{}}
\label{tab:ConfigMedia}
\end{longtable}
\end{landscape}



%###############################################################################################
%###############################################################################################
%
%		File end
%
%###############################################################################################
%###############################################################################################